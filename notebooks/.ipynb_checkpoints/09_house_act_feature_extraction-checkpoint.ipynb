{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-26T16:23:40.077077Z",
     "start_time": "2019-10-26T16:23:35.975692Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import soundfile\n",
    "import librosa\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-26T16:23:44.001017Z",
     "start_time": "2019-10-26T16:23:43.862525Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-26T16:23:49.613693Z",
     "start_time": "2019-10-26T16:23:49.527844Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /Users/greenapple/project3/src/features/feature_extraction_VGGish.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile '/Users/greenapple/project3/src/features/feature_extraction_VGGish.py'\n",
    "\n",
    "import os\n",
    "import soundfile\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from src.features import vggish_input\n",
    "from src.features import vggish_params\n",
    "from src.features import vggish_postprocess\n",
    "from src.features import vggish_slim\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def read_audio(path, target_fs=None):\n",
    "    (audio, fs) = soundfile.read(path)\n",
    "\n",
    "    if audio.ndim > 1:\n",
    "        audio = np.mean(audio, axis=1)\n",
    "        \n",
    "    if target_fs is not None and fs != target_fs:\n",
    "        audio = librosa.resample(audio, orig_sr=fs, target_sr=target_fs)\n",
    "        fs = target_fs\n",
    "        \n",
    "    return audio, fs\n",
    "    \n",
    "\n",
    "# Feature extraction\n",
    "def extract_audioset_embedding(audio_file):\n",
    "    \"\"\"Extract log mel spectrogram features. \n",
    "    \"\"\"\n",
    "    \n",
    "    # Arguments & parameters\n",
    "    mel_bins = vggish_params.NUM_BANDS\n",
    "    sample_rate = vggish_params.SAMPLE_RATE\n",
    "    input_len = vggish_params.NUM_FRAMES\n",
    "    embedding_size = vggish_params.EMBEDDING_SIZE\n",
    "    \n",
    "    '''You may modify the EXAMPLE_HOP_SECONDS in vggish_params.py to change the \n",
    "    hop size. '''\n",
    "\n",
    "    # Paths\n",
    "    path = '/Users/greenapple/project3/data/house_activities_wavs/'\n",
    "    audio_path = os.path.join(path, audio_file)\n",
    "    checkpoint_path = '/Users/greenapple/project3/src/features/vggish_model.ckpt'\n",
    "    pcm_params_path = '/Users/greenapple/project3/src/features/vggish_pca_params.npz'\n",
    "    \n",
    "    # Load model\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    vggish_slim.define_vggish_slim(training=False)\n",
    "    vggish_slim.load_vggish_slim_checkpoint(sess, checkpoint_path)\n",
    "    features_tensor = sess.graph.get_tensor_by_name(vggish_params.INPUT_TENSOR_NAME)\n",
    "    embedding_tensor = sess.graph.get_tensor_by_name(vggish_params.OUTPUT_TENSOR_NAME)\n",
    "    \n",
    "    pproc = vggish_postprocess.Postprocessor(pcm_params_path)\n",
    "\n",
    "    # Read audio\n",
    "    (audio, _) = read_audio(audio_path, target_fs=sample_rate)\n",
    "    \n",
    "    # Extract log mel feature\n",
    "    logmel = vggish_input.waveform_to_examples(audio, sample_rate)\n",
    "\n",
    "    # Extract embedding feature\n",
    "    [embedding_batch] = sess.run([embedding_tensor], feed_dict={features_tensor: logmel})\n",
    "    \n",
    "    # PCA\n",
    "    postprocessed_batch = pproc.postprocess(embedding_batch)\n",
    "    \n",
    "    print('Audio length: {}'.format(len(audio)))\n",
    "    print('Log mel shape: {}'.format(logmel.shape))\n",
    "    print('Embedding feature shape: {}'.format(postprocessed_batch.shape))\n",
    "    \n",
    "    return postprocessed_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.features import feature_extraction_VGGish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T04:42:51.308504Z",
     "start_time": "2019-10-21T04:42:46.400265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/greenapple/project3/src/features/vggish_model.ckpt\n",
      "Audio length: 171350\n",
      "Log mel shape: (11, 96, 64)\n",
      "Embedding feature shape: (11, 128)\n"
     ]
    }
   ],
   "source": [
    "features = extract_audioset_embedding('20191020_200040_1.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T02:28:43.435564Z",
     "start_time": "2019-10-21T02:28:43.425408Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 128)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project3",
   "language": "python",
   "name": "project3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
