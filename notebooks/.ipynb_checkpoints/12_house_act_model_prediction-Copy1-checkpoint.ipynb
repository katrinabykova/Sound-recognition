{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T17:37:38.299997Z",
     "start_time": "2019-10-29T17:37:35.455624Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import soundfile\n",
    "import librosa\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.ensemble import (RandomForestClassifier, ExtraTreesClassifier, VotingClassifier, \n",
    "                              AdaBoostClassifier, BaggingRegressor)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.features import feature_extraction_VGGish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T17:38:10.281401Z",
     "start_time": "2019-10-29T17:38:10.176805Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T17:38:12.178642Z",
     "start_time": "2019-10-29T17:38:12.065713Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%writefile '/Users/greenapple/project3/src/features/feature_extraction_VGGish.py'\n",
    "\n",
    "import os\n",
    "import soundfile\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from src.features import vggish_input\n",
    "from src.features import vggish_params\n",
    "from src.features import vggish_postprocess\n",
    "from src.features import vggish_slim\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "def read_audio(path, target_fs=None):\n",
    "    (audio, fs) = soundfile.read(path)\n",
    "\n",
    "    if audio.ndim > 1:\n",
    "        audio = np.mean(audio, axis=1)\n",
    "        \n",
    "    if target_fs is not None and fs != target_fs:\n",
    "        audio = librosa.resample(audio, orig_sr=fs, target_sr=target_fs)\n",
    "        fs = target_fs\n",
    "        \n",
    "    return audio, fs\n",
    "    \n",
    "\n",
    "# Feature extraction\n",
    "def extract_audioset_embedding(audio_file):\n",
    "    \"\"\"Extract log mel spectrogram features. \n",
    "    \"\"\"\n",
    "    \n",
    "    # Arguments & parameters\n",
    "    mel_bins = vggish_params.NUM_BANDS\n",
    "    sample_rate = vggish_params.SAMPLE_RATE\n",
    "    input_len = vggish_params.NUM_FRAMES\n",
    "    embedding_size = vggish_params.EMBEDDING_SIZE\n",
    "    \n",
    "    '''You may modify the EXAMPLE_HOP_SECONDS in vggish_params.py to change the \n",
    "    hop size. '''\n",
    "\n",
    "    # Paths\n",
    "    path = '/Users/greenapple/project3/data/house_activities_wavs/'\n",
    "    audio_path = os.path.join(path, audio_file)\n",
    "    checkpoint_path = '/Users/greenapple/project3/src/features/vggish_model.ckpt'\n",
    "    pcm_params_path = '/Users/greenapple/project3/src/features/vggish_pca_params.npz'\n",
    "    \n",
    "    # Load model\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    vggish_slim.define_vggish_slim(training=False)\n",
    "    vggish_slim.load_vggish_slim_checkpoint(sess, checkpoint_path)\n",
    "    features_tensor = sess.graph.get_tensor_by_name(vggish_params.INPUT_TENSOR_NAME)\n",
    "    embedding_tensor = sess.graph.get_tensor_by_name(vggish_params.OUTPUT_TENSOR_NAME)\n",
    "    \n",
    "    pproc = vggish_postprocess.Postprocessor(pcm_params_path)\n",
    "\n",
    "    # Read audio\n",
    "    (audio, _) = read_audio(audio_path, target_fs=sample_rate)\n",
    "    \n",
    "    # Extract log mel feature\n",
    "    logmel = vggish_input.waveform_to_examples(audio, sample_rate)\n",
    "\n",
    "    # Extract embedding feature\n",
    "    [embedding_batch] = sess.run([embedding_tensor], feed_dict={features_tensor: logmel})\n",
    "    \n",
    "    # PCA\n",
    "    postprocessed_batch = pproc.postprocess(embedding_batch)\n",
    "    \n",
    "    print('Audio length: {}'.format(len(audio)))\n",
    "    print('Log mel shape: {}'.format(logmel.shape))\n",
    "    print('Embedding feature shape: {}'.format(postprocessed_batch.shape))\n",
    "    \n",
    "    return postprocessed_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T17:38:13.318162Z",
     "start_time": "2019-10-29T17:38:12.749327Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load pre-trained models\n",
    "model_names = [\n",
    "    'logreg1',\n",
    "    'logreg2',\n",
    "    'logreg3',\n",
    "    'KNN',\n",
    "    'NBmultinomial',\n",
    "    'RF',\n",
    "    'GBM'\n",
    "]\n",
    "\n",
    "model_fldr = '/Users/greenapple/project3/aws/models'\n",
    "\n",
    "for model in model_names:\n",
    "    pickling_out = open(os.path.join(model_fldr, f'{model}_10_cls_model_rand.pkl'), 'rb')\n",
    "    exec(f'{model} = pickle.load(pickling_out)')\n",
    "    pickling_out.close()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T17:38:13.415431Z",
     "start_time": "2019-10-29T17:38:13.320325Z"
    }
   },
   "outputs": [],
   "source": [
    "# Converts an audio file to a dataframe with features that are ready for a model prediction\n",
    "def audio_to_df(audio_file, audio_folder):\n",
    "    \n",
    "    # Extract features\n",
    "    audio_path = os.path.join(audio_folder, audio_file)\n",
    "    features = extract_audioset_embedding(audio_path)\n",
    "    \n",
    "    # Take date from the first 5 sec of the wav file\n",
    "    features_5sec = features[:5]\n",
    "    \n",
    "    # Reshape array in 1 row with 640 features\n",
    "    features_row = features_5sec.reshape(1, 640)\n",
    "    features_df = pd.DataFrame(features_row)\n",
    "    \n",
    "    return features_df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T17:38:14.297403Z",
     "start_time": "2019-10-29T17:38:14.201186Z"
    }
   },
   "outputs": [],
   "source": [
    "# Makes a dataframe with features extracted from the house activity audio files\n",
    "\n",
    "def audio_list_to_df(audio_file_list, audio_folder):\n",
    "    audio_df = pd.DataFrame()\n",
    "    for audio_file in audio_file_list:\n",
    "        row = audio_to_df(audio_file, audio_folder)\n",
    "        audio_df = pd.concat([audio_df, row], ignore_index=True)   \n",
    "    return audio_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T17:38:36.069762Z",
     "start_time": "2019-10-29T17:38:23.655626Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/greenapple/project3/src/features/vggish_model.ckpt\n",
      "Audio length: 80000\n",
      "Log mel shape: (5, 96, 64)\n",
      "Embedding feature shape: (5, 128)\n",
      "INFO:tensorflow:Restoring parameters from /Users/greenapple/project3/src/features/vggish_model.ckpt\n",
      "Audio length: 160128\n",
      "Log mel shape: (10, 96, 64)\n",
      "Embedding feature shape: (10, 128)\n",
      "INFO:tensorflow:Restoring parameters from /Users/greenapple/project3/src/features/vggish_model.ckpt\n",
      "Audio length: 80299\n",
      "Log mel shape: (5, 96, 64)\n",
      "Embedding feature shape: (5, 128)\n",
      "INFO:tensorflow:Restoring parameters from /Users/greenapple/project3/src/features/vggish_model.ckpt\n",
      "Audio length: 160128\n",
      "Log mel shape: (10, 96, 64)\n",
      "Embedding feature shape: (10, 128)\n",
      "INFO:tensorflow:Restoring parameters from /Users/greenapple/project3/src/features/vggish_model.ckpt\n",
      "Audio length: 160086\n",
      "Log mel shape: (10, 96, 64)\n",
      "Embedding feature shape: (10, 128)\n",
      "INFO:tensorflow:Restoring parameters from /Users/greenapple/project3/src/features/vggish_model.ckpt\n",
      "Audio length: 80214\n",
      "Log mel shape: (5, 96, 64)\n",
      "Embedding feature shape: (5, 128)\n",
      "INFO:tensorflow:Restoring parameters from /Users/greenapple/project3/src/features/vggish_model.ckpt\n",
      "Audio length: 160150\n",
      "Log mel shape: (10, 96, 64)\n",
      "Embedding feature shape: (10, 128)\n"
     ]
    }
   ],
   "source": [
    "# List of home activities sound files for prediction\n",
    "audio_file_list = [\n",
    "    '20191029_073112.wav',\n",
    "    '20191029_073337.wav',\n",
    "    '20191029_073459.wav',\n",
    "    '20191025_073237.wav',\n",
    "    '20191025_073858.wav',\n",
    "    '20191025_074029.wav',\n",
    "    '20191025_074057.wav'\n",
    "]\n",
    "\n",
    "audio_folder = '/Users/greenapple/project3/data/house_activities_wavs/'\n",
    "\n",
    "audio_df = audio_list_to_df(audio_file_list, audio_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T17:38:47.580566Z",
     "start_time": "2019-10-29T17:38:47.479211Z"
    }
   },
   "outputs": [],
   "source": [
    "# Takes in a list of sound files and models - returns predicted values\n",
    "\n",
    "def sound_recognition(audio_files, models):\n",
    "    audio_df_pred = pd.DataFrame()\n",
    "   \n",
    "    # Extract features\n",
    "    audio_df = audio_list_to_df(audio_files.values(), audio_folder)\n",
    "    \n",
    "    # Predict\n",
    "    for model in models.values():\n",
    "        row = model.predict(audio_df)\n",
    "        row = row.reshape(1, len(audio_files))\n",
    "        row = pd.DataFrame(row)\n",
    "        audio_df_pred = pd.concat([audio_df_pred, row], ignore_index=True)  \n",
    "     \n",
    "    # Rename columns with sound file names\n",
    "    audio_df_pred.columns = audio_files.keys()\n",
    "    \n",
    "    # Add a column with model names\n",
    "    audio_df_pred['model'] = models.keys()\n",
    "    \n",
    "     # Change column order\n",
    "    columns = audio_df_pred.columns.to_list()\n",
    "    columns = columns[-1:] + columns[:-1]\n",
    "    audio_df_pred = audio_df_pred[columns]\n",
    "    audio_df_pred\n",
    "    \n",
    "    return audio_df_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting sound class for house recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T18:45:04.036758Z",
     "start_time": "2019-10-29T18:44:49.353493Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/greenapple/project3/src/features/vggish_model.ckpt\n",
      "Audio length: 89750\n",
      "Log mel shape: (5, 96, 64)\n",
      "Embedding feature shape: (5, 128)\n",
      "INFO:tensorflow:Restoring parameters from /Users/greenapple/project3/src/features/vggish_model.ckpt\n",
      "Audio length: 96299\n",
      "Log mel shape: (6, 96, 64)\n",
      "Embedding feature shape: (6, 128)\n",
      "INFO:tensorflow:Restoring parameters from /Users/greenapple/project3/src/features/vggish_model.ckpt\n",
      "Audio length: 80000\n",
      "Log mel shape: (5, 96, 64)\n",
      "Embedding feature shape: (5, 128)\n",
      "INFO:tensorflow:Restoring parameters from /Users/greenapple/project3/src/features/vggish_model.ckpt\n",
      "Audio length: 160128\n",
      "Log mel shape: (10, 96, 64)\n",
      "Embedding feature shape: (10, 128)\n",
      "INFO:tensorflow:Restoring parameters from /Users/greenapple/project3/src/features/vggish_model.ckpt\n",
      "Audio length: 80299\n",
      "Log mel shape: (5, 96, 64)\n",
      "Embedding feature shape: (5, 128)\n",
      "INFO:tensorflow:Restoring parameters from /Users/greenapple/project3/src/features/vggish_model.ckpt\n",
      "Audio length: 160128\n",
      "Log mel shape: (10, 96, 64)\n",
      "Embedding feature shape: (10, 128)\n",
      "INFO:tensorflow:Restoring parameters from /Users/greenapple/project3/src/features/vggish_model.ckpt\n",
      "Audio length: 160086\n",
      "Log mel shape: (10, 96, 64)\n",
      "Embedding feature shape: (10, 128)\n",
      "INFO:tensorflow:Restoring parameters from /Users/greenapple/project3/src/features/vggish_model.ckpt\n",
      "Audio length: 80214\n",
      "Log mel shape: (5, 96, 64)\n",
      "Embedding feature shape: (5, 128)\n",
      "INFO:tensorflow:Restoring parameters from /Users/greenapple/project3/src/features/vggish_model.ckpt\n",
      "Audio length: 160150\n",
      "Log mel shape: (10, 96, 64)\n",
      "Embedding feature shape: (10, 128)\n"
     ]
    }
   ],
   "source": [
    "# Predict sound class from a list of sound files\n",
    "\n",
    "# List of home activities sound files for prediction\n",
    "audio_file_list = [\n",
    "    '20191029_micr1.wav',\n",
    "    '20191029_073337_t.wav',\n",
    "    '20191029_073112.wav',\n",
    "    '20191029_073337.wav',\n",
    "    '20191029_073459.wav',\n",
    "    '20191025_073237.wav',\n",
    "    '20191025_073858.wav',\n",
    "    '20191025_074029.wav',\n",
    "    '20191025_074057.wav'\n",
    "]\n",
    "\n",
    "audio_folder = '/Users/greenapple/project3/data/house_activities_wavs/'\n",
    "\n",
    "# Home activities labeles\n",
    "audio_file_keys = [\n",
    "    'micr1',\n",
    "    'micr2',\n",
    "    'vacuum cleaner',\n",
    "    'microwave',\n",
    "    'opening doors',\n",
    "    'clarinet',\n",
    "    'water',\n",
    "    'human_cat_sound',\n",
    "    'cat'\n",
    "]\n",
    "\n",
    "models = {\n",
    "    'Logistic_regression1':logreg1,\n",
    "    'Logistic_regression2':logreg2,\n",
    "    'Logistic_regression3':logreg3,\n",
    "    'KNN':KNN,\n",
    "    'Naive_Bayes_multinomial':NBmultinomial,\n",
    "    'Random_Forest':RF,\n",
    "    'Gradient_boosting':GBM\n",
    "}\n",
    "\n",
    "audio_files = dict(zip(audio_file_keys, audio_file_list))\n",
    "\n",
    "audio_df_pred = sound_recognition(audio_files, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T18:45:04.126012Z",
     "start_time": "2019-10-29T18:45:04.038837Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>micr1</th>\n",
       "      <th>micr2</th>\n",
       "      <th>vacuum cleaner</th>\n",
       "      <th>microwave</th>\n",
       "      <th>opening doors</th>\n",
       "      <th>clarinet</th>\n",
       "      <th>water</th>\n",
       "      <th>human_cat_sound</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Logistic_regression1</td>\n",
       "      <td>footsteps</td>\n",
       "      <td>blender</td>\n",
       "      <td>vacuum_cleaner</td>\n",
       "      <td>blender</td>\n",
       "      <td>meow</td>\n",
       "      <td>clarinet</td>\n",
       "      <td>water_tap</td>\n",
       "      <td>meow</td>\n",
       "      <td>meow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Logistic_regression2</td>\n",
       "      <td>microwave</td>\n",
       "      <td>blender</td>\n",
       "      <td>vacuum_cleaner</td>\n",
       "      <td>blender</td>\n",
       "      <td>meow</td>\n",
       "      <td>clarinet</td>\n",
       "      <td>water_tap</td>\n",
       "      <td>meow</td>\n",
       "      <td>meow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Logistic_regression3</td>\n",
       "      <td>meow</td>\n",
       "      <td>blender</td>\n",
       "      <td>vacuum_cleaner</td>\n",
       "      <td>blender</td>\n",
       "      <td>meow</td>\n",
       "      <td>clarinet</td>\n",
       "      <td>water_tap</td>\n",
       "      <td>meow</td>\n",
       "      <td>meow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>KNN</td>\n",
       "      <td>microwave</td>\n",
       "      <td>door</td>\n",
       "      <td>vacuum_cleaner</td>\n",
       "      <td>door</td>\n",
       "      <td>music</td>\n",
       "      <td>music</td>\n",
       "      <td>water_tap</td>\n",
       "      <td>water_tap</td>\n",
       "      <td>microwave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Naive_Bayes_multinomial</td>\n",
       "      <td>microwave</td>\n",
       "      <td>door</td>\n",
       "      <td>vacuum_cleaner</td>\n",
       "      <td>door</td>\n",
       "      <td>speech</td>\n",
       "      <td>clarinet</td>\n",
       "      <td>meow</td>\n",
       "      <td>speech</td>\n",
       "      <td>meow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>music</td>\n",
       "      <td>speech</td>\n",
       "      <td>vacuum_cleaner</td>\n",
       "      <td>speech</td>\n",
       "      <td>music</td>\n",
       "      <td>music</td>\n",
       "      <td>music</td>\n",
       "      <td>music</td>\n",
       "      <td>music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Gradient_boosting</td>\n",
       "      <td>water_tap</td>\n",
       "      <td>blender</td>\n",
       "      <td>vacuum_cleaner</td>\n",
       "      <td>blender</td>\n",
       "      <td>water_tap</td>\n",
       "      <td>music</td>\n",
       "      <td>water_tap</td>\n",
       "      <td>speech</td>\n",
       "      <td>speech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model      micr1    micr2  vacuum cleaner microwave  \\\n",
       "0     Logistic_regression1  footsteps  blender  vacuum_cleaner   blender   \n",
       "1     Logistic_regression2  microwave  blender  vacuum_cleaner   blender   \n",
       "2     Logistic_regression3       meow  blender  vacuum_cleaner   blender   \n",
       "3                      KNN  microwave     door  vacuum_cleaner      door   \n",
       "4  Naive_Bayes_multinomial  microwave     door  vacuum_cleaner      door   \n",
       "5            Random_Forest      music   speech  vacuum_cleaner    speech   \n",
       "6        Gradient_boosting  water_tap  blender  vacuum_cleaner   blender   \n",
       "\n",
       "  opening doors  clarinet      water human_cat_sound        cat  \n",
       "0          meow  clarinet  water_tap            meow       meow  \n",
       "1          meow  clarinet  water_tap            meow       meow  \n",
       "2          meow  clarinet  water_tap            meow       meow  \n",
       "3         music     music  water_tap       water_tap  microwave  \n",
       "4        speech  clarinet       meow          speech       meow  \n",
       "5         music     music      music           music      music  \n",
       "6     water_tap     music  water_tap          speech     speech  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classification of recorded sounds\n",
    "audio_df_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Little voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T18:45:04.222700Z",
     "start_time": "2019-10-29T18:45:04.129243Z"
    }
   },
   "outputs": [],
   "source": [
    "# It takes more than 8 hours to train a voting or meta- classifiers. Build a little voting classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T18:45:04.321720Z",
     "start_time": "2019-10-29T18:45:04.225019Z"
    }
   },
   "outputs": [],
   "source": [
    "# Little voting classifier\n",
    "def little_vote(df_pred):\n",
    "    pred = []\n",
    "    df_pred_vc = pd.DataFrame()\n",
    "    \n",
    "    for column in list(df_pred.columns):\n",
    "        if column=='model':\n",
    "            pred.append('little_VotingClassifier')\n",
    "        else:\n",
    "            pred.append(df_pred[column].mode()[0])\n",
    "    \n",
    "    pred_dict = dict(zip(list(df_pred.columns), pred))\n",
    "    \n",
    "    df_pred = df_pred.append(pred_dict, ignore_index=True)\n",
    "        \n",
    "    return df_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T18:45:04.428733Z",
     "start_time": "2019-10-29T18:45:04.323988Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>micr1</th>\n",
       "      <th>micr2</th>\n",
       "      <th>vacuum cleaner</th>\n",
       "      <th>microwave</th>\n",
       "      <th>opening doors</th>\n",
       "      <th>clarinet</th>\n",
       "      <th>water</th>\n",
       "      <th>human_cat_sound</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Logistic_regression1</td>\n",
       "      <td>footsteps</td>\n",
       "      <td>blender</td>\n",
       "      <td>vacuum_cleaner</td>\n",
       "      <td>blender</td>\n",
       "      <td>meow</td>\n",
       "      <td>clarinet</td>\n",
       "      <td>water_tap</td>\n",
       "      <td>meow</td>\n",
       "      <td>meow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Logistic_regression2</td>\n",
       "      <td>microwave</td>\n",
       "      <td>blender</td>\n",
       "      <td>vacuum_cleaner</td>\n",
       "      <td>blender</td>\n",
       "      <td>meow</td>\n",
       "      <td>clarinet</td>\n",
       "      <td>water_tap</td>\n",
       "      <td>meow</td>\n",
       "      <td>meow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Logistic_regression3</td>\n",
       "      <td>meow</td>\n",
       "      <td>blender</td>\n",
       "      <td>vacuum_cleaner</td>\n",
       "      <td>blender</td>\n",
       "      <td>meow</td>\n",
       "      <td>clarinet</td>\n",
       "      <td>water_tap</td>\n",
       "      <td>meow</td>\n",
       "      <td>meow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>KNN</td>\n",
       "      <td>microwave</td>\n",
       "      <td>door</td>\n",
       "      <td>vacuum_cleaner</td>\n",
       "      <td>door</td>\n",
       "      <td>music</td>\n",
       "      <td>music</td>\n",
       "      <td>water_tap</td>\n",
       "      <td>water_tap</td>\n",
       "      <td>microwave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Naive_Bayes_multinomial</td>\n",
       "      <td>microwave</td>\n",
       "      <td>door</td>\n",
       "      <td>vacuum_cleaner</td>\n",
       "      <td>door</td>\n",
       "      <td>speech</td>\n",
       "      <td>clarinet</td>\n",
       "      <td>meow</td>\n",
       "      <td>speech</td>\n",
       "      <td>meow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>music</td>\n",
       "      <td>speech</td>\n",
       "      <td>vacuum_cleaner</td>\n",
       "      <td>speech</td>\n",
       "      <td>music</td>\n",
       "      <td>music</td>\n",
       "      <td>music</td>\n",
       "      <td>music</td>\n",
       "      <td>music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Gradient_boosting</td>\n",
       "      <td>water_tap</td>\n",
       "      <td>blender</td>\n",
       "      <td>vacuum_cleaner</td>\n",
       "      <td>blender</td>\n",
       "      <td>water_tap</td>\n",
       "      <td>music</td>\n",
       "      <td>water_tap</td>\n",
       "      <td>speech</td>\n",
       "      <td>speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>little_VotingClassifier</td>\n",
       "      <td>microwave</td>\n",
       "      <td>blender</td>\n",
       "      <td>vacuum_cleaner</td>\n",
       "      <td>blender</td>\n",
       "      <td>meow</td>\n",
       "      <td>clarinet</td>\n",
       "      <td>water_tap</td>\n",
       "      <td>meow</td>\n",
       "      <td>meow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model      micr1    micr2  vacuum cleaner microwave  \\\n",
       "0     Logistic_regression1  footsteps  blender  vacuum_cleaner   blender   \n",
       "1     Logistic_regression2  microwave  blender  vacuum_cleaner   blender   \n",
       "2     Logistic_regression3       meow  blender  vacuum_cleaner   blender   \n",
       "3                      KNN  microwave     door  vacuum_cleaner      door   \n",
       "4  Naive_Bayes_multinomial  microwave     door  vacuum_cleaner      door   \n",
       "5            Random_Forest      music   speech  vacuum_cleaner    speech   \n",
       "6        Gradient_boosting  water_tap  blender  vacuum_cleaner   blender   \n",
       "7  little_VotingClassifier  microwave  blender  vacuum_cleaner   blender   \n",
       "\n",
       "  opening doors  clarinet      water human_cat_sound        cat  \n",
       "0          meow  clarinet  water_tap            meow       meow  \n",
       "1          meow  clarinet  water_tap            meow       meow  \n",
       "2          meow  clarinet  water_tap            meow       meow  \n",
       "3         music     music  water_tap       water_tap  microwave  \n",
       "4        speech  clarinet       meow          speech       meow  \n",
       "5         music     music      music           music      music  \n",
       "6     water_tap     music  water_tap          speech     speech  \n",
       "7          meow  clarinet  water_tap            meow       meow  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_df_pred_vc = little_vote(audio_df_pred)\n",
    "audio_df_pred_vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening door recording was contaminated by the cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T17:39:43.735211Z",
     "start_time": "2019-10-29T17:39:43.625137Z"
    }
   },
   "outputs": [],
   "source": [
    "# Estimate model train time. Explore later.\n",
    "from scitime import Estimator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project3",
   "language": "python",
   "name": "project3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
