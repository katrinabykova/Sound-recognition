{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T03:19:42.048246Z",
     "start_time": "2019-10-23T03:19:39.490133Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "import sklearn\n",
    "from skmultilearn.ensemble import MajorityVotingClassifier\n",
    "from sklearn import linear_model, svm, naive_bayes, neighbors, ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T03:19:53.829740Z",
     "start_time": "2019-10-23T03:19:53.738274Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data formatting for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T21:42:44.044884Z",
     "start_time": "2019-10-21T21:42:43.906458Z"
    }
   },
   "outputs": [],
   "source": [
    "# Unpickle data \n",
    "with open('/Users/greenapple/project3/data/processed/house_bal.pkl', 'rb') as f:\n",
    "    house_bal = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T21:42:45.143726Z",
     "start_time": "2019-10-21T21:42:45.027403Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id_list</th>\n",
       "      <th>y</th>\n",
       "      <th>y_name</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>630</th>\n",
       "      <th>631</th>\n",
       "      <th>632</th>\n",
       "      <th>633</th>\n",
       "      <th>634</th>\n",
       "      <th>635</th>\n",
       "      <th>636</th>\n",
       "      <th>637</th>\n",
       "      <th>638</th>\n",
       "      <th>639</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>b'--ZhevVpy1s'</td>\n",
       "      <td>375</td>\n",
       "      <td>toothbrush</td>\n",
       "      <td>117</td>\n",
       "      <td>35</td>\n",
       "      <td>163</td>\n",
       "      <td>90</td>\n",
       "      <td>198</td>\n",
       "      <td>103</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>202</td>\n",
       "      <td>9</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>247</td>\n",
       "      <td>72</td>\n",
       "      <td>44</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>b'-2hQKCE-oTI'</td>\n",
       "      <td>53</td>\n",
       "      <td>footsteps</td>\n",
       "      <td>30</td>\n",
       "      <td>162</td>\n",
       "      <td>44</td>\n",
       "      <td>7</td>\n",
       "      <td>216</td>\n",
       "      <td>116</td>\n",
       "      <td>206</td>\n",
       "      <td>...</td>\n",
       "      <td>213</td>\n",
       "      <td>109</td>\n",
       "      <td>50</td>\n",
       "      <td>88</td>\n",
       "      <td>19</td>\n",
       "      <td>46</td>\n",
       "      <td>54</td>\n",
       "      <td>154</td>\n",
       "      <td>42</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>b'-3pPrlCm6gg'</td>\n",
       "      <td>198</td>\n",
       "      <td>clarinet</td>\n",
       "      <td>179</td>\n",
       "      <td>190</td>\n",
       "      <td>122</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>58</td>\n",
       "      <td>15</td>\n",
       "      <td>207</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>43</td>\n",
       "      <td>97</td>\n",
       "      <td>57</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>b'-70wVF5u-gg'</td>\n",
       "      <td>366</td>\n",
       "      <td>chopping_food</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>186</td>\n",
       "      <td>34</td>\n",
       "      <td>87</td>\n",
       "      <td>250</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>144</td>\n",
       "      <td>63</td>\n",
       "      <td>110</td>\n",
       "      <td>255</td>\n",
       "      <td>139</td>\n",
       "      <td>138</td>\n",
       "      <td>59</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>b'-ASYwidRD7M'</td>\n",
       "      <td>43</td>\n",
       "      <td>snoring</td>\n",
       "      <td>53</td>\n",
       "      <td>100</td>\n",
       "      <td>144</td>\n",
       "      <td>84</td>\n",
       "      <td>223</td>\n",
       "      <td>68</td>\n",
       "      <td>95</td>\n",
       "      <td>...</td>\n",
       "      <td>56</td>\n",
       "      <td>78</td>\n",
       "      <td>153</td>\n",
       "      <td>65</td>\n",
       "      <td>208</td>\n",
       "      <td>207</td>\n",
       "      <td>200</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 643 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     video_id_list    y         y_name    0    1    2   3    4    5    6  ...  \\\n",
       "5   b'--ZhevVpy1s'  375     toothbrush  117   35  163  90  198  103   63  ...   \n",
       "20  b'-2hQKCE-oTI'   53      footsteps   30  162   44   7  216  116  206  ...   \n",
       "28  b'-3pPrlCm6gg'  198       clarinet  179  190  122  19    0  114  255  ...   \n",
       "63  b'-70wVF5u-gg'  366  chopping_food    0  114  186  34   87  250   58  ...   \n",
       "82  b'-ASYwidRD7M'   43        snoring   53  100  144  84  223   68   95  ...   \n",
       "\n",
       "    630  631  632  633  634  635  636  637  638  639  \n",
       "5     0    1  202    9  116    0  247   72   44  166  \n",
       "20  213  109   50   88   19   46   54  154   42  211  \n",
       "28   58   15  207    0  108   43   97   57   42    0  \n",
       "63    0  122  144   63  110  255  139  138   59  154  \n",
       "82   56   78  153   65  208  207  200  255  255   66  \n",
       "\n",
       "[5 rows x 643 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_bal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T21:54:45.418679Z",
     "start_time": "2019-10-21T21:54:45.351730Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45717, 643)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_bal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T21:54:47.455479Z",
     "start_time": "2019-10-21T21:54:47.377778Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(house_bal.y_name.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T21:42:48.338390Z",
     "start_time": "2019-10-21T21:42:48.259512Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speech            4042\n",
       "music             3781\n",
       "laughter          3772\n",
       "snoring           3370\n",
       "vacuum_cleaner    3054\n",
       "typing            2644\n",
       "dishes_pots       2560\n",
       "frying_food       2102\n",
       "blender           1884\n",
       "toilet_flush      1882\n",
       "door              1868\n",
       "whoop             1736\n",
       "footsteps         1492\n",
       "baby_cry          1414\n",
       "screeming         1116\n",
       "whispering         972\n",
       "clarinet           960\n",
       "crying             918\n",
       "microwave          894\n",
       "television         866\n",
       "hair_dryer         772\n",
       "video_games        592\n",
       "shaving            552\n",
       "bathtab            472\n",
       "water_tap          458\n",
       "chopping_food      410\n",
       "meow               388\n",
       "dog                358\n",
       "purr               304\n",
       "toothbrush          84\n",
       "Name: y_name, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_bal.y_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T21:54:58.897190Z",
     "start_time": "2019-10-21T21:54:58.821596Z"
    }
   },
   "outputs": [],
   "source": [
    "# Assign features X and target y\n",
    "X = house_bal[house_bal.columns[3:643]]\n",
    "y = house_bal.y_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T22:31:17.554240Z",
     "start_time": "2019-10-21T22:31:17.445930Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36573, 640), (36573,), (9144, 640), (9144,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and evaluate models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T17:35:29.887767Z",
     "start_time": "2019-10-19T17:35:29.883261Z"
    }
   },
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train and fit logistic regression with  RandomizedSearchCV:  1st set of parameteres\n",
    "from src.models import model_sel_rand_search\n",
    "\n",
    "# Function arguments:\n",
    "model = LogisticRegression(random_state=3)\n",
    "transformer = RandomOverSampler(random_state=3, sampling_strategy='minority')\n",
    "CV = 5\n",
    "\n",
    "# Function arguments: classifier params\n",
    "penalty = ['l1', 'l2']\n",
    "C = np.logspace(0, 4, 10)\n",
    "solver = ['liblinear', 'saga']\n",
    "\n",
    "param_distributions = dict(\n",
    "        model__C = C, \n",
    "        model__penalty = penalty,\n",
    "        model__solver=solver)\n",
    "\n",
    "# Call parameter selection function\n",
    "logreg1_30_cls_scores_params, logreg1_30_cls_model = model_sel_rand_search.train_fit_time(model,\n",
    "                                                                               param_distributions,\n",
    "                                                                               transformer,\n",
    "                                                                               X_train,\n",
    "                                                                               X_test,\n",
    "                                                                               y_train,\n",
    "                                                                               y_test,\n",
    "                                                                               CV)\n",
    "# Pickle results\n",
    "with open('/Users/greenapple/project3/models/logreg1_30_cls_scores_params_rand.pkl', 'wb') as f:\n",
    "    pickle.dump(logreg1_30_cls_scores_params, f)\n",
    "    \n",
    "# Pickle model\n",
    "with open('/Users/greenapple/project3/models/logreg1_30_cls_model_rand.pkl', 'wb') as f:\n",
    "    pickle.dump(logreg1_30_cls_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and fit logistic regression with  RandomizedSearchCV: 2nd set of parameteres\n",
    "from src.models import model_sel_rand_search\n",
    "\n",
    "# Function arguments:\n",
    "model = LogisticRegression(random_state=3, multi_class='multinomial', solver='saga')\n",
    "transformer = RandomOverSampler(random_state=3, sampling_strategy='minority')\n",
    "CV = 5\n",
    "\n",
    "# Function arguments: classifier params\n",
    "penalty = ['elasticnet']\n",
    "C = np.logspace(0, 4, 10)\n",
    "solver = 'saga'\n",
    "multiclass='multinomial'\n",
    "l1_1ratio = list(np.arange(0, 1, 0.1))\n",
    "\n",
    "param_distributions = dict(\n",
    "        model__C = C, \n",
    "        model__penalty = penalty,\n",
    "        model__l1_ratio=l1_ratio)\n",
    "\n",
    "\n",
    "# Call parameter selection function\n",
    "logreg2_30_cls_scores_params, logreg2_30_cls_model = model_sel_rand_search.train_fit_time(model,\n",
    "                                                                               param_distributions,\n",
    "                                                                               transformer,\n",
    "                                                                               X_train,\n",
    "                                                                               X_test,\n",
    "                                                                               y_train,\n",
    "                                                                               y_test,\n",
    "                                                                               CV)\n",
    "# Pickle results\n",
    "with open('/Users/greenapple/project3/models/logreg2_30_cls_scores_params_rand.pkl', 'wb') as f:\n",
    "    pickle.dump(logreg2_30_cls_scores_params, f)\n",
    "    \n",
    "# Pickle model\n",
    "with open('/Users/greenapple/project3/models/logreg2_30_cls_model_rand.pkl', 'wb') as f:\n",
    "    pickle.dump(logreg2_30_cls_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and fit logistic regression with  RandomizedSearchCV: 3rd set of parameteres\n",
    "from src.models import model_sel_rand_search\n",
    "\n",
    "# Function arguments:\n",
    "model = LogisticRegression(random_state=3, multi_class='multinomial')\n",
    "transformer = RandomOverSampler(random_state=3, sampling_strategy='minority')\n",
    "CV = 5\n",
    "\n",
    "# Function arguments: classifier params\n",
    "penalty = ['l2']\n",
    "C = np.logspace(0, 4, 10)\n",
    "solver = ['sag', 'lbfgs', 'newton-cg']\n",
    "\n",
    "param_distributions = dict(\n",
    "        model__C = C, \n",
    "        model__penalty = penalty,\n",
    "        model__solver=solver\n",
    ")\n",
    "\n",
    "# Call parameter selection function\n",
    "logreg3_30_cls_scores_params, logreg3_30_cls_model = model_sel_rand_search.train_fit_time(model,\n",
    "                                                                               param_distributions,\n",
    "                                                                               transformer,\n",
    "                                                                               X_train,\n",
    "                                                                               X_test,\n",
    "                                                                               y_train,\n",
    "                                                                               y_test,\n",
    "                                                                               CV)\n",
    "# Pickle results\n",
    "with open('/Users/greenapple/project3/models/logreg3_30_cls_scores_params_rand.pkl', 'wb') as f:\n",
    "    pickle.dump(logreg3_30_cls_scores_params, f)\n",
    "    \n",
    "# Pickle model\n",
    "with open('/Users/greenapple/project3/models/logreg3_30_cls_model_rand.pkl', 'wb') as f:\n",
    "    pickle.dump(logreg3_30_cls_model, f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpickle results\n",
    "unpicking_out = open('/Users/greenapple/project3/models/logreg3_30_cls_scores_params_rand.pkl', 'rb')\n",
    "logreg3_30_cls_scores_params = pickle.load(unpicking_out)\n",
    "logreg3_30_cls_scores_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpickle results\n",
    "unpicking_out = open('/Users/greenapple/project3/models/logreg3_30_cls_model_rand.pkl', 'rb')\n",
    "logreg3_30_cls_model = pickle.load(unpicking_out)\n",
    "logreg3_30_cls_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick best logreg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T04:08:58.711750Z",
     "start_time": "2019-10-19T04:08:58.704570Z"
    }
   },
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T22:44:05.517998Z",
     "start_time": "2019-10-21T22:43:22.018705Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train and fit KNN with  RandomizedSearchCV\n",
    "from src.models import model_sel_rand_search\n",
    "\n",
    "# Function arguments:\n",
    "model = KNeighborsClassifier()\n",
    "transformer = RandomOverSampler(random_state=3, sampling_strategy='minority')\n",
    "CV = 5\n",
    "\n",
    "# Function arguments: classifier params\n",
    "k_range = list(range(1, 10, 1))\n",
    "\n",
    "param_grid = dict(model__n_neighbors=k_range)\n",
    "\n",
    "# Call parameter selection function\n",
    "KNN_30_cls_scores_params, KNN_30_cls_model = model_sel_rand_search.train_fit_time(model,\n",
    "                                                                               param_grid,\n",
    "                                                                               transformer,\n",
    "                                                                               X_train,\n",
    "                                                                               X_test,\n",
    "                                                                               y_train,\n",
    "                                                                               y_test,\n",
    "                                                                               CV)\n",
    "\n",
    "# Pickle results\n",
    "with open('/Users/greenapple/project3/models/KNN_30_cls_scores_params_rand.pkl', 'wb') as f:\n",
    "    pickle.dump(KNN_30_cls_scores_params, f)\n",
    "    \n",
    "# Pickle model\n",
    "with open('/Users/greenapple/project3/models/KNN_30_cls_model_rand.pkl', 'wb') as f:\n",
    "    pickle.dump(KNN_30_cls_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpickle results\n",
    "unpicking_out = open('/Users/greenapple/project3/models/KNN_30_cls_scores_params_rand.pkl', 'rb')\n",
    "KNN_30_cls_scores_params = pickle.load(unpicking_out)\n",
    "KNN_30_cls_scores_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpickle results\n",
    "unpicking_out = open('/Users/greenapple/project3/models/KNN_30_cls_model_rand.pkl', 'rb')\n",
    "KNN_30_cls_model = pickle.load(unpicking_out)\n",
    "KNN_30_cls_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes MultiNomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T22:46:31.708756Z",
     "start_time": "2019-10-21T22:46:31.269131Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train and fit naive Bayes MultiNomial with RandomizedSearchCV\n",
    "from src.models import model_sel_rand_search\n",
    "\n",
    "# Function arguments:\n",
    "model = MultinomialNB()\n",
    "transformer = RandomOverSampler(random_state=3, sampling_strategy='minority')\n",
    "CV = 5\n",
    "\n",
    "# Function arguments: classifier params\n",
    "alphas = [1, 10, 100]\n",
    "# Selects the min alpha. Keep alpha = 1 to make sure the model can take data it has not seen before \n",
    "# from the test set.\n",
    "\n",
    "param_grid = dict(model__alpha=alphas)\n",
    "\n",
    "# Call parameter selection function\n",
    "NBmultinomial_30_cls_scores_params, NBmultinomial_30_cls_model = model_sel_rand_search.train_fit_time(model,\n",
    "                                                                               param_grid,\n",
    "                                                                               transformer,\n",
    "                                                                               X_train,\n",
    "                                                                               X_test,\n",
    "                                                                               y_train,\n",
    "                                                                               y_test,\n",
    "                                                                               CV)\n",
    "\n",
    "# Pickle results\n",
    "with open('/Users/greenapple/project3/models/NBmultinomial_30_cls_scores_params_rand.pkl', 'wb') as f:\n",
    "    pickle.dump(NBmultinomial_30_cls_scores_params, f)\n",
    "    \n",
    "# Pickle model\n",
    "with open('/Users/greenapple/project3/models/NBmultinomial_30_cls_model_rand.pkl', 'wb') as f:\n",
    "    pickle.dump(NBmultinomial_30_cls_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpickle results\n",
    "unpicking_out = open('/Users/greenapple/project3/models/NBmultinomial_30_cls_scores_params_rand.pkl', 'rb')\n",
    "NBmultinomial_30_cls_scores_params = pickle.load(unpicking_out)\n",
    "NBmultinomial_30_cls_scores_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpickle best model\n",
    "unpicking_out = open('/Users/greenapple/project3/models/NBmultinomial_30_cls_model_rand.pkl', 'rb')\n",
    "NBmultinomial_30_cls_model = pickle.load(unpicking_out)\n",
    "NBmultinomial_30_cls_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T23:20:52.968294Z",
     "start_time": "2019-10-21T22:48:22.725052Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train and fit SVC with RandomizedSearchCV\n",
    "from src.models import model_sel_rand_search\n",
    "\n",
    "# Function arguments:\n",
    "model = SVC(probability=True)\n",
    "transformer = RandomOverSampler(random_state=3, sampling_strategy='minority')\n",
    "CV = 5\n",
    "\n",
    "# Function arguments: classifier params\n",
    "kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "C = [0.001, 0.01, 0.1, 1, 10]\n",
    "gamma = [0.01, 0.1, 1, 10]\n",
    "degree = [2, 3, 4]\n",
    "\n",
    "param_grid = dict(model__C=C,\n",
    "                 model__kernel=kernel,\n",
    "                 model__gamma=gamma,\n",
    "                 model__degree=degree\n",
    "                 )\n",
    "\n",
    "# Call parameter selection function\n",
    "SVC_30_cls_scores_params, SVC_30_cls_model = model_sel_rand_search.train_fit_time(model,\n",
    "                                                                               param_grid,\n",
    "                                                                               transformer,\n",
    "                                                                               X_train,\n",
    "                                                                               X_test,\n",
    "                                                                               y_train,\n",
    "                                                                               y_test,\n",
    "                                                                               CV)\n",
    "\n",
    "# Pickle results\n",
    "with open('/Users/greenapple/project3/models/SVC_30_cls_scores_params_rand.pkl', 'wb') as f:\n",
    "    pickle.dump(SVC_30_cls_scores_params, f)\n",
    "    \n",
    "# Pickle model\n",
    "with open('/Users/greenapple/project3/models/SVC_30_cls_model_rand.pkl', 'wb') as f:\n",
    "    pickle.dump(SVC_30_cls_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpickle results\n",
    "unpicking_out = open('/Users/greenapple/project3/models/SVC_30_cls_scores_params_rand.pkl', 'rb')\n",
    "SVC_30_cls_scores_params = pickle.load(unpicking_out)\n",
    "SVC_30_cls_scores_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpickle model\n",
    "unpicking_out = open('/Users/greenapple/project3/models/SVC_30_cls_model_rand.pkl', 'rb')\n",
    "SVC_30_cls_model = pickle.load(unpicking_out)\n",
    "SVC_30_cls_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T06:52:24.564264Z",
     "start_time": "2019-10-22T06:09:22.157127Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train and fit Random Forest\n",
    "from src.models import model_sel_rand_search\n",
    "\n",
    "# Function arguments:\n",
    "model = RandomForestClassifier(random_state=3)\n",
    "transformer = RandomOverSampler(random_state=3, sampling_strategy='minority')\n",
    "CV = 5\n",
    "\n",
    "# Function arguments: classifier params\n",
    "n_estimators = [10, 50, 100, 300, 500]\n",
    "criterion = ['gini', 'entropy']\n",
    "max_depth = [5, 10, 50, 100, None]\n",
    "min_samples_split = [2, 5, 10, 50]\n",
    "max_features = [5, 10, 25, 50, 100]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "                \n",
    "param_grid = dict(model__n_estimators=n_estimators,\n",
    "                  model__criterion=criterion,\n",
    "                  model__max_depth=max_depth,\n",
    "                  model__min_samples_split=min_samples_split,\n",
    "                  model__max_features=max_features,\n",
    "                  model__bootstrap=bootstrap\n",
    "                 )\n",
    "\n",
    "# Call parameter selection function\n",
    "RF_30_cls_scores_params, RF_30_cls_model = model_sel_rand_search.train_fit_time(model,\n",
    "                                                                        param_grid,\n",
    "                                                                        transformer,\n",
    "                                                                        X_train,\n",
    "                                                                        X_test,\n",
    "                                                                        y_train,\n",
    "                                                                        y_test,\n",
    "                                                                        CV)\n",
    "\n",
    "# Pickle results\n",
    "with open('/Users/greenapple/project3/models/RF_30_cls_scores_params_rand.pkl', 'wb') as f:\n",
    "    pickle.dump(RF_30_cls_scores_params, f)\n",
    "    \n",
    "# Pickle model\n",
    "with open('/Users/greenapple/project3/models/RF_30_cls_model_rand.pkl', 'wb') as f:\n",
    "    pickle.dump(RF_30_cls_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpickle results\n",
    "unpicking_out = open('/Users/greenapple/project3/models/RF_30_cls_scores_params_rand.pkl', 'rb')\n",
    "RF_30_cls_scores_params = pickle.load(unpicking_out)\n",
    "RF_30_cls_scores_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpickle model\n",
    "unpicking_out = open('/Users/greenapple/project3/models/RF_30_cls_model_rand.pkl', 'rb')\n",
    "RF_30_cls_model = pickle.load(unpicking_out)\n",
    "RF_30_cls_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T07:00:45.462798Z",
     "start_time": "2019-10-22T06:52:24.566680Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train and fit Gradient Boosting\n",
    "from src.models import model_sel_rand_search\n",
    "\n",
    "# Function arguments:\n",
    "model = GradientBoostingClassifier(random_state=3)\n",
    "transformer = RandomOverSampler(random_state=3, sampling_strategy='minority')\n",
    "CV = 5\n",
    "\n",
    "# Function arguments: classifier params\n",
    "n_estimators = [50, 100, 300, 500]\n",
    "max_depth = [5, 10, 50, 100, None]\n",
    "min_samples_split = [2, 5, 10, 20, 50]\n",
    "max_features = [5, 10, 25, 50, 100]\n",
    "\n",
    "\n",
    "param_grid = dict(model__n_estimators=n_estimators,\n",
    "                  model__max_depth=max_depth,\n",
    "                  model__min_samples_split=min_samples_split,\n",
    "                  model__max_features=max_features,\n",
    "                 )\n",
    "\n",
    "# Call parameter selection function\n",
    "GBM_30_cls_scores_params, GBM_30_cls_model = model_sel_rand_search.train_fit_time(model,\n",
    "                                                                        param_grid,\n",
    "                                                                        transformer,\n",
    "                                                                        X_train,\n",
    "                                                                        X_test,\n",
    "                                                                        y_train,\n",
    "                                                                        y_test,\n",
    "                                                                        CV)\n",
    "\n",
    "# Pickle results\n",
    "with open('/Users/greenapple/project3/models/GBM_30_cls_scores_params_rand.pkl', 'wb') as f:\n",
    "    pickle.dump(GBM_30_cls_scores_params, f)\n",
    "    \n",
    "# Pickle model\n",
    "with open('/Users/greenapple/project3/models/GBM_30_cls_model_rand.pkl', 'wb') as f:\n",
    "    pickle.dump(GBM_30_cls_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpickle results\n",
    "unpicking_out = open('/Users/greenapple/project3/models/GBM_30_cls_scores_params_rand.pkl', 'rb')\n",
    "GBM_30_cls_scores_params = pickle.load(unpicking_out)\n",
    "GBM_30_cls_scores_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpickle model\n",
    "unpicking_out = open('/Users/greenapple/project3/models/GBM_30_cls_model_rand.pkl', 'rb')\n",
    "GBM_30_cls_model = pickle.load(unpicking_out)\n",
    "GBM_30_cls_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T00:07:18.304982Z",
     "start_time": "2019-10-22T00:07:18.048965Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train and fit Dummy classifier\n",
    "from src.models import model_sel_rand_search\n",
    "\n",
    "# Function arguments:\n",
    "model = DummyClassifier(random_state=3, strategy='stratified')\n",
    "transformer = RandomOverSampler(random_state=3, sampling_strategy='minority')\n",
    "CV = 5\n",
    "\n",
    "# Function arguments: classifier params\n",
    "\n",
    "param_grid = dict()\n",
    "\n",
    "# Call parameter selection function\n",
    "Dummy_30_cls_scores_params, Dummy_30_cls_model = model_sel_rand_search.train_fit_time(model,\n",
    "                                                                        param_grid,\n",
    "                                                                        transformer,\n",
    "                                                                        X_train,\n",
    "                                                                        X_test,\n",
    "                                                                        y_train,\n",
    "                                                                        y_test,\n",
    "                                                                        CV)\n",
    "\n",
    "# Pickle results\n",
    "with open('/Users/greenapple/project3/models/Dummy_30_cls_scores_params_rand.pkl', 'wb') as f:\n",
    "    pickle.dump(Dummy_30_cls_scores_params, f)\n",
    "    \n",
    "# Pickle model\n",
    "with open('/Users/greenapple/project3/models/Dummy_30_cls_model_rand.pkl', 'wb') as f:\n",
    "    pickle.dump(Dummy_30_cls_scores_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T00:07:29.791703Z",
     "start_time": "2019-10-22T00:07:29.707075Z"
    }
   },
   "outputs": [],
   "source": [
    "Dummy_30_cls_scores_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T00:07:45.861782Z",
     "start_time": "2019-10-22T00:07:45.782856Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dummy classifier\n",
    "dummy = DummyClassifier()\n",
    "dummy.fit(X_train, y_train)\n",
    "f1_dummy = f1_score(y_test, dummy.predict(X_test), average='micro')\n",
    "accuracy_dummy = accuracy_score(y_test, dummy.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T00:07:46.368892Z",
     "start_time": "2019-10-22T00:07:46.285594Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Dummy classifier F1 score: ', f1_dummy)\n",
    "print('Dummy classifier accuracy score: ', accuracy_dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "%config InlineBackend.figure_formats = ['retina']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [\n",
    "    ('logreg', logreg_30_cls_model),\n",
    "    ('KNN', KNN_30_cls_models_rand),\n",
    "    ('NBmultinomial', NBmultinomial_30_cls_model),\n",
    "    ('SVC', SVC_30_cls_model),\n",
    "    ('RF', RF_30_cls_model),\n",
    "    ('GBM', GBM_30_cls_model)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max voting classifier\n",
    "\n",
    "# Max voting classifier\n",
    "average_voting_classifer = VotingClassifier(estimators=model_list,\n",
    "                                    voting='hard',\n",
    "                                    n_jobs=-1)\n",
    "\n",
    "f1_train = cross_val_score(max_voting_classifer, \n",
    "            X_train, y_train, scoring='f1_micro', cv=5).mean()\n",
    "\n",
    "max_voting_classifer.fit(X_train, y_train)\n",
    "y_hat = max_voting_classifer.predict(X_test) \n",
    "\n",
    "f1_test = f1_score(y_test, y_hat, average='micro')\n",
    "# f1_test_s = f1_score(y_test, y_hat, average='samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_train, f1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average voting classifier\n",
    "average_voting_classifer = VotingClassifier(estimators=model_list,\n",
    "                                    voting='soft',\n",
    "                                    n_jobs=-1)\n",
    "\n",
    "f1_train = cross_val_score(max_voting_classifer, \n",
    "            X_train, y_train, scoring='f1_micro', cv=5).mean()\n",
    "\n",
    "max_voting_classifer.fit(X_train, y_train)\n",
    "y_hat = max_voting_classifer.predict(X_test) \n",
    "\n",
    "f1_test = f1_score(y_test, y_hat, average='micro')\n",
    "# f1_test_s = f1_score(y_test, y_hat, average='samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_train, f1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacked classifier\n",
    "model = logreg_2_cls_model\n",
    "\n",
    "stacked_classifier = StackingClassifier(classifiers=model_list, \n",
    "                                        meta_classifier=model, \n",
    "                                        use_probas=False)\n",
    "\n",
    "\n",
    "f1_train = cross_val_score(max_voting_classifer, \n",
    "            X_train, y_train, scoring='f1_micro', cv=5).mean()\n",
    "\n",
    "max_voting_classifer.fit(X_train, y_train)\n",
    "y_hat = max_voting_classifer.predict(X_test) \n",
    "\n",
    "f1_test = f1_score(y_test, y_hat, average='micro')\n",
    "# f1_test_s = f1_score(y_test, y_hat, average='samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_train, f1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list of tuples onto a dictionary\n",
    "classifier_list = [x[1] for x in model_list]\n",
    "classifier_names = [x[0] for x in model_list]\n",
    "classifier_dict = dict(zip(classifier_names, classifier_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name, classifier in classifier_dict.items():\n",
    "    \n",
    "    # Stacked classifier\n",
    "    model = classifier\n",
    "\n",
    "    stacked_classifier = StackingClassifier(classifiers=model_list, \n",
    "                                        meta_classifier=model, \n",
    "                                        use_probas=False)\n",
    "\n",
    "\n",
    "    f1_train = cross_val_score(max_voting_classifer, \n",
    "            X_train, y_train, scoring='f1_micro', cv=5).mean()\n",
    "\n",
    "    max_voting_classifer.fit(X_train, y_train)\n",
    "    y_hat = max_voting_classifer.predict(X_test) \n",
    "\n",
    "    f1_test = f1_score(y_test, y_hat, average='micro')\n",
    "    # f1_test_s = f1_score(y_test, y_hat, average='samples')\n",
    "    \n",
    "    print(name, f1_train, f1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T00:08:32.095083Z",
     "start_time": "2019-10-22T00:08:32.017383Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T00:08:32.523590Z",
     "start_time": "2019-10-22T00:08:32.381869Z"
    }
   },
   "outputs": [],
   "source": [
    "null_accuracy = y_test.value_counts().head(1) / len(y_test)\n",
    "print('Null accuracy: ', null_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T00:21:38.099861Z",
     "start_time": "2019-10-22T00:21:38.018427Z"
    }
   },
   "outputs": [],
   "source": [
    "model_score_table = pd.DataFrame(columns=['Models', 'F1_score_train'])\n",
    "model_score_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T00:21:40.108964Z",
     "start_time": "2019-10-22T00:21:40.037780Z"
    }
   },
   "outputs": [],
   "source": [
    "model_score_table['Models'] = ['Logistis_Regression',\n",
    "                              'KNN',\n",
    "                              'Multinomial_NB',\n",
    "                              'SVC_poly',\n",
    "                              'Random_Forest',\n",
    "                               'GBM',\n",
    "                               'Dummy'\n",
    "                              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T00:23:29.707450Z",
     "start_time": "2019-10-22T00:23:29.642848Z"
    }
   },
   "outputs": [],
   "source": [
    "model_score_table['F1_score_train'] = trainin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T00:23:33.700648Z",
     "start_time": "2019-10-22T00:23:33.629584Z"
    }
   },
   "outputs": [],
   "source": [
    "model_score_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T00:31:20.145737Z",
     "start_time": "2019-10-22T00:31:20.084893Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pickle results\n",
    "with open('/Users/greenapple/project3/reports/figures/model_score_table_MVP.pkl', 'wb') as f:\n",
    "    pickle.dump(model_score_table, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for printing confusion matrices (see: https://gist.github.com/shaypal5/94c53d765083101efc0240d776a23823)\n",
    "\n",
    "# prints confusion matrix as a heatmap which is nicer to visaulize\n",
    "\n",
    "def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=18):\n",
    "    \"\"\"Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a heatmap.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    confusion_matrix: numpy.ndarray\n",
    "        The numpy.ndarray object returned from a call to sklearn.metrics.confusion_matrix. \n",
    "        Similarly constructed ndarrays can also be used.\n",
    "    class_names: list\n",
    "        An ordered list of class names, in the order they index the given confusion matrix.\n",
    "    figsize: tuple\n",
    "        A 2-long tuple, the first value determining the horizontal size of the ouputted figure,\n",
    "        the second determining the vertical size. Defaults to (10,7).\n",
    "    fontsize: int\n",
    "        Font size for axes labels. Defaults to 14.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.figure.Figure\n",
    "        The resulting confusion matrix figure\n",
    "    \"\"\"\n",
    "    df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names, )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "cm = print_confusion_matrix(conf_mat, ['Class 0', 'Class 1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model for later\n",
    "filename = /Users/greenapple/project3/models/logreg.sav'\n",
    "joblib.dump(logreg, filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project3",
   "language": "python",
   "name": "project3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "287.986px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
