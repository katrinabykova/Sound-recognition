{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T03:19:42.048246Z",
     "start_time": "2019-10-23T03:19:39.490133Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "import sklearn\n",
    "from skmultilearn.ensemble import MajorityVotingClassifier\n",
    "from sklearn import linear_model, svm, naive_bayes, neighbors, ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T03:19:53.829740Z",
     "start_time": "2019-10-23T03:19:53.738274Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data formatting for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T21:42:44.044884Z",
     "start_time": "2019-10-21T21:42:43.906458Z"
    }
   },
   "outputs": [],
   "source": [
    "# Unpickle data \n",
    "with open('/Users/greenapple/project3/data/processed/house_bal.pkl', 'rb') as f:\n",
    "    house_bal = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T21:42:45.143726Z",
     "start_time": "2019-10-21T21:42:45.027403Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id_list</th>\n",
       "      <th>y</th>\n",
       "      <th>y_name</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>630</th>\n",
       "      <th>631</th>\n",
       "      <th>632</th>\n",
       "      <th>633</th>\n",
       "      <th>634</th>\n",
       "      <th>635</th>\n",
       "      <th>636</th>\n",
       "      <th>637</th>\n",
       "      <th>638</th>\n",
       "      <th>639</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>b'--ZhevVpy1s'</td>\n",
       "      <td>375</td>\n",
       "      <td>toothbrush</td>\n",
       "      <td>117</td>\n",
       "      <td>35</td>\n",
       "      <td>163</td>\n",
       "      <td>90</td>\n",
       "      <td>198</td>\n",
       "      <td>103</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>202</td>\n",
       "      <td>9</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>247</td>\n",
       "      <td>72</td>\n",
       "      <td>44</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>b'-2hQKCE-oTI'</td>\n",
       "      <td>53</td>\n",
       "      <td>footsteps</td>\n",
       "      <td>30</td>\n",
       "      <td>162</td>\n",
       "      <td>44</td>\n",
       "      <td>7</td>\n",
       "      <td>216</td>\n",
       "      <td>116</td>\n",
       "      <td>206</td>\n",
       "      <td>...</td>\n",
       "      <td>213</td>\n",
       "      <td>109</td>\n",
       "      <td>50</td>\n",
       "      <td>88</td>\n",
       "      <td>19</td>\n",
       "      <td>46</td>\n",
       "      <td>54</td>\n",
       "      <td>154</td>\n",
       "      <td>42</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>b'-3pPrlCm6gg'</td>\n",
       "      <td>198</td>\n",
       "      <td>clarinet</td>\n",
       "      <td>179</td>\n",
       "      <td>190</td>\n",
       "      <td>122</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>58</td>\n",
       "      <td>15</td>\n",
       "      <td>207</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>43</td>\n",
       "      <td>97</td>\n",
       "      <td>57</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>b'-70wVF5u-gg'</td>\n",
       "      <td>366</td>\n",
       "      <td>chopping_food</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>186</td>\n",
       "      <td>34</td>\n",
       "      <td>87</td>\n",
       "      <td>250</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>144</td>\n",
       "      <td>63</td>\n",
       "      <td>110</td>\n",
       "      <td>255</td>\n",
       "      <td>139</td>\n",
       "      <td>138</td>\n",
       "      <td>59</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>b'-ASYwidRD7M'</td>\n",
       "      <td>43</td>\n",
       "      <td>snoring</td>\n",
       "      <td>53</td>\n",
       "      <td>100</td>\n",
       "      <td>144</td>\n",
       "      <td>84</td>\n",
       "      <td>223</td>\n",
       "      <td>68</td>\n",
       "      <td>95</td>\n",
       "      <td>...</td>\n",
       "      <td>56</td>\n",
       "      <td>78</td>\n",
       "      <td>153</td>\n",
       "      <td>65</td>\n",
       "      <td>208</td>\n",
       "      <td>207</td>\n",
       "      <td>200</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 643 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     video_id_list    y         y_name    0    1    2   3    4    5    6  ...  \\\n",
       "5   b'--ZhevVpy1s'  375     toothbrush  117   35  163  90  198  103   63  ...   \n",
       "20  b'-2hQKCE-oTI'   53      footsteps   30  162   44   7  216  116  206  ...   \n",
       "28  b'-3pPrlCm6gg'  198       clarinet  179  190  122  19    0  114  255  ...   \n",
       "63  b'-70wVF5u-gg'  366  chopping_food    0  114  186  34   87  250   58  ...   \n",
       "82  b'-ASYwidRD7M'   43        snoring   53  100  144  84  223   68   95  ...   \n",
       "\n",
       "    630  631  632  633  634  635  636  637  638  639  \n",
       "5     0    1  202    9  116    0  247   72   44  166  \n",
       "20  213  109   50   88   19   46   54  154   42  211  \n",
       "28   58   15  207    0  108   43   97   57   42    0  \n",
       "63    0  122  144   63  110  255  139  138   59  154  \n",
       "82   56   78  153   65  208  207  200  255  255   66  \n",
       "\n",
       "[5 rows x 643 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_bal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T21:54:45.418679Z",
     "start_time": "2019-10-21T21:54:45.351730Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45717, 643)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_bal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T21:54:47.455479Z",
     "start_time": "2019-10-21T21:54:47.377778Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(house_bal.y_name.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T21:42:48.338390Z",
     "start_time": "2019-10-21T21:42:48.259512Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speech            4042\n",
       "music             3781\n",
       "laughter          3772\n",
       "snoring           3370\n",
       "vacuum_cleaner    3054\n",
       "typing            2644\n",
       "dishes_pots       2560\n",
       "frying_food       2102\n",
       "blender           1884\n",
       "toilet_flush      1882\n",
       "door              1868\n",
       "whoop             1736\n",
       "footsteps         1492\n",
       "baby_cry          1414\n",
       "screeming         1116\n",
       "whispering         972\n",
       "clarinet           960\n",
       "crying             918\n",
       "microwave          894\n",
       "television         866\n",
       "hair_dryer         772\n",
       "video_games        592\n",
       "shaving            552\n",
       "bathtab            472\n",
       "water_tap          458\n",
       "chopping_food      410\n",
       "meow               388\n",
       "dog                358\n",
       "purr               304\n",
       "toothbrush          84\n",
       "Name: y_name, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_bal.y_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T21:54:52.146318Z",
     "start_time": "2019-10-21T21:54:52.074896Z"
    }
   },
   "outputs": [],
   "source": [
    "two_class_list = [\n",
    "    'footsteps',\n",
    "    'purr'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T21:54:52.572722Z",
     "start_time": "2019-10-21T21:54:52.468736Z"
    }
   },
   "outputs": [],
   "source": [
    "house_2_classes = house_bal.loc[house_bal.y_name.isin(two_class_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T21:54:53.500586Z",
     "start_time": "2019-10-21T21:54:53.427247Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1796, 643)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_2_classes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T21:54:55.918308Z",
     "start_time": "2019-10-21T21:54:55.834689Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id_list</th>\n",
       "      <th>y</th>\n",
       "      <th>y_name</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>630</th>\n",
       "      <th>631</th>\n",
       "      <th>632</th>\n",
       "      <th>633</th>\n",
       "      <th>634</th>\n",
       "      <th>635</th>\n",
       "      <th>636</th>\n",
       "      <th>637</th>\n",
       "      <th>638</th>\n",
       "      <th>639</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>b'-2hQKCE-oTI'</td>\n",
       "      <td>53</td>\n",
       "      <td>footsteps</td>\n",
       "      <td>30</td>\n",
       "      <td>162</td>\n",
       "      <td>44</td>\n",
       "      <td>7</td>\n",
       "      <td>216</td>\n",
       "      <td>116</td>\n",
       "      <td>206</td>\n",
       "      <td>...</td>\n",
       "      <td>213</td>\n",
       "      <td>109</td>\n",
       "      <td>50</td>\n",
       "      <td>88</td>\n",
       "      <td>19</td>\n",
       "      <td>46</td>\n",
       "      <td>54</td>\n",
       "      <td>154</td>\n",
       "      <td>42</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>b'-G_hnfp4a0M'</td>\n",
       "      <td>53</td>\n",
       "      <td>footsteps</td>\n",
       "      <td>141</td>\n",
       "      <td>93</td>\n",
       "      <td>96</td>\n",
       "      <td>107</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>220</td>\n",
       "      <td>...</td>\n",
       "      <td>250</td>\n",
       "      <td>104</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>12</td>\n",
       "      <td>234</td>\n",
       "      <td>61</td>\n",
       "      <td>81</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>b'-IWlQN6cfe4'</td>\n",
       "      <td>53</td>\n",
       "      <td>footsteps</td>\n",
       "      <td>78</td>\n",
       "      <td>146</td>\n",
       "      <td>188</td>\n",
       "      <td>30</td>\n",
       "      <td>200</td>\n",
       "      <td>44</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>96</td>\n",
       "      <td>33</td>\n",
       "      <td>255</td>\n",
       "      <td>83</td>\n",
       "      <td>228</td>\n",
       "      <td>123</td>\n",
       "      <td>120</td>\n",
       "      <td>58</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>281</td>\n",
       "      <td>b'-blH_CYo09w'</td>\n",
       "      <td>53</td>\n",
       "      <td>footsteps</td>\n",
       "      <td>190</td>\n",
       "      <td>217</td>\n",
       "      <td>227</td>\n",
       "      <td>113</td>\n",
       "      <td>96</td>\n",
       "      <td>140</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>163</td>\n",
       "      <td>45</td>\n",
       "      <td>183</td>\n",
       "      <td>31</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>562</td>\n",
       "      <td>b'0EsJvIfMx0w'</td>\n",
       "      <td>53</td>\n",
       "      <td>footsteps</td>\n",
       "      <td>50</td>\n",
       "      <td>106</td>\n",
       "      <td>202</td>\n",
       "      <td>91</td>\n",
       "      <td>186</td>\n",
       "      <td>156</td>\n",
       "      <td>46</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "      <td>140</td>\n",
       "      <td>214</td>\n",
       "      <td>143</td>\n",
       "      <td>47</td>\n",
       "      <td>100</td>\n",
       "      <td>14</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 643 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id_list   y     y_name    0    1    2    3    4    5    6  ...  \\\n",
       "20   b'-2hQKCE-oTI'  53  footsteps   30  162   44    7  216  116  206  ...   \n",
       "138  b'-G_hnfp4a0M'  53  footsteps  141   93   96  107  139    0  220  ...   \n",
       "150  b'-IWlQN6cfe4'  53  footsteps   78  146  188   30  200   44  120  ...   \n",
       "281  b'-blH_CYo09w'  53  footsteps  190  217  227  113   96  140   43  ...   \n",
       "562  b'0EsJvIfMx0w'  53  footsteps   50  106  202   91  186  156   46  ...   \n",
       "\n",
       "     630  631  632  633  634  635  636  637  638  639  \n",
       "20   213  109   50   88   19   46   54  154   42  211  \n",
       "138  250  104   46    0   98   12  234   61   81  133  \n",
       "150  130   96   33  255   83  228  123  120   58  236  \n",
       "281  255  255  163   45  183   31   39    0   54  196  \n",
       "562   42    4   58  140  214  143   47  100   14  255  \n",
       "\n",
       "[5 rows x 643 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_2_classes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T21:54:58.897190Z",
     "start_time": "2019-10-21T21:54:58.821596Z"
    }
   },
   "outputs": [],
   "source": [
    "# Assign features X and target y\n",
    "X = house_2_classes[house_2_classes.columns[3:643]]\n",
    "y = house_2_classes.y_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T22:31:17.554240Z",
     "start_time": "2019-10-21T22:31:17.445930Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1436, 640), (1436,), (360, 640), (360,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T21:55:01.467769Z",
     "start_time": "2019-10-21T21:55:01.397919Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['random_state', 'ratio', 'return_indices', 'sampling_strategy'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look up attributes\n",
    "RandomOverSampler('self').get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and evaluate models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T17:35:29.887767Z",
     "start_time": "2019-10-19T17:35:29.883261Z"
    }
   },
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fldr = '/Users/greenapple/project3/models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Train and fit logistic regression with  RandomizedSearchCV:  1st set of parameteres\n",
    "from src.models import model_sel_rand_search\n",
    "\n",
    "# Function arguments:\n",
    "model = LogisticRegression(random_state=3)\n",
    "transformer = RandomOverSampler(random_state=3, sampling_strategy='minority')\n",
    "CV = 5\n",
    "\n",
    "# Function arguments: classifier params\n",
    "penalty = ['l1', 'l2']\n",
    "C = np.logspace(0, 4, 10)\n",
    "solver = ['liblinear', 'saga']\n",
    "\n",
    "param_distributions = dict(\n",
    "        model__C = C, \n",
    "        model__penalty = penalty,\n",
    "        model__solver=solver)\n",
    "\n",
    "# Call parameter selection function\n",
    "logreg1_2_cls_scores_params, logreg1_2_cls_model = model_sel_rand_search.train_fit_time(model,\n",
    "                                                                               param_distributions,\n",
    "                                                                               transformer,\n",
    "                                                                               X_train,\n",
    "                                                                               X_test,\n",
    "                                                                               y_train,\n",
    "                                                                               y_test,\n",
    "                                                                               CV)\n",
    "# Pickle results\n",
    "with open(os.path.join(model_fldr, 'logreg1_2_cls_scores_params_rand.pkl'), 'wb') as f:\n",
    "    pickle.dump(logreg1_2_cls_scores_params, f)\n",
    "    \n",
    "# Pickle model\n",
    "with open(os.path.join(model_fldr, 'logreg1_2_cls_model_rand.pkl'), 'wb') as f:\n",
    "    pickle.dump(logreg1_2_cls_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_train_score': 0.9178272980501393,\n",
       " 'best_test_score': 0.9055555555555556,\n",
       " 'time_sec': 28.675217,\n",
       " 'time_best_fit_sec': 1.0755522,\n",
       " 'best_params': {'model__solver': 'saga',\n",
       "  'model__penalty': 'l1',\n",
       "  'model__C': 1.0},\n",
       " 'best_estimator': Pipeline(memory=None,\n",
       "          steps=[('transformer',\n",
       "                  RandomOverSampler(random_state=3, ratio=None,\n",
       "                                    return_indices=False,\n",
       "                                    sampling_strategy='minority')),\n",
       "                 ('model',\n",
       "                  LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                     fit_intercept=True, intercept_scaling=1,\n",
       "                                     l1_ratio=None, max_iter=100,\n",
       "                                     multi_class='warn', n_jobs=None,\n",
       "                                     penalty='l1', random_state=3, solver='saga',\n",
       "                                     tol=0.0001, verbose=0, warm_start=False))],\n",
       "          verbose=False),\n",
       " 'best_test_proba': array([[6.97127382e-03, 9.93028726e-01],\n",
       "        [5.00006885e-01, 4.99993115e-01],\n",
       "        [9.99412760e-01, 5.87240136e-04],\n",
       "        [9.45626549e-01, 5.43734506e-02],\n",
       "        [9.99426796e-01, 5.73204313e-04],\n",
       "        [9.98351186e-01, 1.64881355e-03],\n",
       "        [9.99946708e-01, 5.32918640e-05],\n",
       "        [1.00000000e+00, 1.01202245e-10],\n",
       "        [9.99395311e-01, 6.04689307e-04],\n",
       "        [3.97839428e-09, 9.99999996e-01],\n",
       "        [9.77889174e-01, 2.21108263e-02],\n",
       "        [9.93517879e-01, 6.48212090e-03],\n",
       "        [9.99983582e-01, 1.64182399e-05],\n",
       "        [9.99999789e-01, 2.11439271e-07],\n",
       "        [9.99101560e-01, 8.98440334e-04],\n",
       "        [9.99513233e-01, 4.86766898e-04],\n",
       "        [6.93123254e-01, 3.06876746e-01],\n",
       "        [1.00000000e+00, 2.91104360e-10],\n",
       "        [9.65526429e-01, 3.44735710e-02],\n",
       "        [1.72923143e-01, 8.27076857e-01],\n",
       "        [9.99999983e-01, 1.67301031e-08],\n",
       "        [3.93944202e-02, 9.60605580e-01],\n",
       "        [9.99999908e-01, 9.19895086e-08],\n",
       "        [9.99952524e-01, 4.74760644e-05],\n",
       "        [9.99640225e-01, 3.59775318e-04],\n",
       "        [9.99863847e-01, 1.36153221e-04],\n",
       "        [9.99570096e-01, 4.29903996e-04],\n",
       "        [9.94783862e-01, 5.21613846e-03],\n",
       "        [9.99726932e-01, 2.73068400e-04],\n",
       "        [9.99725984e-01, 2.74015558e-04],\n",
       "        [5.36813865e-01, 4.63186135e-01],\n",
       "        [9.99945955e-01, 5.40447573e-05],\n",
       "        [9.13654757e-01, 8.63452434e-02],\n",
       "        [9.99554424e-01, 4.45576075e-04],\n",
       "        [4.60485044e-05, 9.99953951e-01],\n",
       "        [9.99361691e-01, 6.38308656e-04],\n",
       "        [9.99999951e-01, 4.91480479e-08],\n",
       "        [9.99999815e-01, 1.85019229e-07],\n",
       "        [9.99999655e-01, 3.45053865e-07],\n",
       "        [5.49074003e-01, 4.50925997e-01],\n",
       "        [1.00000000e+00, 2.51308481e-10],\n",
       "        [9.99587219e-01, 4.12780584e-04],\n",
       "        [9.99886061e-01, 1.13938560e-04],\n",
       "        [4.85275316e-01, 5.14724684e-01],\n",
       "        [2.49629800e-01, 7.50370200e-01],\n",
       "        [6.98395957e-04, 9.99301604e-01],\n",
       "        [9.99999849e-01, 1.51327178e-07],\n",
       "        [4.10274231e-01, 5.89725769e-01],\n",
       "        [9.99972002e-01, 2.79977619e-05],\n",
       "        [9.99999697e-01, 3.02540214e-07],\n",
       "        [2.95214020e-03, 9.97047860e-01],\n",
       "        [9.99982949e-01, 1.70512778e-05],\n",
       "        [9.14938344e-01, 8.50616563e-02],\n",
       "        [9.99091963e-01, 9.08036788e-04],\n",
       "        [9.99967802e-01, 3.21979804e-05],\n",
       "        [9.95540242e-01, 4.45975805e-03],\n",
       "        [9.99996839e-01, 3.16100040e-06],\n",
       "        [9.99258708e-01, 7.41291727e-04],\n",
       "        [9.99999868e-01, 1.31510760e-07],\n",
       "        [9.99927114e-01, 7.28861570e-05],\n",
       "        [9.99908620e-01, 9.13797931e-05],\n",
       "        [9.99999716e-01, 2.83967627e-07],\n",
       "        [1.09343203e-02, 9.89065680e-01],\n",
       "        [9.66283851e-01, 3.37161487e-02],\n",
       "        [1.59286947e-04, 9.99840713e-01],\n",
       "        [9.90342651e-01, 9.65734912e-03],\n",
       "        [9.99971160e-01, 2.88402256e-05],\n",
       "        [9.99997863e-01, 2.13728202e-06],\n",
       "        [9.99999512e-01, 4.88314909e-07],\n",
       "        [9.99716472e-01, 2.83527525e-04],\n",
       "        [9.96794550e-01, 3.20545043e-03],\n",
       "        [6.54719249e-01, 3.45280751e-01],\n",
       "        [9.99984225e-01, 1.57745708e-05],\n",
       "        [9.99757775e-01, 2.42224603e-04],\n",
       "        [9.99561164e-01, 4.38836155e-04],\n",
       "        [2.38979053e-03, 9.97610209e-01],\n",
       "        [3.88979433e-01, 6.11020567e-01],\n",
       "        [9.79277864e-01, 2.07221356e-02],\n",
       "        [9.99999984e-01, 1.62638783e-08],\n",
       "        [9.99914484e-01, 8.55162834e-05],\n",
       "        [9.99980890e-01, 1.91098946e-05],\n",
       "        [9.98943333e-01, 1.05666665e-03],\n",
       "        [2.37503130e-02, 9.76249687e-01],\n",
       "        [9.99999971e-01, 2.89167235e-08],\n",
       "        [9.99094317e-01, 9.05682656e-04],\n",
       "        [9.99999973e-01, 2.67613410e-08],\n",
       "        [9.99642846e-01, 3.57153994e-04],\n",
       "        [9.99998759e-01, 1.24056638e-06],\n",
       "        [9.99389338e-01, 6.10661779e-04],\n",
       "        [9.98977542e-01, 1.02245769e-03],\n",
       "        [1.93366582e-02, 9.80663342e-01],\n",
       "        [9.94657793e-01, 5.34220694e-03],\n",
       "        [2.16979402e-07, 9.99999783e-01],\n",
       "        [9.99993292e-01, 6.70766938e-06],\n",
       "        [9.99993075e-01, 6.92482845e-06],\n",
       "        [9.98747996e-01, 1.25200376e-03],\n",
       "        [2.10286053e-02, 9.78971395e-01],\n",
       "        [9.99982101e-01, 1.78985686e-05],\n",
       "        [1.00000000e+00, 4.15995485e-10],\n",
       "        [9.99993547e-01, 6.45282828e-06],\n",
       "        [9.99996534e-01, 3.46595137e-06],\n",
       "        [9.99997456e-01, 2.54363575e-06],\n",
       "        [9.99989688e-01, 1.03123922e-05],\n",
       "        [8.70386396e-01, 1.29613604e-01],\n",
       "        [9.99971426e-01, 2.85743653e-05],\n",
       "        [9.99989795e-01, 1.02045348e-05],\n",
       "        [9.99999807e-01, 1.92618508e-07],\n",
       "        [9.97593140e-01, 2.40685951e-03],\n",
       "        [9.33827787e-04, 9.99066172e-01],\n",
       "        [8.95784048e-01, 1.04215952e-01],\n",
       "        [9.99974476e-01, 2.55243994e-05],\n",
       "        [9.63815398e-01, 3.61846018e-02],\n",
       "        [9.99986258e-01, 1.37416979e-05],\n",
       "        [9.99231123e-01, 7.68877248e-04],\n",
       "        [1.60826996e-01, 8.39173004e-01],\n",
       "        [9.99829836e-01, 1.70164464e-04],\n",
       "        [9.97223914e-01, 2.77608564e-03],\n",
       "        [2.37550171e-01, 7.62449829e-01],\n",
       "        [5.45958526e-01, 4.54041474e-01],\n",
       "        [9.98811085e-01, 1.18891482e-03],\n",
       "        [9.78786009e-01, 2.12139905e-02],\n",
       "        [7.83474416e-01, 2.16525584e-01],\n",
       "        [9.63232301e-01, 3.67676991e-02],\n",
       "        [9.83531633e-02, 9.01646837e-01],\n",
       "        [9.99800473e-01, 1.99526607e-04],\n",
       "        [4.51758768e-01, 5.48241232e-01],\n",
       "        [2.74900818e-01, 7.25099182e-01],\n",
       "        [9.97455960e-01, 2.54404014e-03],\n",
       "        [1.64246059e-01, 8.35753941e-01],\n",
       "        [9.85481666e-01, 1.45183337e-02],\n",
       "        [9.90139209e-01, 9.86079133e-03],\n",
       "        [9.47035756e-01, 5.29642443e-02],\n",
       "        [9.99998047e-01, 1.95299457e-06],\n",
       "        [9.99969509e-01, 3.04914587e-05],\n",
       "        [9.99999525e-01, 4.75349041e-07],\n",
       "        [9.99995712e-01, 4.28818738e-06],\n",
       "        [9.61189341e-01, 3.88106587e-02],\n",
       "        [9.95662879e-01, 4.33712069e-03],\n",
       "        [9.99906739e-01, 9.32610345e-05],\n",
       "        [9.99999986e-01, 1.40866818e-08],\n",
       "        [9.96318835e-01, 3.68116534e-03],\n",
       "        [9.99738570e-01, 2.61430217e-04],\n",
       "        [3.96232750e-02, 9.60376725e-01],\n",
       "        [9.88875449e-01, 1.11245514e-02],\n",
       "        [9.99985620e-01, 1.43797171e-05],\n",
       "        [9.99204157e-01, 7.95843428e-04],\n",
       "        [9.99139721e-01, 8.60278932e-04],\n",
       "        [9.99424021e-01, 5.75979487e-04],\n",
       "        [9.99988273e-01, 1.17273619e-05],\n",
       "        [9.99991503e-01, 8.49716618e-06],\n",
       "        [9.99997610e-01, 2.39012049e-06],\n",
       "        [9.99991237e-01, 8.76315103e-06],\n",
       "        [4.79838701e-03, 9.95201613e-01],\n",
       "        [9.99978700e-01, 2.13000749e-05],\n",
       "        [9.99999591e-01, 4.09330963e-07],\n",
       "        [9.99963515e-01, 3.64848912e-05],\n",
       "        [8.56422833e-02, 9.14357717e-01],\n",
       "        [5.50231410e-01, 4.49768590e-01],\n",
       "        [9.99600845e-01, 3.99154597e-04],\n",
       "        [8.58116654e-01, 1.41883346e-01],\n",
       "        [9.99919328e-01, 8.06716069e-05],\n",
       "        [9.99227583e-01, 7.72417281e-04],\n",
       "        [9.99289033e-01, 7.10967182e-04],\n",
       "        [9.99999923e-01, 7.73437034e-08],\n",
       "        [4.70440289e-02, 9.52955971e-01],\n",
       "        [9.99760938e-01, 2.39061766e-04],\n",
       "        [9.99986992e-01, 1.30081565e-05],\n",
       "        [9.99999990e-01, 1.02466707e-08],\n",
       "        [4.63513758e-04, 9.99536486e-01],\n",
       "        [2.29590405e-01, 7.70409595e-01],\n",
       "        [6.36606073e-04, 9.99363394e-01],\n",
       "        [9.71147565e-01, 2.88524349e-02],\n",
       "        [9.99999900e-01, 9.99596180e-08],\n",
       "        [1.52962822e-01, 8.47037178e-01],\n",
       "        [9.85074535e-01, 1.49254650e-02],\n",
       "        [9.99999314e-01, 6.85710808e-07],\n",
       "        [9.90451826e-01, 9.54817370e-03],\n",
       "        [8.39580233e-01, 1.60419767e-01],\n",
       "        [9.39833058e-03, 9.90601669e-01],\n",
       "        [9.99997015e-01, 2.98543821e-06],\n",
       "        [5.49122126e-01, 4.50877874e-01],\n",
       "        [9.98527917e-01, 1.47208342e-03],\n",
       "        [9.90060590e-01, 9.93941038e-03],\n",
       "        [9.47995454e-01, 5.20045458e-02],\n",
       "        [9.99706104e-01, 2.93896187e-04],\n",
       "        [1.00000000e+00, 3.25817984e-10],\n",
       "        [9.99987287e-01, 1.27129101e-05],\n",
       "        [3.55534135e-09, 9.99999996e-01],\n",
       "        [9.85044912e-01, 1.49550880e-02],\n",
       "        [9.99999880e-01, 1.19854994e-07],\n",
       "        [9.99987171e-01, 1.28287080e-05],\n",
       "        [9.99999015e-01, 9.84854758e-07],\n",
       "        [9.99998758e-01, 1.24214471e-06],\n",
       "        [9.99963025e-01, 3.69746269e-05],\n",
       "        [9.99999734e-01, 2.66097078e-07],\n",
       "        [9.75837253e-01, 2.41627469e-02],\n",
       "        [9.99999400e-01, 5.99515016e-07],\n",
       "        [9.99616729e-01, 3.83270913e-04],\n",
       "        [3.81197555e-03, 9.96188024e-01],\n",
       "        [4.55527540e-01, 5.44472460e-01],\n",
       "        [9.99999582e-01, 4.18469568e-07],\n",
       "        [7.15560964e-07, 9.99999284e-01],\n",
       "        [9.99916414e-01, 8.35857281e-05],\n",
       "        [9.92660385e-01, 7.33961499e-03],\n",
       "        [9.99999560e-01, 4.40476948e-07],\n",
       "        [9.88549226e-01, 1.14507736e-02],\n",
       "        [9.99920212e-01, 7.97879981e-05],\n",
       "        [8.66019341e-02, 9.13398066e-01],\n",
       "        [6.55393121e-01, 3.44606879e-01],\n",
       "        [9.87550911e-01, 1.24490892e-02],\n",
       "        [9.99036067e-01, 9.63933054e-04],\n",
       "        [9.99426877e-01, 5.73122837e-04],\n",
       "        [9.77419091e-01, 2.25809085e-02],\n",
       "        [9.99875825e-01, 1.24174579e-04],\n",
       "        [4.01035517e-03, 9.95989645e-01],\n",
       "        [9.70981700e-01, 2.90183003e-02],\n",
       "        [9.99996900e-01, 3.10029608e-06],\n",
       "        [4.20861758e-02, 9.57913824e-01],\n",
       "        [9.99999875e-01, 1.25261397e-07],\n",
       "        [9.99999999e-01, 9.11087915e-10],\n",
       "        [7.27486528e-01, 2.72513472e-01],\n",
       "        [3.00190545e-01, 6.99809455e-01],\n",
       "        [9.99999690e-01, 3.09690059e-07],\n",
       "        [7.55443772e-01, 2.44556228e-01],\n",
       "        [6.27227462e-01, 3.72772538e-01],\n",
       "        [9.99998058e-01, 1.94229359e-06],\n",
       "        [9.94580122e-01, 5.41987775e-03],\n",
       "        [9.99999964e-01, 3.62604089e-08],\n",
       "        [9.99999997e-01, 3.49835217e-09],\n",
       "        [5.59187757e-01, 4.40812243e-01],\n",
       "        [9.99962684e-01, 3.73155203e-05],\n",
       "        [9.99994475e-01, 5.52486578e-06],\n",
       "        [9.95515524e-01, 4.48447579e-03],\n",
       "        [9.99967287e-01, 3.27125356e-05],\n",
       "        [9.99996496e-01, 3.50390110e-06],\n",
       "        [9.99940548e-01, 5.94515873e-05],\n",
       "        [9.91745431e-01, 8.25456948e-03],\n",
       "        [9.99999830e-01, 1.69930101e-07],\n",
       "        [9.99986233e-01, 1.37673275e-05],\n",
       "        [1.00000000e+00, 7.90716827e-11],\n",
       "        [3.24331777e-02, 9.67566822e-01],\n",
       "        [9.99952163e-01, 4.78368215e-05],\n",
       "        [9.99934047e-01, 6.59532653e-05],\n",
       "        [1.64901529e-01, 8.35098471e-01],\n",
       "        [8.27764297e-01, 1.72235703e-01],\n",
       "        [9.99954082e-01, 4.59184937e-05],\n",
       "        [9.99990862e-01, 9.13810137e-06],\n",
       "        [9.99999991e-01, 8.92985979e-09],\n",
       "        [1.37081342e-01, 8.62918658e-01],\n",
       "        [9.99999600e-01, 3.99901951e-07],\n",
       "        [9.99999871e-01, 1.29262445e-07],\n",
       "        [4.31502874e-02, 9.56849713e-01],\n",
       "        [9.43927963e-01, 5.60720368e-02],\n",
       "        [3.22099452e-03, 9.96779005e-01],\n",
       "        [9.99659782e-01, 3.40217830e-04],\n",
       "        [9.99957135e-01, 4.28652965e-05],\n",
       "        [9.99999508e-01, 4.91726041e-07],\n",
       "        [9.99996903e-01, 3.09705724e-06],\n",
       "        [9.98771871e-01, 1.22812910e-03],\n",
       "        [2.56689262e-03, 9.97433107e-01],\n",
       "        [9.97479295e-01, 2.52070463e-03],\n",
       "        [9.99933860e-01, 6.61402997e-05],\n",
       "        [9.99999805e-01, 1.94593092e-07],\n",
       "        [9.99972335e-01, 2.76648894e-05],\n",
       "        [9.99998372e-01, 1.62795941e-06],\n",
       "        [9.95877072e-01, 4.12292833e-03],\n",
       "        [9.99998961e-01, 1.03922028e-06],\n",
       "        [9.99825258e-01, 1.74742186e-04],\n",
       "        [9.99998185e-01, 1.81534697e-06],\n",
       "        [9.99744745e-01, 2.55255178e-04],\n",
       "        [9.99993761e-01, 6.23864579e-06],\n",
       "        [9.99991745e-01, 8.25517398e-06],\n",
       "        [9.36633003e-05, 9.99906337e-01],\n",
       "        [9.92248117e-01, 7.75188309e-03],\n",
       "        [9.55041910e-04, 9.99044958e-01],\n",
       "        [9.98094427e-01, 1.90557303e-03],\n",
       "        [6.95183516e-01, 3.04816484e-01],\n",
       "        [9.97013226e-01, 2.98677393e-03],\n",
       "        [9.99834900e-01, 1.65099827e-04],\n",
       "        [9.04902569e-01, 9.50974311e-02],\n",
       "        [9.99999113e-01, 8.87450191e-07],\n",
       "        [9.99999991e-01, 8.77173297e-09],\n",
       "        [9.99999947e-01, 5.30643855e-08],\n",
       "        [9.99995457e-01, 4.54341914e-06],\n",
       "        [9.99999853e-01, 1.47069792e-07],\n",
       "        [9.99873558e-01, 1.26441534e-04],\n",
       "        [3.36689809e-04, 9.99663310e-01],\n",
       "        [9.99997877e-01, 2.12297405e-06],\n",
       "        [1.13974927e-03, 9.98860251e-01],\n",
       "        [6.13177815e-05, 9.99938682e-01],\n",
       "        [9.94380710e-01, 5.61929033e-03],\n",
       "        [9.99580206e-01, 4.19794311e-04],\n",
       "        [9.99999341e-01, 6.59178595e-07],\n",
       "        [4.85974142e-01, 5.14025858e-01],\n",
       "        [9.97176317e-01, 2.82368292e-03],\n",
       "        [9.99980604e-01, 1.93959164e-05],\n",
       "        [9.99980658e-01, 1.93423284e-05],\n",
       "        [9.99999421e-01, 5.78684568e-07],\n",
       "        [9.99990502e-01, 9.49775157e-06],\n",
       "        [9.97316819e-01, 2.68318079e-03],\n",
       "        [9.64801918e-01, 3.51980821e-02],\n",
       "        [9.99998104e-01, 1.89645335e-06],\n",
       "        [9.99622138e-01, 3.77862458e-04],\n",
       "        [1.40053907e-03, 9.98599461e-01],\n",
       "        [9.99735763e-01, 2.64237322e-04],\n",
       "        [7.23372159e-01, 2.76627841e-01],\n",
       "        [6.02695255e-01, 3.97304745e-01],\n",
       "        [9.99923072e-01, 7.69279322e-05],\n",
       "        [9.88084696e-01, 1.19153036e-02],\n",
       "        [9.92144243e-01, 7.85575744e-03],\n",
       "        [9.99993250e-01, 6.74999714e-06],\n",
       "        [7.97666597e-06, 9.99992023e-01],\n",
       "        [3.42156743e-02, 9.65784326e-01],\n",
       "        [9.51567609e-01, 4.84323908e-02],\n",
       "        [8.05731246e-01, 1.94268754e-01],\n",
       "        [9.99996609e-01, 3.39145020e-06],\n",
       "        [9.99995785e-01, 4.21482932e-06],\n",
       "        [2.80441785e-04, 9.99719558e-01],\n",
       "        [8.38292199e-01, 1.61707801e-01],\n",
       "        [9.99999943e-01, 5.71658437e-08],\n",
       "        [8.90409519e-04, 9.99109590e-01],\n",
       "        [9.99998189e-01, 1.81120359e-06],\n",
       "        [2.73147755e-05, 9.99972685e-01],\n",
       "        [9.99936708e-01, 6.32917883e-05],\n",
       "        [9.96432043e-01, 3.56795697e-03],\n",
       "        [9.99895870e-01, 1.04129732e-04],\n",
       "        [2.80496559e-09, 9.99999997e-01],\n",
       "        [2.62570075e-05, 9.99973743e-01],\n",
       "        [9.99196658e-01, 8.03341988e-04],\n",
       "        [9.99985732e-01, 1.42677791e-05],\n",
       "        [9.99982392e-01, 1.76076622e-05],\n",
       "        [9.99751120e-01, 2.48879979e-04],\n",
       "        [9.99999552e-01, 4.47672639e-07],\n",
       "        [9.99812395e-01, 1.87604785e-04],\n",
       "        [9.99999985e-01, 1.51994318e-08],\n",
       "        [9.99979500e-01, 2.04999544e-05],\n",
       "        [9.99999992e-01, 8.40417531e-09],\n",
       "        [9.99780935e-01, 2.19064878e-04],\n",
       "        [9.92693349e-01, 7.30665095e-03],\n",
       "        [9.99942014e-01, 5.79859405e-05],\n",
       "        [9.99999804e-01, 1.96073127e-07],\n",
       "        [9.99995718e-01, 4.28168034e-06],\n",
       "        [1.10691692e-01, 8.89308308e-01],\n",
       "        [9.98643901e-01, 1.35609922e-03],\n",
       "        [9.81914016e-01, 1.80859838e-02],\n",
       "        [9.99289128e-01, 7.10871862e-04],\n",
       "        [2.22813670e-01, 7.77186330e-01],\n",
       "        [1.60485407e-03, 9.98395146e-01],\n",
       "        [9.99935218e-01, 6.47817774e-05],\n",
       "        [8.24311571e-01, 1.75688429e-01],\n",
       "        [9.17061856e-02, 9.08293814e-01],\n",
       "        [9.99717253e-01, 2.82746663e-04],\n",
       "        [9.99652174e-01, 3.47825944e-04],\n",
       "        [9.57123071e-01, 4.28769294e-02],\n",
       "        [9.95534896e-01, 4.46510410e-03],\n",
       "        [9.99978951e-01, 2.10485585e-05],\n",
       "        [8.34622036e-02, 9.16537796e-01],\n",
       "        [1.00000000e+00, 1.02988038e-10],\n",
       "        [9.99640110e-01, 3.59890007e-04],\n",
       "        [9.99975411e-01, 2.45890452e-05]]),\n",
       " 'best_y_hat': array(['purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'purr', 'purr',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps', 'purr',\n",
       "        'purr', 'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'purr', 'purr', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'purr', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps', 'purr',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'purr', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'purr', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps'], dtype=object),\n",
       " 'all_scores': {'mean_fit_time': array([3.33121257, 2.89455509, 0.66181087, 2.21434312, 0.37013459,\n",
       "         0.40114899, 2.30597425, 0.64575176, 0.59928784, 2.20848298]),\n",
       "  'std_fit_time': array([0.20353151, 0.01340507, 0.23792368, 0.02152061, 0.02098282,\n",
       "         0.02291226, 0.10614963, 0.08618555, 0.03336914, 0.502378  ]),\n",
       "  'mean_score_time': array([0.00787783, 0.00618525, 0.00756588, 0.00667191, 0.00727835,\n",
       "         0.00632863, 0.00751915, 0.0116219 , 0.00641179, 0.00766191]),\n",
       "  'std_score_time': array([0.00154983, 0.00087664, 0.00175716, 0.00137428, 0.00319791,\n",
       "         0.00116897, 0.0018827 , 0.00428891, 0.00143413, 0.00343939]),\n",
       "  'param_model__solver': masked_array(data=['saga', 'saga', 'liblinear', 'saga', 'liblinear',\n",
       "                     'liblinear', 'saga', 'liblinear', 'liblinear', 'saga'],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__penalty': masked_array(data=['l1', 'l1', 'l2', 'l2', 'l1', 'l1', 'l2', 'l2', 'l2',\n",
       "                     'l2'],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__C': masked_array(data=[1.0, 3593.813663804626, 464.15888336127773, 10000.0,\n",
       "                     2.7825594022071245, 1291.5496650148827,\n",
       "                     21.544346900318832, 166.81005372000593,\n",
       "                     3593.813663804626, 464.15888336127773],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'model__solver': 'saga',\n",
       "    'model__penalty': 'l1',\n",
       "    'model__C': 1.0},\n",
       "   {'model__solver': 'saga',\n",
       "    'model__penalty': 'l1',\n",
       "    'model__C': 3593.813663804626},\n",
       "   {'model__solver': 'liblinear',\n",
       "    'model__penalty': 'l2',\n",
       "    'model__C': 464.15888336127773},\n",
       "   {'model__solver': 'saga', 'model__penalty': 'l2', 'model__C': 10000.0},\n",
       "   {'model__solver': 'liblinear',\n",
       "    'model__penalty': 'l1',\n",
       "    'model__C': 2.7825594022071245},\n",
       "   {'model__solver': 'liblinear',\n",
       "    'model__penalty': 'l1',\n",
       "    'model__C': 1291.5496650148827},\n",
       "   {'model__solver': 'saga',\n",
       "    'model__penalty': 'l2',\n",
       "    'model__C': 21.544346900318832},\n",
       "   {'model__solver': 'liblinear',\n",
       "    'model__penalty': 'l2',\n",
       "    'model__C': 166.81005372000593},\n",
       "   {'model__solver': 'liblinear',\n",
       "    'model__penalty': 'l2',\n",
       "    'model__C': 3593.813663804626},\n",
       "   {'model__solver': 'saga',\n",
       "    'model__penalty': 'l2',\n",
       "    'model__C': 464.15888336127773}],\n",
       "  'split0_test_score': array([0.92013889, 0.92013889, 0.91319444, 0.92013889, 0.90972222,\n",
       "         0.91319444, 0.92013889, 0.91319444, 0.90972222, 0.92013889]),\n",
       "  'split1_test_score': array([0.94076655, 0.94076655, 0.93031359, 0.94076655, 0.92682927,\n",
       "         0.92682927, 0.94076655, 0.91986063, 0.92682927, 0.94076655]),\n",
       "  'split2_test_score': array([0.91637631, 0.91637631, 0.90592334, 0.91637631, 0.91289199,\n",
       "         0.90592334, 0.91637631, 0.90940767, 0.90592334, 0.91637631]),\n",
       "  'split3_test_score': array([0.87456446, 0.87456446, 0.87804878, 0.87456446, 0.88850174,\n",
       "         0.89198606, 0.87456446, 0.88501742, 0.8815331 , 0.87456446]),\n",
       "  'split4_test_score': array([0.93728223, 0.93728223, 0.93379791, 0.93728223, 0.92682927,\n",
       "         0.93031359, 0.93728223, 0.93379791, 0.93379791, 0.93728223]),\n",
       "  'mean_test_score': array([0.9178273 , 0.9178273 , 0.91225627, 0.9178273 , 0.91295265,\n",
       "         0.91364903, 0.9178273 , 0.91225627, 0.91155989, 0.9178273 ]),\n",
       "  'std_test_score': array([0.02358773, 0.02358773, 0.01999928, 0.02358773, 0.01409079,\n",
       "         0.01399944, 0.02358773, 0.01594951, 0.01823892, 0.02358773]),\n",
       "  'rank_test_score': array([ 1,  1,  8,  1,  7,  6,  1,  8, 10,  1], dtype=int32)}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load parameteres and scores\n",
    "pickling_out = open(os.path.join(model_fldr, 'logreg1_2_cls_scores_params_rand.pkl'), 'rb')\n",
    "logreg1_2_cls_scores_params = pickle.load(pickling_out)\n",
    "logreg1_2_cls_scores_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('transformer',\n",
       "                                              RandomOverSampler(random_state=3,\n",
       "                                                                ratio=None,\n",
       "                                                                return_indices=False,\n",
       "                                                                sampling_strategy='minority')),\n",
       "                                             ('model',\n",
       "                                              LogisticRegression(C=1.0,\n",
       "                                                                 class_weight=None,\n",
       "                                                                 dual=False,\n",
       "                                                                 fit_intercept=True,\n",
       "                                                                 intercept_scaling=1,\n",
       "                                                                 l1_ratio=None,\n",
       "                                                                 max_iter=100,\n",
       "                                                                 multi_class='war...\n",
       "                   param_distributions={'model__C': array([1.00000000e+00, 2.78255940e+00, 7.74263683e+00, 2.15443469e+01,\n",
       "       5.99484250e+01, 1.66810054e+02, 4.64158883e+02, 1.29154967e+03,\n",
       "       3.59381366e+03, 1.00000000e+04]),\n",
       "                                        'model__penalty': ['l1', 'l2'],\n",
       "                                        'model__solver': ['liblinear', 'saga']},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='f1_micro', verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load best model\n",
    "pickling_out = open(os.path.join(model_fldr, 'logreg1_2_cls_model_rand.pkl'), 'rb')\n",
    "logreg1_2_cls_model = pickle.load(pickling_out)\n",
    "logreg1_2_cls_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_train_score': 0.9143454038997214,\n",
       " 'best_test_score': 0.9055555555555556,\n",
       " 'time_sec': 65.068219,\n",
       " 'time_best_fit_sec': 1.7317128,\n",
       " 'best_params': {'model__penalty': 'elasticnet',\n",
       "  'model__l1_ratio': 0.7000000000000001,\n",
       "  'model__C': 21.544346900318832},\n",
       " 'best_estimator': Pipeline(memory=None,\n",
       "          steps=[('transformer',\n",
       "                  RandomOverSampler(random_state=3, ratio=None,\n",
       "                                    return_indices=False,\n",
       "                                    sampling_strategy='minority')),\n",
       "                 ('model',\n",
       "                  LogisticRegression(C=21.544346900318832, class_weight=None,\n",
       "                                     dual=False, fit_intercept=True,\n",
       "                                     intercept_scaling=1,\n",
       "                                     l1_ratio=0.7000000000000001, max_iter=100,\n",
       "                                     multi_class='multinomial', n_jobs=None,\n",
       "                                     penalty='elasticnet', random_state=3,\n",
       "                                     solver='saga', tol=0.0001, verbose=0,\n",
       "                                     warm_start=False))],\n",
       "          verbose=False),\n",
       " 'best_test_proba': array([[3.72838374e-03, 9.96271616e-01],\n",
       "        [5.00013985e-01, 4.99986015e-01],\n",
       "        [9.99929104e-01, 7.08962240e-05],\n",
       "        [9.70120474e-01, 2.98795264e-02],\n",
       "        [9.99793361e-01, 2.06638720e-04],\n",
       "        [9.99531723e-01, 4.68277131e-04],\n",
       "        [9.99992612e-01, 7.38752040e-06],\n",
       "        [1.00000000e+00, 7.49371932e-13],\n",
       "        [9.99867783e-01, 1.32216856e-04],\n",
       "        [8.28240296e-11, 1.00000000e+00],\n",
       "        [9.92476525e-01, 7.52347456e-03],\n",
       "        [9.98254073e-01, 1.74592673e-03],\n",
       "        [9.99998364e-01, 1.63634164e-06],\n",
       "        [9.99999987e-01, 1.30261293e-08],\n",
       "        [9.99798463e-01, 2.01536705e-04],\n",
       "        [9.99911521e-01, 8.84792684e-05],\n",
       "        [8.45127527e-01, 1.54872473e-01],\n",
       "        [1.00000000e+00, 2.48439950e-12],\n",
       "        [9.77958393e-01, 2.20416066e-02],\n",
       "        [9.26226224e-02, 9.07377378e-01],\n",
       "        [9.99999999e-01, 7.33844875e-10],\n",
       "        [2.12616785e-02, 9.78738322e-01],\n",
       "        [9.99999999e-01, 1.48818018e-09],\n",
       "        [9.99992797e-01, 7.20272115e-06],\n",
       "        [9.99941078e-01, 5.89224767e-05],\n",
       "        [9.99978497e-01, 2.15034505e-05],\n",
       "        [9.99910723e-01, 8.92768104e-05],\n",
       "        [9.98911044e-01, 1.08895617e-03],\n",
       "        [9.99969155e-01, 3.08446983e-05],\n",
       "        [9.99970554e-01, 2.94460009e-05],\n",
       "        [5.46443046e-01, 4.53556954e-01],\n",
       "        [9.99994812e-01, 5.18810676e-06],\n",
       "        [9.29820484e-01, 7.01795157e-02],\n",
       "        [9.99858101e-01, 1.41899431e-04],\n",
       "        [1.04333046e-05, 9.99989567e-01],\n",
       "        [9.99894498e-01, 1.05501671e-04],\n",
       "        [9.99999998e-01, 1.57429122e-09],\n",
       "        [9.99999993e-01, 7.29027093e-09],\n",
       "        [9.99999982e-01, 1.79784441e-08],\n",
       "        [6.41901022e-01, 3.58098978e-01],\n",
       "        [1.00000000e+00, 3.08440969e-12],\n",
       "        [9.99939919e-01, 6.00807987e-05],\n",
       "        [9.99970964e-01, 2.90361704e-05],\n",
       "        [3.35669132e-01, 6.64330868e-01],\n",
       "        [2.07273589e-01, 7.92726411e-01],\n",
       "        [1.93629073e-04, 9.99806371e-01],\n",
       "        [9.99999994e-01, 6.22514707e-09],\n",
       "        [4.11288660e-01, 5.88711340e-01],\n",
       "        [9.99997540e-01, 2.46008407e-06],\n",
       "        [9.99999985e-01, 1.48261605e-08],\n",
       "        [7.53126151e-04, 9.99246874e-01],\n",
       "        [9.99998491e-01, 1.50902628e-06],\n",
       "        [9.34121252e-01, 6.58787482e-02],\n",
       "        [9.99829446e-01, 1.70554315e-04],\n",
       "        [9.99996102e-01, 3.89771467e-06],\n",
       "        [9.98615292e-01, 1.38470754e-03],\n",
       "        [9.99999771e-01, 2.29436783e-07],\n",
       "        [9.99851688e-01, 1.48311975e-04],\n",
       "        [9.99999995e-01, 5.38046384e-09],\n",
       "        [9.99993954e-01, 6.04638770e-06],\n",
       "        [9.99981636e-01, 1.83644033e-05],\n",
       "        [9.99999980e-01, 1.99018093e-08],\n",
       "        [5.46777825e-03, 9.94532222e-01],\n",
       "        [9.68859504e-01, 3.11404959e-02],\n",
       "        [2.19110455e-05, 9.99978089e-01],\n",
       "        [9.96914812e-01, 3.08518767e-03],\n",
       "        [9.99997144e-01, 2.85586443e-06],\n",
       "        [9.99999909e-01, 9.14991454e-08],\n",
       "        [9.99999971e-01, 2.92895707e-08],\n",
       "        [9.99961777e-01, 3.82226703e-05],\n",
       "        [9.99225000e-01, 7.75000152e-04],\n",
       "        [7.05244372e-01, 2.94755628e-01],\n",
       "        [9.99998591e-01, 1.40889053e-06],\n",
       "        [9.99951241e-01, 4.87587266e-05],\n",
       "        [9.99913519e-01, 8.64810929e-05],\n",
       "        [8.51440683e-04, 9.99148559e-01],\n",
       "        [5.57468656e-01, 4.42531344e-01],\n",
       "        [9.94156661e-01, 5.84333851e-03],\n",
       "        [9.99999999e-01, 6.24983572e-10],\n",
       "        [9.99981400e-01, 1.85996849e-05],\n",
       "        [9.99997426e-01, 2.57383385e-06],\n",
       "        [9.99799083e-01, 2.00917121e-04],\n",
       "        [1.53203823e-02, 9.84679618e-01],\n",
       "        [9.99999999e-01, 9.50876150e-10],\n",
       "        [9.99770818e-01, 2.29182444e-04],\n",
       "        [9.99999999e-01, 1.28435396e-09],\n",
       "        [9.99926662e-01, 7.33378096e-05],\n",
       "        [9.99999950e-01, 4.95937495e-08],\n",
       "        [9.99809202e-01, 1.90797962e-04],\n",
       "        [9.99689090e-01, 3.10910468e-04],\n",
       "        [1.10907551e-02, 9.88909245e-01],\n",
       "        [9.98463252e-01, 1.53674789e-03],\n",
       "        [1.07933837e-08, 9.99999989e-01],\n",
       "        [9.99999475e-01, 5.24925353e-07],\n",
       "        [9.99999415e-01, 5.84647182e-07],\n",
       "        [9.99490828e-01, 5.09171659e-04],\n",
       "        [1.68590593e-02, 9.83140941e-01],\n",
       "        [9.99996985e-01, 3.01487333e-06],\n",
       "        [1.00000000e+00, 7.89841958e-12],\n",
       "        [9.99999509e-01, 4.90690504e-07],\n",
       "        [9.99999785e-01, 2.15423227e-07],\n",
       "        [9.99999848e-01, 1.52288695e-07],\n",
       "        [9.99999289e-01, 7.11005131e-07],\n",
       "        [8.73772740e-01, 1.26227260e-01],\n",
       "        [9.99993210e-01, 6.79043452e-06],\n",
       "        [9.99999021e-01, 9.78733016e-07],\n",
       "        [9.99999995e-01, 5.39554807e-09],\n",
       "        [9.99056612e-01, 9.43387545e-04],\n",
       "        [2.15350866e-04, 9.99784649e-01],\n",
       "        [9.35521410e-01, 6.44785900e-02],\n",
       "        [9.99997160e-01, 2.84038406e-06],\n",
       "        [9.81070188e-01, 1.89298117e-02],\n",
       "        [9.99998071e-01, 1.92850108e-06],\n",
       "        [9.99823525e-01, 1.76475234e-04],\n",
       "        [1.48747630e-01, 8.51252370e-01],\n",
       "        [9.99975650e-01, 2.43504467e-05],\n",
       "        [9.99109565e-01, 8.90435342e-04],\n",
       "        [2.33791990e-01, 7.66208010e-01],\n",
       "        [6.04371041e-01, 3.95628959e-01],\n",
       "        [9.99613886e-01, 3.86113713e-04],\n",
       "        [9.91574096e-01, 8.42590401e-03],\n",
       "        [8.24646008e-01, 1.75353992e-01],\n",
       "        [9.78201769e-01, 2.17982309e-02],\n",
       "        [7.91733545e-02, 9.20826646e-01],\n",
       "        [9.99939180e-01, 6.08204778e-05],\n",
       "        [3.54932703e-01, 6.45067297e-01],\n",
       "        [2.52728577e-01, 7.47271423e-01],\n",
       "        [9.99080166e-01, 9.19833550e-04],\n",
       "        [1.47694493e-01, 8.52305507e-01],\n",
       "        [9.95227664e-01, 4.77233559e-03],\n",
       "        [9.96619965e-01, 3.38003512e-03],\n",
       "        [9.60230366e-01, 3.97696338e-02],\n",
       "        [9.99999841e-01, 1.58763496e-07],\n",
       "        [9.99994780e-01, 5.22003463e-06],\n",
       "        [9.99999981e-01, 1.92577456e-08],\n",
       "        [9.99999657e-01, 3.43382879e-07],\n",
       "        [9.82447028e-01, 1.75529722e-02],\n",
       "        [9.98674272e-01, 1.32572804e-03],\n",
       "        [9.99989159e-01, 1.08412655e-05],\n",
       "        [1.00000000e+00, 2.54766085e-10],\n",
       "        [9.98616992e-01, 1.38300827e-03],\n",
       "        [9.99939334e-01, 6.06656861e-05],\n",
       "        [3.56433859e-02, 9.64356614e-01],\n",
       "        [9.92529906e-01, 7.47009446e-03],\n",
       "        [9.99998569e-01, 1.43072285e-06],\n",
       "        [9.99792556e-01, 2.07443829e-04],\n",
       "        [9.99780530e-01, 2.19469722e-04],\n",
       "        [9.99793002e-01, 2.06998415e-04],\n",
       "        [9.99998782e-01, 1.21845448e-06],\n",
       "        [9.99998845e-01, 1.15536635e-06],\n",
       "        [9.99999831e-01, 1.68910441e-07],\n",
       "        [9.99999220e-01, 7.80386114e-07],\n",
       "        [2.71799016e-03, 9.97282010e-01],\n",
       "        [9.99997536e-01, 2.46393368e-06],\n",
       "        [9.99999977e-01, 2.25551858e-08],\n",
       "        [9.99996005e-01, 3.99502436e-06],\n",
       "        [6.82289584e-02, 9.31771042e-01],\n",
       "        [5.91608101e-01, 4.08391899e-01],\n",
       "        [9.99920305e-01, 7.96949429e-05],\n",
       "        [9.14341860e-01, 8.56581398e-02],\n",
       "        [9.99989715e-01, 1.02846097e-05],\n",
       "        [9.99860364e-01, 1.39635623e-04],\n",
       "        [9.99814439e-01, 1.85561183e-04],\n",
       "        [9.99999996e-01, 3.60024104e-09],\n",
       "        [2.78358332e-02, 9.72164167e-01],\n",
       "        [9.99961992e-01, 3.80075374e-05],\n",
       "        [9.99998442e-01, 1.55760384e-06],\n",
       "        [1.00000000e+00, 1.28381340e-10],\n",
       "        [3.77621450e-05, 9.99962238e-01],\n",
       "        [2.42545063e-01, 7.57454937e-01],\n",
       "        [1.82156074e-04, 9.99817844e-01],\n",
       "        [9.82349271e-01, 1.76507290e-02],\n",
       "        [9.99999997e-01, 3.30840897e-09],\n",
       "        [1.12617018e-01, 8.87382982e-01],\n",
       "        [9.92598118e-01, 7.40188238e-03],\n",
       "        [9.99999947e-01, 5.31967330e-08],\n",
       "        [9.95664993e-01, 4.33500663e-03],\n",
       "        [8.58886683e-01, 1.41113317e-01],\n",
       "        [4.10238548e-03, 9.95897615e-01],\n",
       "        [9.99999815e-01, 1.85223425e-07],\n",
       "        [5.55469334e-01, 4.44530666e-01],\n",
       "        [9.99601143e-01, 3.98856666e-04],\n",
       "        [9.94294030e-01, 5.70597040e-03],\n",
       "        [9.55821921e-01, 4.41780787e-02],\n",
       "        [9.99940482e-01, 5.95177132e-05],\n",
       "        [1.00000000e+00, 4.09419955e-12],\n",
       "        [9.99998938e-01, 1.06177160e-06],\n",
       "        [7.39519377e-11, 1.00000000e+00],\n",
       "        [9.92545392e-01, 7.45460785e-03],\n",
       "        [9.99999995e-01, 5.34139203e-09],\n",
       "        [9.99998773e-01, 1.22669001e-06],\n",
       "        [9.99999946e-01, 5.41242088e-08],\n",
       "        [9.99999887e-01, 1.13298939e-07],\n",
       "        [9.99997358e-01, 2.64237626e-06],\n",
       "        [9.99999991e-01, 8.91567040e-09],\n",
       "        [9.86042325e-01, 1.39576747e-02],\n",
       "        [9.99999951e-01, 4.85558010e-08],\n",
       "        [9.99898454e-01, 1.01546000e-04],\n",
       "        [9.74596103e-04, 9.99025404e-01],\n",
       "        [4.36027978e-01, 5.63972022e-01],\n",
       "        [9.99999973e-01, 2.69163424e-08],\n",
       "        [2.82491123e-08, 9.99999972e-01],\n",
       "        [9.99982263e-01, 1.77365561e-05],\n",
       "        [9.96794031e-01, 3.20596871e-03],\n",
       "        [9.99999980e-01, 2.01089854e-08],\n",
       "        [9.97137641e-01, 2.86235939e-03],\n",
       "        [9.99990727e-01, 9.27251707e-06],\n",
       "        [6.86059083e-02, 9.31394092e-01],\n",
       "        [6.12783472e-01, 3.87216528e-01],\n",
       "        [9.93982566e-01, 6.01743380e-03],\n",
       "        [9.99863161e-01, 1.36838719e-04],\n",
       "        [9.99829699e-01, 1.70300967e-04],\n",
       "        [9.84786461e-01, 1.52135393e-02],\n",
       "        [9.99974919e-01, 2.50812094e-05],\n",
       "        [2.70244750e-03, 9.97297552e-01],\n",
       "        [9.87012806e-01, 1.29871945e-02],\n",
       "        [9.99999484e-01, 5.16045466e-07],\n",
       "        [3.07421841e-02, 9.69257816e-01],\n",
       "        [9.99999991e-01, 8.93885387e-09],\n",
       "        [1.00000000e+00, 1.24452159e-11],\n",
       "        [7.79833122e-01, 2.20166878e-01],\n",
       "        [3.12855231e-01, 6.87144769e-01],\n",
       "        [9.99999981e-01, 1.85008496e-08],\n",
       "        [8.65171581e-01, 1.34828419e-01],\n",
       "        [6.77638927e-01, 3.22361073e-01],\n",
       "        [9.99999888e-01, 1.12081645e-07],\n",
       "        [9.98599075e-01, 1.40092536e-03],\n",
       "        [9.99999999e-01, 8.45667596e-10],\n",
       "        [1.00000000e+00, 1.31527535e-10],\n",
       "        [5.39235037e-01, 4.60764963e-01],\n",
       "        [9.99994202e-01, 5.79798861e-06],\n",
       "        [9.99999634e-01, 3.66474436e-07],\n",
       "        [9.98044941e-01, 1.95505869e-03],\n",
       "        [9.99993697e-01, 6.30349068e-06],\n",
       "        [9.99999659e-01, 3.40887582e-07],\n",
       "        [9.99993454e-01, 6.54590288e-06],\n",
       "        [9.96566307e-01, 3.43369339e-03],\n",
       "        [9.99999992e-01, 7.52705059e-09],\n",
       "        [9.99997123e-01, 2.87744376e-06],\n",
       "        [1.00000000e+00, 6.80507869e-13],\n",
       "        [2.73919183e-02, 9.72608082e-01],\n",
       "        [9.99997050e-01, 2.94985500e-06],\n",
       "        [9.99995932e-01, 4.06761005e-06],\n",
       "        [1.15006760e-01, 8.84993240e-01],\n",
       "        [8.64308342e-01, 1.35691658e-01],\n",
       "        [9.99994474e-01, 5.52588876e-06],\n",
       "        [9.99999021e-01, 9.78935414e-07],\n",
       "        [1.00000000e+00, 1.33121526e-10],\n",
       "        [8.56728718e-02, 9.14327128e-01],\n",
       "        [9.99999983e-01, 1.66368467e-08],\n",
       "        [9.99999996e-01, 4.00953496e-09],\n",
       "        [3.27266387e-02, 9.67273361e-01],\n",
       "        [9.66217216e-01, 3.37827838e-02],\n",
       "        [9.83224436e-04, 9.99016776e-01],\n",
       "        [9.99954818e-01, 4.51824856e-05],\n",
       "        [9.99993037e-01, 6.96314493e-06],\n",
       "        [9.99999964e-01, 3.56484170e-08],\n",
       "        [9.99999607e-01, 3.93139315e-07],\n",
       "        [9.99764822e-01, 2.35177616e-04],\n",
       "        [1.25014480e-03, 9.98749855e-01],\n",
       "        [9.99239568e-01, 7.60432409e-04],\n",
       "        [9.99989088e-01, 1.09120320e-05],\n",
       "        [9.99999991e-01, 9.28410178e-09],\n",
       "        [9.99997567e-01, 2.43297576e-06],\n",
       "        [9.99999892e-01, 1.07513385e-07],\n",
       "        [9.98684067e-01, 1.31593335e-03],\n",
       "        [9.99999946e-01, 5.40117786e-08],\n",
       "        [9.99980732e-01, 1.92683218e-05],\n",
       "        [9.99999913e-01, 8.70702453e-08],\n",
       "        [9.99953324e-01, 4.66761619e-05],\n",
       "        [9.99999516e-01, 4.83827379e-07],\n",
       "        [9.99999162e-01, 8.37914837e-07],\n",
       "        [1.95479503e-05, 9.99980452e-01],\n",
       "        [9.97636409e-01, 2.36359072e-03],\n",
       "        [3.08767843e-04, 9.99691232e-01],\n",
       "        [9.99267220e-01, 7.32779593e-04],\n",
       "        [7.19600997e-01, 2.80399003e-01],\n",
       "        [9.99179942e-01, 8.20058356e-04],\n",
       "        [9.99975784e-01, 2.42156963e-05],\n",
       "        [9.46158209e-01, 5.38417914e-02],\n",
       "        [9.99999949e-01, 5.07988071e-08],\n",
       "        [1.00000000e+00, 2.18406097e-10],\n",
       "        [9.99999998e-01, 2.15769615e-09],\n",
       "        [9.99999514e-01, 4.85552924e-07],\n",
       "        [9.99999991e-01, 8.70348906e-09],\n",
       "        [9.99979429e-01, 2.05713318e-05],\n",
       "        [5.94704222e-05, 9.99940530e-01],\n",
       "        [9.99999707e-01, 2.93274017e-07],\n",
       "        [4.65668753e-04, 9.99534331e-01],\n",
       "        [7.04287809e-06, 9.99992957e-01],\n",
       "        [9.97640049e-01, 2.35995121e-03],\n",
       "        [9.99896213e-01, 1.03786978e-04],\n",
       "        [9.99999961e-01, 3.93320152e-08],\n",
       "        [5.04827325e-01, 4.95172675e-01],\n",
       "        [9.99145454e-01, 8.54545807e-04],\n",
       "        [9.99998890e-01, 1.10952340e-06],\n",
       "        [9.99998125e-01, 1.87508597e-06],\n",
       "        [9.99999973e-01, 2.70851082e-08],\n",
       "        [9.99998816e-01, 1.18401455e-06],\n",
       "        [9.98987505e-01, 1.01249484e-03],\n",
       "        [9.75554716e-01, 2.44452845e-02],\n",
       "        [9.99999905e-01, 9.50655867e-08],\n",
       "        [9.99950041e-01, 4.99587508e-05],\n",
       "        [4.83981585e-04, 9.99516018e-01],\n",
       "        [9.99956851e-01, 4.31489925e-05],\n",
       "        [7.61927142e-01, 2.38072858e-01],\n",
       "        [6.27331371e-01, 3.72668629e-01],\n",
       "        [9.99978435e-01, 2.15652805e-05],\n",
       "        [9.94296497e-01, 5.70350341e-03],\n",
       "        [9.96950098e-01, 3.04990244e-03],\n",
       "        [9.99999466e-01, 5.33502091e-07],\n",
       "        [6.01181581e-07, 9.99999399e-01],\n",
       "        [2.40901183e-02, 9.75909882e-01],\n",
       "        [9.65853557e-01, 3.41464427e-02],\n",
       "        [8.56637434e-01, 1.43362566e-01],\n",
       "        [9.99999735e-01, 2.64504553e-07],\n",
       "        [9.99999688e-01, 3.11801824e-07],\n",
       "        [9.20219377e-05, 9.99907978e-01],\n",
       "        [7.56932599e-01, 2.43067401e-01],\n",
       "        [9.99999999e-01, 1.44420810e-09],\n",
       "        [3.03182335e-04, 9.99696818e-01],\n",
       "        [9.99999846e-01, 1.54422998e-07],\n",
       "        [3.96468256e-06, 9.99996035e-01],\n",
       "        [9.99991367e-01, 8.63260036e-06],\n",
       "        [9.99330445e-01, 6.69554617e-04],\n",
       "        [9.99971804e-01, 2.81957274e-05],\n",
       "        [5.01163310e-11, 1.00000000e+00],\n",
       "        [4.41439746e-06, 9.99995586e-01],\n",
       "        [9.99893752e-01, 1.06247576e-04],\n",
       "        [9.99998090e-01, 1.90963692e-06],\n",
       "        [9.99998075e-01, 1.92520202e-06],\n",
       "        [9.99975964e-01, 2.40360632e-05],\n",
       "        [9.99999983e-01, 1.66337623e-08],\n",
       "        [9.99971693e-01, 2.83072299e-05],\n",
       "        [1.00000000e+00, 4.38519161e-10],\n",
       "        [9.99997519e-01, 2.48136474e-06],\n",
       "        [1.00000000e+00, 1.06239395e-10],\n",
       "        [9.99945312e-01, 5.46884408e-05],\n",
       "        [9.96613952e-01, 3.38604789e-03],\n",
       "        [9.99988847e-01, 1.11531958e-05],\n",
       "        [9.99999989e-01, 1.05396965e-08],\n",
       "        [9.99999771e-01, 2.29403581e-07],\n",
       "        [4.08972989e-02, 9.59102701e-01],\n",
       "        [9.99552162e-01, 4.47837596e-04],\n",
       "        [9.94117736e-01, 5.88226399e-03],\n",
       "        [9.99889475e-01, 1.10525020e-04],\n",
       "        [1.85396332e-01, 8.14603668e-01],\n",
       "        [7.09542607e-04, 9.99290457e-01],\n",
       "        [9.99987963e-01, 1.20366759e-05],\n",
       "        [8.75941025e-01, 1.24058975e-01],\n",
       "        [5.79112032e-02, 9.42088797e-01],\n",
       "        [9.99926945e-01, 7.30546689e-05],\n",
       "        [9.99929252e-01, 7.07484688e-05],\n",
       "        [9.77705859e-01, 2.22941413e-02],\n",
       "        [9.97911905e-01, 2.08809483e-03],\n",
       "        [9.99996490e-01, 3.51042353e-06],\n",
       "        [4.39731776e-02, 9.56026822e-01],\n",
       "        [1.00000000e+00, 1.04866918e-12],\n",
       "        [9.99938083e-01, 6.19168537e-05],\n",
       "        [9.99998453e-01, 1.54671688e-06]]),\n",
       " 'best_y_hat': array(['purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'purr', 'purr',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps', 'purr',\n",
       "        'purr', 'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'purr', 'purr', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'purr', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps', 'purr',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'purr', 'purr',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps'], dtype=object),\n",
       " 'all_scores': {'mean_fit_time': array([4.64340315, 3.15972662, 4.5373054 , 4.5473434 , 4.52148099,\n",
       "         4.95083642, 5.64718399, 5.46199212, 5.69940462, 5.38385391]),\n",
       "  'std_fit_time': array([0.09451856, 0.06285076, 0.22363095, 0.16804899, 0.17907133,\n",
       "         0.3408141 , 0.51888884, 0.43401977, 0.28955786, 0.6353777 ]),\n",
       "  'mean_score_time': array([0.01313305, 0.00653543, 0.0117928 , 0.00639577, 0.00665121,\n",
       "         0.00854702, 0.01110315, 0.00960965, 0.00833592, 0.00578508]),\n",
       "  'std_score_time': array([0.0083963 , 0.00176178, 0.00401923, 0.00179237, 0.00179501,\n",
       "         0.00423935, 0.0046877 , 0.00428925, 0.00389564, 0.00105884]),\n",
       "  'param_model__penalty': masked_array(data=['elasticnet', 'elasticnet', 'elasticnet', 'elasticnet',\n",
       "                     'elasticnet', 'elasticnet', 'elasticnet', 'elasticnet',\n",
       "                     'elasticnet', 'elasticnet'],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__l1_ratio': masked_array(data=[0.7000000000000001, 0.0, 0.4, 0.30000000000000004, 0.1,\n",
       "                     0.1, 0.5, 0.7000000000000001, 0.2, 0.9],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__C': masked_array(data=[21.544346900318832, 7.742636826811269,\n",
       "                     21.544346900318832, 166.81005372000593,\n",
       "                     2.7825594022071245, 464.15888336127773,\n",
       "                     59.94842503189409, 1291.5496650148827,\n",
       "                     21.544346900318832, 59.94842503189409],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'model__penalty': 'elasticnet',\n",
       "    'model__l1_ratio': 0.7000000000000001,\n",
       "    'model__C': 21.544346900318832},\n",
       "   {'model__penalty': 'elasticnet',\n",
       "    'model__l1_ratio': 0.0,\n",
       "    'model__C': 7.742636826811269},\n",
       "   {'model__penalty': 'elasticnet',\n",
       "    'model__l1_ratio': 0.4,\n",
       "    'model__C': 21.544346900318832},\n",
       "   {'model__penalty': 'elasticnet',\n",
       "    'model__l1_ratio': 0.30000000000000004,\n",
       "    'model__C': 166.81005372000593},\n",
       "   {'model__penalty': 'elasticnet',\n",
       "    'model__l1_ratio': 0.1,\n",
       "    'model__C': 2.7825594022071245},\n",
       "   {'model__penalty': 'elasticnet',\n",
       "    'model__l1_ratio': 0.1,\n",
       "    'model__C': 464.15888336127773},\n",
       "   {'model__penalty': 'elasticnet',\n",
       "    'model__l1_ratio': 0.5,\n",
       "    'model__C': 59.94842503189409},\n",
       "   {'model__penalty': 'elasticnet',\n",
       "    'model__l1_ratio': 0.7000000000000001,\n",
       "    'model__C': 1291.5496650148827},\n",
       "   {'model__penalty': 'elasticnet',\n",
       "    'model__l1_ratio': 0.2,\n",
       "    'model__C': 21.544346900318832},\n",
       "   {'model__penalty': 'elasticnet',\n",
       "    'model__l1_ratio': 0.9,\n",
       "    'model__C': 59.94842503189409}],\n",
       "  'split0_test_score': array([0.92013889, 0.92013889, 0.92013889, 0.92013889, 0.92013889,\n",
       "         0.92013889, 0.92013889, 0.92013889, 0.92013889, 0.92013889]),\n",
       "  'split1_test_score': array([0.93728223, 0.93728223, 0.93728223, 0.93728223, 0.93728223,\n",
       "         0.93728223, 0.93728223, 0.93728223, 0.93728223, 0.93728223]),\n",
       "  'split2_test_score': array([0.90940767, 0.90940767, 0.90940767, 0.90940767, 0.90940767,\n",
       "         0.90940767, 0.90940767, 0.90940767, 0.90940767, 0.90940767]),\n",
       "  'split3_test_score': array([0.87108014, 0.87108014, 0.87108014, 0.87108014, 0.87108014,\n",
       "         0.87108014, 0.87108014, 0.87108014, 0.87108014, 0.87108014]),\n",
       "  'split4_test_score': array([0.93379791, 0.93379791, 0.93379791, 0.93379791, 0.93379791,\n",
       "         0.93379791, 0.93379791, 0.93379791, 0.93379791, 0.93379791]),\n",
       "  'mean_test_score': array([0.9143454, 0.9143454, 0.9143454, 0.9143454, 0.9143454, 0.9143454,\n",
       "         0.9143454, 0.9143454, 0.9143454, 0.9143454]),\n",
       "  'std_test_score': array([0.02380113, 0.02380113, 0.02380113, 0.02380113, 0.02380113,\n",
       "         0.02380113, 0.02380113, 0.02380113, 0.02380113, 0.02380113]),\n",
       "  'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)}}"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and fit logistic regression with  RandomizedSearchCV: 2nd set of parameteres\n",
    "from src.models import model_sel_rand_search\n",
    "\n",
    "# Function arguments:\n",
    "model = LogisticRegression(random_state=3, multi_class='multinomial', solver='saga')\n",
    "transformer = RandomOverSampler(random_state=3, sampling_strategy='minority')\n",
    "CV = 5\n",
    "\n",
    "# Function arguments: classifier params\n",
    "penalty = ['elasticnet']\n",
    "C = np.logspace(0, 4, 10)\n",
    "solver = 'saga'\n",
    "multiclass='multinomial'\n",
    "l1_1ratio = list(np.arange(0, 1, 0.1))\n",
    "\n",
    "param_distributions = dict(\n",
    "        model__C = C, \n",
    "        model__penalty = penalty,\n",
    "        model__l1_ratio=l1_ratio)\n",
    "\n",
    "\n",
    "# Call parameter selection function\n",
    "logreg2_2_cls_scores_params, logreg2_2_cls_model = model_sel_rand_search.train_fit_time(model,\n",
    "                                                                               param_distributions,\n",
    "                                                                               transformer,\n",
    "                                                                               X_train,\n",
    "                                                                               X_test,\n",
    "                                                                               y_train,\n",
    "                                                                               y_test,\n",
    "                                                                               CV)\n",
    "# Pickle results\n",
    "with open('/Users/greenapple/project3/models/logreg2_2_cls_scores_params_rand.pkl', 'wb') as f:\n",
    "    pickle.dump(logreg2_2_cls_scores_params, f)\n",
    "    \n",
    "# Pickle model\n",
    "with open('/Users/greenapple/project3/models/logreg2_2_cls_model_rand.pkl', 'wb') as f:\n",
    "    pickle.dump(logreg2_2_cls_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_train_score': 0.9157381615598886,\n",
       " 'best_test_score': 0.9083333333333333,\n",
       " 'time_sec': 59.726693,\n",
       " 'time_best_fit_sec': 0.6185069999999999,\n",
       " 'best_params': {'model__solver': 'lbfgs',\n",
       "  'model__penalty': 'l2',\n",
       "  'model__C': 1291.5496650148827},\n",
       " 'best_estimator': Pipeline(memory=None,\n",
       "          steps=[('transformer',\n",
       "                  RandomOverSampler(random_state=3, ratio=None,\n",
       "                                    return_indices=False,\n",
       "                                    sampling_strategy='minority')),\n",
       "                 ('model',\n",
       "                  LogisticRegression(C=1291.5496650148827, class_weight=None,\n",
       "                                     dual=False, fit_intercept=True,\n",
       "                                     intercept_scaling=1, l1_ratio=None,\n",
       "                                     max_iter=100, multi_class='multinomial',\n",
       "                                     n_jobs=None, penalty='l2', random_state=3,\n",
       "                                     solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                     warm_start=False))],\n",
       "          verbose=False),\n",
       " 'best_test_proba': array([[0.00000000e+000, 1.00000000e+000],\n",
       "        [9.88281504e-001, 1.17184964e-002],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.68985782e-046, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 1.61042216e-200],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 8.87921689e-283],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [9.99856637e-001, 1.43362729e-004],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [9.09107526e-138, 1.00000000e+000],\n",
       "        [1.75562746e-187, 1.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 3.49512954e-176],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [2.16646342e-056, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [3.92082864e-263, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 2.52113828e-151],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 4.25888867e-054],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 1.20470174e-145],\n",
       "        [9.85037440e-052, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 9.54623988e-060],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [2.34713789e-287, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.99612412e-273, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [2.44211306e-099, 1.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [3.02611963e-138, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [2.12317823e-179, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 2.06803641e-136],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 1.20614720e-275],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [9.82415961e-109, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.59282387e-254, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 1.42595624e-117],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [4.18035144e-293, 1.00000000e+000],\n",
       "        [1.00000000e+000, 4.07843722e-130],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [3.80355738e-283, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [5.24525036e-193, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [5.35800704e-059, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 2.69512729e-170],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.20504695e-185, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 4.20599002e-198],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 4.53896219e-086],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [3.00305305e-015, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.86278484e-034, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000]]),\n",
       " 'best_y_hat': array(['purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'purr', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'purr', 'purr',\n",
       "        'purr', 'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'purr', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps'], dtype=object),\n",
       " 'all_scores': {'mean_fit_time': array([ 2.43573437,  2.44917974,  2.46617918,  2.48641391,  3.25386362,\n",
       "          1.59180412,  3.04286542, 13.35266542,  9.19315243,  2.71638613]),\n",
       "  'std_fit_time': array([0.01206352, 0.01718028, 0.01113092, 0.0196749 , 0.21989034,\n",
       "         0.0962978 , 0.20774525, 0.72087071, 0.66859568, 0.37778339]),\n",
       "  'mean_score_time': array([0.00841622, 0.00773325, 0.00538168, 0.00713062, 0.01084862,\n",
       "         0.00843034, 0.00991321, 0.0097014 , 0.00755734, 0.00938702]),\n",
       "  'std_score_time': array([0.00381289, 0.00153937, 0.00042273, 0.00201399, 0.00076761,\n",
       "         0.000528  , 0.00144677, 0.00130302, 0.00235882, 0.00122897]),\n",
       "  'param_model__solver': masked_array(data=['sag', 'sag', 'sag', 'sag', 'lbfgs', 'lbfgs', 'lbfgs',\n",
       "                     'newton-cg', 'newton-cg', 'lbfgs'],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__penalty': masked_array(data=['l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                     'l2'],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__C': masked_array(data=[10000.0, 2.7825594022071245, 21.544346900318832,\n",
       "                     3593.813663804626, 166.81005372000593, 1.0,\n",
       "                     1291.5496650148827, 2.7825594022071245,\n",
       "                     464.15888336127773, 59.94842503189409],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'model__solver': 'sag',\n",
       "    'model__penalty': 'l2',\n",
       "    'model__C': 10000.0},\n",
       "   {'model__solver': 'sag',\n",
       "    'model__penalty': 'l2',\n",
       "    'model__C': 2.7825594022071245},\n",
       "   {'model__solver': 'sag',\n",
       "    'model__penalty': 'l2',\n",
       "    'model__C': 21.544346900318832},\n",
       "   {'model__solver': 'sag',\n",
       "    'model__penalty': 'l2',\n",
       "    'model__C': 3593.813663804626},\n",
       "   {'model__solver': 'lbfgs',\n",
       "    'model__penalty': 'l2',\n",
       "    'model__C': 166.81005372000593},\n",
       "   {'model__solver': 'lbfgs', 'model__penalty': 'l2', 'model__C': 1.0},\n",
       "   {'model__solver': 'lbfgs',\n",
       "    'model__penalty': 'l2',\n",
       "    'model__C': 1291.5496650148827},\n",
       "   {'model__solver': 'newton-cg',\n",
       "    'model__penalty': 'l2',\n",
       "    'model__C': 2.7825594022071245},\n",
       "   {'model__solver': 'newton-cg',\n",
       "    'model__penalty': 'l2',\n",
       "    'model__C': 464.15888336127773},\n",
       "   {'model__solver': 'lbfgs',\n",
       "    'model__penalty': 'l2',\n",
       "    'model__C': 59.94842503189409}],\n",
       "  'split0_test_score': array([0.91666667, 0.91666667, 0.91666667, 0.91666667, 0.89583333,\n",
       "         0.89583333, 0.91666667, 0.90972222, 0.91319444, 0.92013889]),\n",
       "  'split1_test_score': array([0.93728223, 0.93728223, 0.93728223, 0.93728223, 0.93031359,\n",
       "         0.93031359, 0.93031359, 0.93379791, 0.92682927, 0.92682927]),\n",
       "  'split2_test_score': array([0.90940767, 0.90940767, 0.90940767, 0.90940767, 0.91637631,\n",
       "         0.91289199, 0.91637631, 0.90592334, 0.90592334, 0.92334495]),\n",
       "  'split3_test_score': array([0.87456446, 0.87456446, 0.87456446, 0.87456446, 0.8815331 ,\n",
       "         0.86759582, 0.8815331 , 0.88501742, 0.88850174, 0.87456446]),\n",
       "  'split4_test_score': array([0.93728223, 0.93728223, 0.93728223, 0.93728223, 0.92682927,\n",
       "         0.93728223, 0.93379791, 0.93379791, 0.93379791, 0.93379791]),\n",
       "  'mean_test_score': array([0.91504178, 0.91504178, 0.91504178, 0.91504178, 0.91016713,\n",
       "         0.90877437, 0.91573816, 0.91364903, 0.91364903, 0.91573816]),\n",
       "  'std_test_score': array([0.02306611, 0.02306611, 0.02306611, 0.02306611, 0.01869184,\n",
       "         0.02512019, 0.01848602, 0.01846995, 0.01594421, 0.02107221]),\n",
       "  'rank_test_score': array([ 3,  3,  3,  3,  9, 10,  1,  7,  7,  1], dtype=int32)}}"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and fit logistic regression with  RandomizedSearchCV: 3rd set of parameteres\n",
    "from src.models import model_sel_rand_search\n",
    "\n",
    "# Function arguments:\n",
    "model = LogisticRegression(random_state=3, multi_class='multinomial')\n",
    "transformer = RandomOverSampler(random_state=3, sampling_strategy='minority')\n",
    "CV = 5\n",
    "\n",
    "# Function arguments: classifier params\n",
    "penalty = ['l2']\n",
    "C = np.logspace(0, 4, 10)\n",
    "solver = ['sag', 'lbfgs', 'newton-cg']\n",
    "\n",
    "param_distributions = dict(\n",
    "        model__C = C, \n",
    "        model__penalty = penalty,\n",
    "        model__solver=solver\n",
    ")\n",
    "\n",
    "# Call parameter selection function\n",
    "logreg3_2_cls_scores_params, logreg3_2_cls_model = model_sel_rand_search.train_fit_time(model,\n",
    "                                                                               param_distributions,\n",
    "                                                                               transformer,\n",
    "                                                                               X_train,\n",
    "                                                                               X_test,\n",
    "                                                                               y_train,\n",
    "                                                                               y_test,\n",
    "                                                                               CV)\n",
    "# Pickle results\n",
    "with open('/Users/greenapple/project3/models/logreg3_2_cls_scores_params_rand.pkl', 'wb') as f:\n",
    "    pickle.dump(logreg3_2_cls_scores_params, f)\n",
    "    \n",
    "# Pickle model\n",
    "with open('/Users/greenapple/project3/models/logreg3_2_cls_model_rand.pkl', 'wb') as f:\n",
    "    pickle.dump(logreg3_2_cls_model, f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_train_score': 0.9136490250696379,\n",
       " 'best_test_score': 0.8944444444444444,\n",
       " 'time_sec': 11.059135,\n",
       " 'time_best_fit_sec': 0.2037918,\n",
       " 'best_params': {'model__penalty': 'l1', 'model__C': 3593.813663804626},\n",
       " 'best_estimator': Pipeline(memory=None,\n",
       "          steps=[('transformer',\n",
       "                  RandomOverSampler(random_state=3, ratio=None,\n",
       "                                    return_indices=False,\n",
       "                                    sampling_strategy='minority')),\n",
       "                 ('model',\n",
       "                  LogisticRegression(C=3593.813663804626, class_weight=None,\n",
       "                                     dual=False, fit_intercept=True,\n",
       "                                     intercept_scaling=1, l1_ratio=None,\n",
       "                                     max_iter=100, multi_class='warn',\n",
       "                                     n_jobs=None, penalty='l1', random_state=3,\n",
       "                                     solver='warn', tol=0.0001, verbose=0,\n",
       "                                     warm_start=False))],\n",
       "          verbose=False),\n",
       " 'best_test_proba': array([[1.44307450e-05, 9.99985569e-01],\n",
       "        [9.93230543e-01, 6.76945688e-03],\n",
       "        [1.00000000e+00, 8.41063940e-12],\n",
       "        [9.99905856e-01, 9.41443581e-05],\n",
       "        [9.99999943e-01, 5.65763650e-08],\n",
       "        [9.99999952e-01, 4.84773314e-08],\n",
       "        [1.00000000e+00, 1.23912121e-12],\n",
       "        [1.00000000e+00, 2.58798695e-27],\n",
       "        [9.99999996e-01, 3.65893132e-09],\n",
       "        [0.00000000e+00, 1.00000000e+00],\n",
       "        [9.99993568e-01, 6.43218275e-06],\n",
       "        [9.99999725e-01, 2.74762699e-07],\n",
       "        [1.00000000e+00, 1.73889773e-13],\n",
       "        [1.00000000e+00, 3.24394414e-19],\n",
       "        [9.99999993e-01, 6.73126100e-09],\n",
       "        [9.99999998e-01, 1.64694506e-09],\n",
       "        [9.99924751e-01, 7.52492475e-05],\n",
       "        [1.00000000e+00, 2.95577504e-26],\n",
       "        [9.94622367e-01, 5.37763312e-03],\n",
       "        [1.41381372e-02, 9.85861863e-01],\n",
       "        [1.00000000e+00, 2.01896697e-19],\n",
       "        [7.86111532e-04, 9.99213888e-01],\n",
       "        [1.00000000e+00, 7.51382869e-20],\n",
       "        [1.00000000e+00, 1.41747597e-11],\n",
       "        [9.99999998e-01, 1.63062234e-09],\n",
       "        [1.00000000e+00, 1.19712317e-10],\n",
       "        [9.99999996e-01, 3.84326797e-09],\n",
       "        [9.99999924e-01, 7.58352026e-08],\n",
       "        [1.00000000e+00, 5.08771591e-11],\n",
       "        [1.00000000e+00, 3.12153807e-11],\n",
       "        [9.11219966e-01, 8.87800343e-02],\n",
       "        [1.00000000e+00, 4.56198637e-14],\n",
       "        [8.93555317e-01, 1.06444683e-01],\n",
       "        [9.99999992e-01, 7.51691927e-09],\n",
       "        [1.35375666e-09, 9.99999999e-01],\n",
       "        [1.00000000e+00, 4.93317596e-10],\n",
       "        [1.00000000e+00, 4.25125184e-20],\n",
       "        [1.00000000e+00, 3.76406962e-18],\n",
       "        [1.00000000e+00, 1.53978956e-16],\n",
       "        [4.99919067e-01, 5.00080933e-01],\n",
       "        [1.00000000e+00, 5.08759005e-25],\n",
       "        [1.00000000e+00, 4.65512641e-10],\n",
       "        [9.99999995e-01, 4.89760648e-09],\n",
       "        [2.62091255e-03, 9.97379087e-01],\n",
       "        [2.40756086e-02, 9.75924391e-01],\n",
       "        [2.39002858e-07, 9.99999761e-01],\n",
       "        [1.00000000e+00, 5.45044794e-18],\n",
       "        [2.45621160e-01, 7.54378840e-01],\n",
       "        [1.00000000e+00, 2.29840556e-13],\n",
       "        [1.00000000e+00, 4.80831563e-18],\n",
       "        [3.43463443e-08, 9.99999966e-01],\n",
       "        [1.00000000e+00, 3.51156840e-13],\n",
       "        [9.99664944e-01, 3.35056002e-04],\n",
       "        [9.99999935e-01, 6.45822635e-08],\n",
       "        [1.00000000e+00, 1.06981884e-11],\n",
       "        [9.99997588e-01, 2.41183782e-06],\n",
       "        [1.00000000e+00, 3.26298745e-14],\n",
       "        [1.00000000e+00, 2.81157946e-10],\n",
       "        [1.00000000e+00, 7.56139997e-18],\n",
       "        [1.00000000e+00, 3.03608111e-12],\n",
       "        [1.00000000e+00, 9.93320293e-11],\n",
       "        [1.00000000e+00, 7.07056437e-14],\n",
       "        [8.99191610e-05, 9.99910081e-01],\n",
       "        [9.95541452e-01, 4.45854812e-03],\n",
       "        [2.53187249e-10, 1.00000000e+00],\n",
       "        [9.99980820e-01, 1.91799495e-05],\n",
       "        [1.00000000e+00, 7.14270332e-12],\n",
       "        [1.00000000e+00, 2.41300199e-17],\n",
       "        [1.00000000e+00, 9.83602605e-17],\n",
       "        [1.00000000e+00, 1.46695631e-10],\n",
       "        [9.99999991e-01, 9.28513854e-09],\n",
       "        [9.75007376e-01, 2.49926241e-02],\n",
       "        [1.00000000e+00, 1.96578095e-13],\n",
       "        [1.00000000e+00, 3.70371809e-10],\n",
       "        [9.99999999e-01, 1.21145446e-09],\n",
       "        [8.93165599e-08, 9.99999911e-01],\n",
       "        [9.65155561e-01, 3.48444386e-02],\n",
       "        [9.99999869e-01, 1.31248478e-07],\n",
       "        [1.00000000e+00, 4.13729416e-19],\n",
       "        [9.99999997e-01, 2.81901681e-09],\n",
       "        [1.00000000e+00, 4.92556654e-11],\n",
       "        [1.00000000e+00, 1.88977139e-10],\n",
       "        [1.91013717e-04, 9.99808986e-01],\n",
       "        [1.00000000e+00, 4.58585249e-19],\n",
       "        [9.99999672e-01, 3.27518899e-07],\n",
       "        [1.00000000e+00, 1.02111064e-19],\n",
       "        [9.99999998e-01, 1.73896652e-09],\n",
       "        [1.00000000e+00, 1.28057866e-16],\n",
       "        [9.99999994e-01, 5.87340797e-09],\n",
       "        [9.99999947e-01, 5.25376966e-08],\n",
       "        [2.08074631e-04, 9.99791925e-01],\n",
       "        [9.99998287e-01, 1.71317535e-06],\n",
       "        [0.00000000e+00, 1.00000000e+00],\n",
       "        [1.00000000e+00, 1.27315709e-15],\n",
       "        [1.00000000e+00, 2.43238649e-17],\n",
       "        [9.99999826e-01, 1.74471593e-07],\n",
       "        [5.16208605e-05, 9.99948379e-01],\n",
       "        [1.00000000e+00, 1.48366511e-11],\n",
       "        [1.00000000e+00, 3.97358458e-23],\n",
       "        [1.00000000e+00, 1.69212914e-14],\n",
       "        [1.00000000e+00, 9.10700625e-16],\n",
       "        [1.00000000e+00, 2.65886502e-15],\n",
       "        [1.00000000e+00, 1.75769415e-16],\n",
       "        [5.71258354e-01, 4.28741646e-01],\n",
       "        [1.00000000e+00, 4.09130320e-11],\n",
       "        [1.00000000e+00, 2.93224697e-13],\n",
       "        [1.00000000e+00, 4.69342277e-19],\n",
       "        [9.99999514e-01, 4.86135174e-07],\n",
       "        [1.52061372e-08, 9.99999985e-01],\n",
       "        [9.97593929e-01, 2.40607091e-03],\n",
       "        [1.00000000e+00, 1.15877512e-11],\n",
       "        [9.99994726e-01, 5.27445944e-06],\n",
       "        [1.00000000e+00, 3.85635494e-14],\n",
       "        [9.99999987e-01, 1.29552841e-08],\n",
       "        [3.14380889e-01, 6.85619111e-01],\n",
       "        [1.00000000e+00, 1.78409393e-11],\n",
       "        [9.99999857e-01, 1.43260106e-07],\n",
       "        [3.28299536e-02, 9.67170046e-01],\n",
       "        [5.52480928e-01, 4.47519072e-01],\n",
       "        [9.99999995e-01, 5.00658854e-09],\n",
       "        [9.99855648e-01, 1.44351922e-04],\n",
       "        [9.76016929e-01, 2.39830705e-02],\n",
       "        [9.99829013e-01, 1.70986952e-04],\n",
       "        [3.14483733e-02, 9.68551627e-01],\n",
       "        [9.99999998e-01, 1.88680970e-09],\n",
       "        [5.28690933e-02, 9.47130907e-01],\n",
       "        [2.67736811e-01, 7.32263189e-01],\n",
       "        [9.99999276e-01, 7.23727370e-07],\n",
       "        [6.51242075e-01, 3.48757925e-01],\n",
       "        [9.99887474e-01, 1.12526073e-04],\n",
       "        [9.99997955e-01, 2.04461187e-06],\n",
       "        [9.92407191e-01, 7.59280943e-03],\n",
       "        [1.00000000e+00, 9.80793813e-15],\n",
       "        [1.00000000e+00, 7.09645122e-11],\n",
       "        [1.00000000e+00, 3.47045103e-18],\n",
       "        [1.00000000e+00, 1.84381720e-13],\n",
       "        [9.99985260e-01, 1.47398154e-05],\n",
       "        [9.99999987e-01, 1.28827213e-08],\n",
       "        [1.00000000e+00, 1.64249943e-11],\n",
       "        [1.00000000e+00, 4.75524915e-24],\n",
       "        [9.99999939e-01, 6.13155726e-08],\n",
       "        [9.99999997e-01, 2.77540323e-09],\n",
       "        [5.44994026e-03, 9.94550060e-01],\n",
       "        [9.99979639e-01, 2.03607811e-05],\n",
       "        [1.00000000e+00, 2.40357270e-13],\n",
       "        [1.00000000e+00, 4.29417603e-10],\n",
       "        [9.99999958e-01, 4.18359946e-08],\n",
       "        [9.99999225e-01, 7.74934168e-07],\n",
       "        [1.00000000e+00, 4.56630258e-13],\n",
       "        [1.00000000e+00, 4.77678600e-13],\n",
       "        [1.00000000e+00, 6.25914716e-14],\n",
       "        [1.00000000e+00, 2.06934302e-14],\n",
       "        [7.28336474e-05, 9.99927166e-01],\n",
       "        [1.00000000e+00, 8.80474113e-12],\n",
       "        [1.00000000e+00, 1.04777584e-16],\n",
       "        [1.00000000e+00, 2.35582808e-13],\n",
       "        [6.96159525e-03, 9.93038405e-01],\n",
       "        [9.15537194e-01, 8.44628061e-02],\n",
       "        [9.99999999e-01, 5.78866851e-10],\n",
       "        [9.99542253e-01, 4.57746539e-04],\n",
       "        [1.00000000e+00, 1.88354547e-10],\n",
       "        [9.99999999e-01, 9.66637399e-10],\n",
       "        [9.99999998e-01, 2.04461167e-09],\n",
       "        [1.00000000e+00, 6.13521238e-19],\n",
       "        [1.82121182e-03, 9.98178788e-01],\n",
       "        [9.99999986e-01, 1.36953701e-08],\n",
       "        [1.00000000e+00, 6.49228094e-15],\n",
       "        [1.00000000e+00, 4.48599066e-26],\n",
       "        [1.25246480e-11, 1.00000000e+00],\n",
       "        [9.26665809e-02, 9.07333419e-01],\n",
       "        [9.58992045e-07, 9.99999041e-01],\n",
       "        [9.99907805e-01, 9.21950177e-05],\n",
       "        [1.00000000e+00, 1.41534086e-19],\n",
       "        [6.74066585e-03, 9.93259334e-01],\n",
       "        [9.99850848e-01, 1.49151636e-04],\n",
       "        [1.00000000e+00, 3.59123008e-17],\n",
       "        [9.99974694e-01, 2.53064467e-05],\n",
       "        [9.99821244e-01, 1.78755722e-04],\n",
       "        [1.41455454e-05, 9.99985854e-01],\n",
       "        [1.00000000e+00, 6.42252324e-16],\n",
       "        [6.84002692e-01, 3.15997308e-01],\n",
       "        [1.00000000e+00, 6.84693591e-12],\n",
       "        [9.99990418e-01, 9.58205585e-06],\n",
       "        [9.89993690e-01, 1.00063100e-02],\n",
       "        [9.99999902e-01, 9.81853065e-08],\n",
       "        [1.00000000e+00, 2.03275578e-26],\n",
       "        [1.00000000e+00, 1.14790661e-14],\n",
       "        [0.00000000e+00, 1.00000000e+00],\n",
       "        [9.99887962e-01, 1.12037644e-04],\n",
       "        [1.00000000e+00, 3.17781615e-18],\n",
       "        [1.00000000e+00, 1.06290111e-13],\n",
       "        [1.00000000e+00, 1.47341386e-15],\n",
       "        [1.00000000e+00, 1.47818470e-13],\n",
       "        [1.00000000e+00, 3.06114131e-12],\n",
       "        [1.00000000e+00, 1.38147717e-17],\n",
       "        [9.99167742e-01, 8.32257557e-04],\n",
       "        [1.00000000e+00, 2.16457945e-16],\n",
       "        [9.99999988e-01, 1.24464530e-08],\n",
       "        [1.60833310e-07, 9.99999839e-01],\n",
       "        [3.46765084e-01, 6.53234916e-01],\n",
       "        [1.00000000e+00, 4.20074165e-17],\n",
       "        [0.00000000e+00, 1.00000000e+00],\n",
       "        [9.99999993e-01, 6.79046786e-09],\n",
       "        [9.99909627e-01, 9.03734443e-05],\n",
       "        [1.00000000e+00, 1.69607530e-16],\n",
       "        [9.99999940e-01, 6.03388475e-08],\n",
       "        [1.00000000e+00, 7.32073149e-13],\n",
       "        [6.14840657e-03, 9.93851593e-01],\n",
       "        [3.75443899e-01, 6.24556101e-01],\n",
       "        [9.99988268e-01, 1.17324759e-05],\n",
       "        [9.99999988e-01, 1.24246587e-08],\n",
       "        [9.99999989e-01, 1.08363290e-08],\n",
       "        [9.99834670e-01, 1.65329626e-04],\n",
       "        [9.99999999e-01, 5.74413222e-10],\n",
       "        [2.30116691e-04, 9.99769883e-01],\n",
       "        [9.99958426e-01, 4.15740489e-05],\n",
       "        [1.00000000e+00, 5.60161277e-14],\n",
       "        [7.89259599e-04, 9.99210740e-01],\n",
       "        [1.00000000e+00, 3.38953337e-15],\n",
       "        [1.00000000e+00, 9.18761197e-25],\n",
       "        [9.82272799e-01, 1.77272012e-02],\n",
       "        [8.94171447e-02, 9.10582855e-01],\n",
       "        [1.00000000e+00, 4.36329820e-18],\n",
       "        [9.97054188e-01, 2.94581193e-03],\n",
       "        [9.98129045e-01, 1.87095533e-03],\n",
       "        [1.00000000e+00, 4.80222004e-16],\n",
       "        [9.99998636e-01, 1.36430568e-06],\n",
       "        [1.00000000e+00, 5.22951502e-22],\n",
       "        [1.00000000e+00, 2.93257921e-20],\n",
       "        [3.52409468e-02, 9.64759053e-01],\n",
       "        [1.00000000e+00, 1.78566162e-12],\n",
       "        [1.00000000e+00, 5.14948161e-15],\n",
       "        [9.99974358e-01, 2.56423318e-05],\n",
       "        [1.00000000e+00, 4.56378061e-10],\n",
       "        [1.00000000e+00, 1.04196710e-12],\n",
       "        [1.00000000e+00, 4.28484222e-13],\n",
       "        [9.99999972e-01, 2.79681756e-08],\n",
       "        [1.00000000e+00, 1.90363507e-17],\n",
       "        [9.99999999e-01, 5.31518675e-10],\n",
       "        [1.00000000e+00, 1.84015295e-26],\n",
       "        [6.27294886e-03, 9.93727051e-01],\n",
       "        [1.00000000e+00, 3.10089481e-14],\n",
       "        [1.00000000e+00, 1.56966680e-14],\n",
       "        [1.16097538e-02, 9.88390246e-01],\n",
       "        [9.73376606e-01, 2.66233944e-02],\n",
       "        [1.00000000e+00, 4.71687693e-12],\n",
       "        [1.00000000e+00, 2.49536848e-13],\n",
       "        [1.00000000e+00, 1.18049465e-23],\n",
       "        [2.81897411e-04, 9.99718103e-01],\n",
       "        [1.00000000e+00, 2.76378387e-17],\n",
       "        [1.00000000e+00, 1.14546436e-18],\n",
       "        [4.55807398e-04, 9.99544193e-01],\n",
       "        [9.92759418e-01, 7.24058189e-03],\n",
       "        [2.34664231e-07, 9.99999765e-01],\n",
       "        [1.00000000e+00, 1.49959098e-11],\n",
       "        [1.00000000e+00, 1.85058715e-10],\n",
       "        [1.00000000e+00, 1.91711652e-15],\n",
       "        [1.00000000e+00, 2.80288713e-14],\n",
       "        [9.99999988e-01, 1.23018764e-08],\n",
       "        [3.21363280e-06, 9.99996786e-01],\n",
       "        [9.99999153e-01, 8.46776736e-07],\n",
       "        [1.00000000e+00, 8.07107540e-11],\n",
       "        [1.00000000e+00, 3.15562992e-18],\n",
       "        [1.00000000e+00, 1.87351383e-12],\n",
       "        [1.00000000e+00, 5.79791028e-16],\n",
       "        [9.99998173e-01, 1.82714737e-06],\n",
       "        [1.00000000e+00, 5.09873203e-17],\n",
       "        [1.00000000e+00, 2.31344068e-12],\n",
       "        [1.00000000e+00, 8.71016368e-15],\n",
       "        [9.99999998e-01, 2.05097496e-09],\n",
       "        [1.00000000e+00, 5.42875152e-15],\n",
       "        [1.00000000e+00, 3.09977640e-13],\n",
       "        [5.96787952e-10, 9.99999999e-01],\n",
       "        [9.99990180e-01, 9.81988503e-06],\n",
       "        [2.96800960e-07, 9.99999703e-01],\n",
       "        [9.99999417e-01, 5.83201493e-07],\n",
       "        [6.76433894e-01, 3.23566106e-01],\n",
       "        [9.99999998e-01, 2.45993728e-09],\n",
       "        [9.99999999e-01, 9.69775324e-10],\n",
       "        [9.99595797e-01, 4.04203138e-04],\n",
       "        [1.00000000e+00, 9.08635091e-18],\n",
       "        [1.00000000e+00, 9.63423939e-22],\n",
       "        [1.00000000e+00, 5.24692151e-18],\n",
       "        [1.00000000e+00, 2.99911829e-14],\n",
       "        [1.00000000e+00, 2.26386337e-16],\n",
       "        [9.99999985e-01, 1.53649771e-08],\n",
       "        [5.20971688e-09, 9.99999995e-01],\n",
       "        [1.00000000e+00, 1.38233504e-11],\n",
       "        [3.24127583e-06, 9.99996759e-01],\n",
       "        [1.30406796e-12, 1.00000000e+00],\n",
       "        [9.99994744e-01, 5.25615751e-06],\n",
       "        [9.99999926e-01, 7.36958777e-08],\n",
       "        [1.00000000e+00, 2.42336630e-14],\n",
       "        [6.86883343e-01, 3.13116657e-01],\n",
       "        [9.99999889e-01, 1.11182664e-07],\n",
       "        [1.00000000e+00, 2.30098046e-15],\n",
       "        [1.00000000e+00, 1.91231573e-13],\n",
       "        [1.00000000e+00, 1.24729287e-18],\n",
       "        [1.00000000e+00, 1.83752493e-12],\n",
       "        [9.99998837e-01, 1.16279986e-06],\n",
       "        [9.99540938e-01, 4.59062126e-04],\n",
       "        [1.00000000e+00, 7.78592601e-16],\n",
       "        [1.00000000e+00, 2.31913913e-10],\n",
       "        [1.12701497e-07, 9.99999887e-01],\n",
       "        [1.00000000e+00, 2.31023162e-10],\n",
       "        [9.92238826e-01, 7.76117409e-03],\n",
       "        [4.79234956e-01, 5.20765044e-01],\n",
       "        [9.99999998e-01, 1.66489530e-09],\n",
       "        [9.99866411e-01, 1.33588904e-04],\n",
       "        [9.99978940e-01, 2.10598281e-05],\n",
       "        [1.00000000e+00, 2.28226851e-15],\n",
       "        [1.00830455e-12, 1.00000000e+00],\n",
       "        [1.79278188e-03, 9.98207218e-01],\n",
       "        [9.98695787e-01, 1.30421273e-03],\n",
       "        [9.79468402e-01, 2.05315981e-02],\n",
       "        [1.00000000e+00, 5.62281011e-16],\n",
       "        [1.00000000e+00, 4.44686904e-14],\n",
       "        [1.45739553e-07, 9.99999854e-01],\n",
       "        [8.15624628e-03, 9.91843754e-01],\n",
       "        [1.00000000e+00, 6.50690351e-20],\n",
       "        [7.68475569e-08, 9.99999923e-01],\n",
       "        [1.00000000e+00, 7.21979645e-16],\n",
       "        [4.78075357e-11, 1.00000000e+00],\n",
       "        [9.99999992e-01, 8.41423603e-09],\n",
       "        [9.99999995e-01, 4.70800393e-09],\n",
       "        [9.99999982e-01, 1.78173621e-08],\n",
       "        [0.00000000e+00, 1.00000000e+00],\n",
       "        [3.58189034e-11, 1.00000000e+00],\n",
       "        [1.00000000e+00, 3.19640324e-10],\n",
       "        [1.00000000e+00, 1.55880474e-13],\n",
       "        [1.00000000e+00, 2.00552988e-14],\n",
       "        [1.00000000e+00, 6.15865022e-12],\n",
       "        [1.00000000e+00, 1.71063231e-18],\n",
       "        [9.99999997e-01, 3.03624630e-09],\n",
       "        [1.00000000e+00, 5.27992130e-22],\n",
       "        [1.00000000e+00, 1.59950093e-11],\n",
       "        [1.00000000e+00, 7.60558818e-25],\n",
       "        [9.99999997e-01, 2.50891172e-09],\n",
       "        [9.99999617e-01, 3.83237307e-07],\n",
       "        [1.00000000e+00, 1.46056704e-10],\n",
       "        [1.00000000e+00, 1.04858607e-15],\n",
       "        [1.00000000e+00, 2.86012261e-15],\n",
       "        [4.22853983e-06, 9.99995771e-01],\n",
       "        [9.99999999e-01, 1.19200064e-09],\n",
       "        [9.99992277e-01, 7.72315410e-06],\n",
       "        [9.99999978e-01, 2.24905451e-08],\n",
       "        [3.57152801e-01, 6.42847199e-01],\n",
       "        [6.99767449e-07, 9.99999300e-01],\n",
       "        [1.00000000e+00, 3.43358043e-10],\n",
       "        [9.98233652e-01, 1.76634800e-03],\n",
       "        [4.06032419e-02, 9.59396758e-01],\n",
       "        [1.00000000e+00, 2.16331108e-10],\n",
       "        [9.99999978e-01, 2.15947808e-08],\n",
       "        [9.99994758e-01, 5.24217381e-06],\n",
       "        [9.98884637e-01, 1.11536272e-03],\n",
       "        [1.00000000e+00, 1.16738719e-10],\n",
       "        [1.25090907e-02, 9.87490909e-01],\n",
       "        [1.00000000e+00, 2.28632528e-27],\n",
       "        [1.00000000e+00, 1.13734066e-10],\n",
       "        [1.00000000e+00, 7.48511511e-13]]),\n",
       " 'best_y_hat': array(['purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'purr', 'purr',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps', 'purr',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'purr', 'purr', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr', 'purr',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps', 'purr',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'purr', 'footsteps', 'purr',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'purr', 'purr',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps'], dtype=object),\n",
       " 'all_scores': {'mean_fit_time': array([0.37892203, 0.57728262, 0.5867269 , 0.38319559, 0.37730093,\n",
       "         0.36948729, 0.60618873, 0.36629486, 0.62745762, 0.66155238]),\n",
       "  'std_fit_time': array([0.02400646, 0.03587276, 0.0494418 , 0.01103621, 0.00635764,\n",
       "         0.0211971 , 0.06688255, 0.01746388, 0.04270232, 0.23630798]),\n",
       "  'mean_score_time': array([0.00607162, 0.00712609, 0.00619287, 0.00756197, 0.00571694,\n",
       "         0.00573788, 0.00593948, 0.00725365, 0.00690236, 0.00524387]),\n",
       "  'std_score_time': array([0.00073356, 0.00193193, 0.00075693, 0.00338388, 0.00042878,\n",
       "         0.00037894, 0.00048341, 0.00221489, 0.00066017, 0.00100708]),\n",
       "  'param_model__penalty': masked_array(data=['l1', 'l2', 'l2', 'l1', 'l1', 'l1', 'l2', 'l1', 'l2',\n",
       "                     'l2'],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__C': masked_array(data=[2.7825594022071245, 7.742636826811269,\n",
       "                     2.7825594022071245, 1.0, 3593.813663804626,\n",
       "                     21.544346900318832, 166.81005372000593,\n",
       "                     59.94842503189409, 1291.5496650148827,\n",
       "                     464.15888336127773],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'model__penalty': 'l1', 'model__C': 2.7825594022071245},\n",
       "   {'model__penalty': 'l2', 'model__C': 7.742636826811269},\n",
       "   {'model__penalty': 'l2', 'model__C': 2.7825594022071245},\n",
       "   {'model__penalty': 'l1', 'model__C': 1.0},\n",
       "   {'model__penalty': 'l1', 'model__C': 3593.813663804626},\n",
       "   {'model__penalty': 'l1', 'model__C': 21.544346900318832},\n",
       "   {'model__penalty': 'l2', 'model__C': 166.81005372000593},\n",
       "   {'model__penalty': 'l1', 'model__C': 59.94842503189409},\n",
       "   {'model__penalty': 'l2', 'model__C': 1291.5496650148827},\n",
       "   {'model__penalty': 'l2', 'model__C': 464.15888336127773}],\n",
       "  'split0_test_score': array([0.90972222, 0.90972222, 0.91319444, 0.91666667, 0.91319444,\n",
       "         0.91319444, 0.91319444, 0.91319444, 0.90972222, 0.91319444]),\n",
       "  'split1_test_score': array([0.92682927, 0.92682927, 0.91986063, 0.92334495, 0.92682927,\n",
       "         0.92334495, 0.91986063, 0.92682927, 0.92334495, 0.93031359]),\n",
       "  'split2_test_score': array([0.91289199, 0.90592334, 0.90940767, 0.90940767, 0.90592334,\n",
       "         0.90592334, 0.90940767, 0.90592334, 0.90940767, 0.90592334]),\n",
       "  'split3_test_score': array([0.88850174, 0.88501742, 0.88501742, 0.87804878, 0.89198606,\n",
       "         0.89198606, 0.88501742, 0.89198606, 0.88501742, 0.87804878]),\n",
       "  'split4_test_score': array([0.92682927, 0.93379791, 0.93379791, 0.93379791, 0.93031359,\n",
       "         0.93031359, 0.93379791, 0.93031359, 0.93379791, 0.93379791]),\n",
       "  'mean_test_score': array([0.91295265, 0.91225627, 0.91225627, 0.91225627, 0.91364903,\n",
       "         0.91295265, 0.91225627, 0.91364903, 0.91225627, 0.91225627]),\n",
       "  'std_test_score': array([0.01409079, 0.01711081, 0.01594951, 0.01888674, 0.01399944,\n",
       "         0.01340033, 0.01594951, 0.01399944, 0.01638645, 0.01999928]),\n",
       "  'rank_test_score': array([3, 5, 5, 5, 1, 3, 5, 1, 5, 5], dtype=int32)}}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unpickle results\n",
    "unpicking_out = open('/Users/greenapple/project3/models/logreg_2_cls_scores_params_rand.pkl', 'rb')\n",
    "logreg_2_cls_scores_params_rand = pickle.load(unpicking_out)\n",
    "logreg_2_cls_scores_params_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('transformer',\n",
       "                                              RandomOverSampler(random_state=3,\n",
       "                                                                ratio=None,\n",
       "                                                                return_indices=False,\n",
       "                                                                sampling_strategy='minority')),\n",
       "                                             ('model',\n",
       "                                              LogisticRegression(C=1.0,\n",
       "                                                                 class_weight=None,\n",
       "                                                                 dual=False,\n",
       "                                                                 fit_intercept=True,\n",
       "                                                                 intercept_scaling=1,\n",
       "                                                                 l1_ratio=None,\n",
       "                                                                 max_iter=100,\n",
       "                                                                 multi_class='war...\n",
       "                   iid='warn', n_iter=10, n_jobs=-1,\n",
       "                   param_distributions={'model__C': array([1.00000000e+00, 2.78255940e+00, 7.74263683e+00, 2.15443469e+01,\n",
       "       5.99484250e+01, 1.66810054e+02, 4.64158883e+02, 1.29154967e+03,\n",
       "       3.59381366e+03, 1.00000000e+04]),\n",
       "                                        'model__penalty': ['l1', 'l2']},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='f1_micro', verbose=0)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unpickle results\n",
    "unpicking_out = open('/Users/greenapple/project3/models/logreg_2_cls_model_rand.pkl', 'rb')\n",
    "logreg_2_cls_model = pickle.load(unpicking_out)\n",
    "logreg_2_cls_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick best logreg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T04:08:58.711750Z",
     "start_time": "2019-10-19T04:08:58.704570Z"
    }
   },
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T22:44:05.517998Z",
     "start_time": "2019-10-21T22:43:22.018705Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:266: UserWarning: The total space of parameters 9 is smaller than n_iter=10. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Train and fit KNN with  RandomizedSearchCV\n",
    "from src.models import model_sel_rand_search\n",
    "\n",
    "# Function arguments:\n",
    "model = KNeighborsClassifier()\n",
    "transformer = RandomOverSampler(random_state=3, sampling_strategy='minority')\n",
    "CV = 5\n",
    "\n",
    "# Function arguments: classifier params\n",
    "k_range = list(range(1, 10, 1))\n",
    "\n",
    "param_grid = dict(model__n_neighbors=k_range)\n",
    "\n",
    "# Call parameter selection function\n",
    "KNN_2_cls_scores_params, KNN_2_cls_models = model_sel_rand_search.train_fit_time(model,\n",
    "                                                                               param_grid,\n",
    "                                                                               transformer,\n",
    "                                                                               X_train,\n",
    "                                                                               X_test,\n",
    "                                                                               y_train,\n",
    "                                                                               y_test,\n",
    "                                                                               CV)\n",
    "\n",
    "# Pickle results\n",
    "with open('/Users/greenapple/project3/models/KNN_2_cls_scores_params_rand.pkl', 'wb') as f:\n",
    "    pickle.dump(KNN_2_cls_scores_params, f)\n",
    "    \n",
    "# Pickle model\n",
    "with open('/Users/greenapple/project3/models/KNN_2_cls_models_rand.pkl', 'wb') as f:\n",
    "    pickle.dump(KNN_2_cls_models, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_train_score': 0.903899721448468,\n",
       " 'best_test_score': 0.9,\n",
       " 'time_sec': 14.115907,\n",
       " 'time_best_fit_sec': 0.0217182,\n",
       " 'best_params': {'model__n_neighbors': 2},\n",
       " 'best_estimator': Pipeline(memory=None,\n",
       "          steps=[('transformer',\n",
       "                  RandomOverSampler(random_state=3, ratio=None,\n",
       "                                    return_indices=False,\n",
       "                                    sampling_strategy='minority')),\n",
       "                 ('model',\n",
       "                  KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                       metric='minkowski', metric_params=None,\n",
       "                                       n_jobs=None, n_neighbors=2, p=2,\n",
       "                                       weights='uniform'))],\n",
       "          verbose=False),\n",
       " 'best_test_proba': array([[0. , 1. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0. , 1. ],\n",
       "        [1. , 0. ],\n",
       "        [0. , 1. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0. , 1. ],\n",
       "        [0. , 1. ],\n",
       "        [1. , 0. ],\n",
       "        [0.5, 0.5],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0.5, 0.5],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0.5, 0.5],\n",
       "        [0. , 1. ],\n",
       "        [0. , 1. ],\n",
       "        [0. , 1. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0. , 1. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0. , 1. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0. , 1. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0. , 1. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0. , 1. ],\n",
       "        [0.5, 0.5],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0. , 1. ],\n",
       "        [1. , 0. ],\n",
       "        [0. , 1. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0. , 1. ],\n",
       "        [0. , 1. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0. , 1. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0.5, 0.5],\n",
       "        [1. , 0. ],\n",
       "        [0. , 1. ],\n",
       "        [1. , 0. ],\n",
       "        [0. , 1. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0. , 1. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0. , 1. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0. , 1. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0. , 1. ],\n",
       "        [0. , 1. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0. , 1. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0. , 1. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0. , 1. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0. , 1. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0. , 1. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0.5, 0.5],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0. , 1. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0. , 1. ],\n",
       "        [0. , 1. ],\n",
       "        [0. , 1. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0. , 1. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0.5, 0.5],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0. , 1. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0.5, 0.5],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0.5, 0.5],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0. , 1. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0. , 1. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0. , 1. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0. , 1. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0. , 1. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0.5, 0.5],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0. , 1. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0. , 1. ],\n",
       "        [0. , 1. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0. , 1. ],\n",
       "        [1. , 0. ],\n",
       "        [0. , 1. ],\n",
       "        [0. , 1. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0. , 1. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0.5, 0.5],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0. , 1. ],\n",
       "        [0. , 1. ],\n",
       "        [0. , 1. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0. , 1. ],\n",
       "        [0. , 1. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0. , 1. ],\n",
       "        [0. , 1. ],\n",
       "        [1. , 0. ],\n",
       "        [0. , 1. ],\n",
       "        [1. , 0. ],\n",
       "        [0. , 1. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0. , 1. ],\n",
       "        [0. , 1. ],\n",
       "        [0.5, 0.5],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0.5, 0.5],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0.5, 0.5],\n",
       "        [0. , 1. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0. , 1. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [0.5, 0.5],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ],\n",
       "        [1. , 0. ]]),\n",
       " 'best_y_hat': array(['purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'purr', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'purr', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'purr', 'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'purr', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'purr', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'purr', 'footsteps', 'purr',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps'], dtype=object),\n",
       " 'all_scores': {'mean_fit_time': array([0.05779967, 0.07035608, 0.06463275, 0.10882039, 0.06431141,\n",
       "         0.06434431, 0.07483659, 0.07153239, 0.08699899]),\n",
       "  'std_fit_time': array([0.01074678, 0.00840742, 0.00621673, 0.02988581, 0.00515198,\n",
       "         0.00404415, 0.01628705, 0.00868951, 0.04295035]),\n",
       "  'mean_score_time': array([1.11881471, 1.05950375, 1.14105306, 1.30342498, 1.11733217,\n",
       "         1.13116107, 1.12028794, 1.2164012 , 0.96134253]),\n",
       "  'std_score_time': array([0.11244649, 0.06615023, 0.15957293, 0.09142979, 0.11431602,\n",
       "         0.1407154 , 0.07399889, 0.18395193, 0.11009737]),\n",
       "  'param_model__n_neighbors': masked_array(data=[1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'model__n_neighbors': 1},\n",
       "   {'model__n_neighbors': 2},\n",
       "   {'model__n_neighbors': 3},\n",
       "   {'model__n_neighbors': 4},\n",
       "   {'model__n_neighbors': 5},\n",
       "   {'model__n_neighbors': 6},\n",
       "   {'model__n_neighbors': 7},\n",
       "   {'model__n_neighbors': 8},\n",
       "   {'model__n_neighbors': 9}],\n",
       "  'split0_test_score': array([0.89236111, 0.89236111, 0.85416667, 0.85763889, 0.84027778,\n",
       "         0.84027778, 0.83333333, 0.83680556, 0.83333333]),\n",
       "  'split1_test_score': array([0.90940767, 0.90940767, 0.89547038, 0.89547038, 0.8641115 ,\n",
       "         0.88501742, 0.8641115 , 0.87108014, 0.83972125]),\n",
       "  'split2_test_score': array([0.89198606, 0.89198606, 0.8815331 , 0.8815331 , 0.87108014,\n",
       "         0.89198606, 0.88850174, 0.89547038, 0.86759582]),\n",
       "  'split3_test_score': array([0.87804878, 0.88501742, 0.85365854, 0.86062718, 0.82229965,\n",
       "         0.85017422, 0.83275261, 0.83972125, 0.81881533]),\n",
       "  'split4_test_score': array([0.93728223, 0.94076655, 0.91637631, 0.91289199, 0.89547038,\n",
       "         0.91289199, 0.90592334, 0.91289199, 0.89198606]),\n",
       "  'mean_test_score': array([0.90181058, 0.90389972, 0.88022284, 0.8816156 , 0.8586351 ,\n",
       "         0.87604457, 0.86490251, 0.87116992, 0.85027855]),\n",
       "  'std_test_score': array([0.02032369, 0.02010061, 0.02419169, 0.02090957, 0.02528996,\n",
       "         0.02699197, 0.02922664, 0.03000719, 0.02617842]),\n",
       "  'rank_test_score': array([2, 1, 4, 3, 8, 5, 7, 6, 9], dtype=int32)}}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unpickle results\n",
    "unpicking_out = open('/Users/greenapple/project3/models/KNN_2_cls_scores_params_rand.pkl', 'rb')\n",
    "KNN_2_cls_scores_params_rand = pickle.load(unpicking_out)\n",
    "KNN_2_cls_scores_params_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('transformer',\n",
       "                                              RandomOverSampler(random_state=3,\n",
       "                                                                ratio=None,\n",
       "                                                                return_indices=False,\n",
       "                                                                sampling_strategy='minority')),\n",
       "                                             ('model',\n",
       "                                              KNeighborsClassifier(algorithm='auto',\n",
       "                                                                   leaf_size=30,\n",
       "                                                                   metric='minkowski',\n",
       "                                                                   metric_params=None,\n",
       "                                                                   n_jobs=None,\n",
       "                                                                   n_neighbors=5,\n",
       "                                                                   p=2,\n",
       "                                                                   weights='uniform'))],\n",
       "                                      verbose=False),\n",
       "                   iid='warn', n_iter=10, n_jobs=-1,\n",
       "                   param_distributions={'model__n_neighbors': [1, 2, 3, 4, 5, 6,\n",
       "                                                               7, 8, 9]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='f1_micro', verbose=0)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unpickle results\n",
    "unpicking_out = open('/Users/greenapple/project3/models/KNN_2_cls_models_rand.pkl', 'rb')\n",
    "KNN_2_cls_model_rand = pickle.load(unpicking_out)\n",
    "KNN_2_cls_model_rand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes MultiNomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T22:46:31.708756Z",
     "start_time": "2019-10-21T22:46:31.269131Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:266: UserWarning: The total space of parameters 3 is smaller than n_iter=10. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Train and fit naive Bayes MultiNomial with RandomizedSearchCV\n",
    "from src.models import model_sel_rand_search\n",
    "\n",
    "# Function arguments:\n",
    "model = MultinomialNB()\n",
    "transformer = RandomOverSampler(random_state=3, sampling_strategy='minority')\n",
    "CV = 5\n",
    "\n",
    "# Function arguments: classifier params\n",
    "alphas = [1, 10, 100]\n",
    "# Selects the min alpha. Keep alpha = 1 to make sure the model can take data it has not seen before \n",
    "# from the test set.\n",
    "\n",
    "param_grid = dict(model__alpha=alphas)\n",
    "\n",
    "# Call parameter selection function\n",
    "NBmultinomial_2_cls_scores_params, NBmultinomial_2_cls_models = model_sel_rand_search.train_fit_time(model,\n",
    "                                                                               param_grid,\n",
    "                                                                               transformer,\n",
    "                                                                               X_train,\n",
    "                                                                               X_test,\n",
    "                                                                               y_train,\n",
    "                                                                               y_test,\n",
    "                                                                               CV)\n",
    "\n",
    "# Pickle results\n",
    "with open('/Users/greenapple/project3/models/NBmultinomial_2_cls_scores_params_rand.pkl', 'wb') as f:\n",
    "    pickle.dump(NBmultinomial_2_cls_scores_params, f)\n",
    "    \n",
    "# Pickle model\n",
    "with open('/Users/greenapple/project3/models/NBmultinomial_2_cls_models_rand.pkl', 'wb') as f:\n",
    "    pickle.dump(NBmultinomial_2_cls_models, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_train_score': 0.8704735376044568,\n",
       " 'best_test_score': 0.8916666666666667,\n",
       " 'time_sec': 4.496852,\n",
       " 'time_best_fit_sec': 0.0111012,\n",
       " 'best_params': {'model__alpha': 1},\n",
       " 'best_estimator': Pipeline(memory=None,\n",
       "          steps=[('transformer',\n",
       "                  RandomOverSampler(random_state=3, ratio=None,\n",
       "                                    return_indices=False,\n",
       "                                    sampling_strategy='minority')),\n",
       "                 ('model',\n",
       "                  MultinomialNB(alpha=1, class_prior=None, fit_prior=True))],\n",
       "          verbose=False),\n",
       " 'best_test_proba': array([[0.00000000e+000, 1.00000000e+000],\n",
       "        [5.00000000e-001, 5.00000000e-001],\n",
       "        [1.00000000e+000, 8.63638130e-095],\n",
       "        [1.00000000e+000, 1.25560528e-063],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [9.99591345e-001, 4.08655261e-004],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 2.01435652e-039],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.15061600e-193, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 1.60608484e-263],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [2.43148993e-179, 1.00000000e+000],\n",
       "        [1.27221355e-102, 1.00000000e+000],\n",
       "        [1.00000000e+000, 2.93129148e-320],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 1.25213782e-081],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 5.81309699e-199],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [2.54221225e-156, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 4.16236068e-057],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 1.33909134e-061],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 1.54121256e-077],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 6.81544159e-196],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [9.99999987e-001, 1.31390626e-008],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [2.24246120e-021, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 4.16661917e-122],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 9.94043341e-110],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 6.58596159e-191],\n",
       "        [1.00000000e+000, 8.46723182e-212],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 4.09894330e-271],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [9.92994333e-122, 1.00000000e+000],\n",
       "        [1.00000000e+000, 3.09957410e-142],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 1.44747297e-287],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 2.27746950e-099],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [4.46931302e-192, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 1.13219848e-304],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 5.81196766e-277],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.01635906e-095, 1.00000000e+000],\n",
       "        [1.83574587e-248, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 2.89376804e-029],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 9.11939744e-203],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [3.08555131e-038, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.56748560e-244, 1.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 8.34627793e-188],\n",
       "        [1.00000000e+000, 3.13297706e-096],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 1.11544189e-226],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 4.49091478e-121],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [6.92840579e-136, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [9.42674693e-205, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 5.89001241e-087],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [4.25770871e-096, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 2.58477854e-318],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 2.06061427e-066],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.75479897e-265, 1.00000000e+000],\n",
       "        [1.00000000e+000, 1.52614767e-252],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 2.22151908e-255],\n",
       "        [1.00000000e+000, 1.69049747e-104],\n",
       "        [2.65891085e-027, 1.00000000e+000],\n",
       "        [1.00000000e+000, 3.59257132e-256],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 9.49873505e-223],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.18187674e-264, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 2.41051900e-172],\n",
       "        [3.66390176e-202, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 2.70337777e-105],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 2.63164749e-143],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [5.36703343e-209, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [2.36629480e-256, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 2.58984930e-078],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [7.68380848e-192, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [4.49172692e-005, 9.99955083e-001],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 3.46199383e-017],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [3.94941939e-045, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 2.58524071e-164],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [2.96984442e-189, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 1.48219694e-323],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [5.03377185e-300, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [5.18135842e-080, 1.00000000e+000],\n",
       "        [1.00000000e+000, 1.45006804e-249],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 4.62002987e-284],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [3.36652147e-157, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [3.15753835e-045, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 6.74555786e-232],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [6.55194338e-127, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 2.22646021e-238],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [5.61952313e-294, 1.00000000e+000],\n",
       "        [1.00000000e+000, 1.79081931e-205],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 1.68399589e-026],\n",
       "        [0.00000000e+000, 1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 2.18768351e-162],\n",
       "        [1.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 5.34338708e-303],\n",
       "        [1.00000000e+000, 0.00000000e+000]]),\n",
       " 'best_y_hat': array(['purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'purr', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'purr', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'purr', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'purr', 'purr',\n",
       "        'footsteps', 'purr', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr', 'purr',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'purr', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'purr', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'purr', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'purr', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'purr', 'purr',\n",
       "        'footsteps', 'footsteps', 'purr', 'purr', 'purr', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps'], dtype='<U9'),\n",
       " 'all_scores': {'mean_fit_time': array([0.03736815, 0.03737016, 0.02992005]),\n",
       "  'std_fit_time': array([0.00951955, 0.00430863, 0.0022588 ]),\n",
       "  'mean_score_time': array([0.00592055, 0.00687504, 0.00569215]),\n",
       "  'std_score_time': array([0.00076808, 0.00152874, 0.00109143]),\n",
       "  'param_model__alpha': masked_array(data=[1, 10, 100],\n",
       "               mask=[False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'model__alpha': 1}, {'model__alpha': 10}, {'model__alpha': 100}],\n",
       "  'split0_test_score': array([0.875, 0.875, 0.875]),\n",
       "  'split1_test_score': array([0.90940767, 0.90940767, 0.90940767]),\n",
       "  'split2_test_score': array([0.89198606, 0.89198606, 0.89198606]),\n",
       "  'split3_test_score': array([0.79442509, 0.79442509, 0.79442509]),\n",
       "  'split4_test_score': array([0.8815331, 0.8815331, 0.8815331]),\n",
       "  'mean_test_score': array([0.87047354, 0.87047354, 0.87047354]),\n",
       "  'std_test_score': array([0.03974768, 0.03974768, 0.03974768]),\n",
       "  'rank_test_score': array([1, 1, 1], dtype=int32)}}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unpickle results\n",
    "unpicking_out = open('/Users/greenapple/project3/models/NBmultinomial_2_cls_scores_params_rand.pkl', 'rb')\n",
    "NBmultinomial_2_cls_scores_params_rand = pickle.load(unpicking_out)\n",
    "NBmultinomial_2_cls_scores_params_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('transformer',\n",
       "                                              RandomOverSampler(random_state=3,\n",
       "                                                                ratio=None,\n",
       "                                                                return_indices=False,\n",
       "                                                                sampling_strategy='minority')),\n",
       "                                             ('model',\n",
       "                                              MultinomialNB(alpha=1.0,\n",
       "                                                            class_prior=None,\n",
       "                                                            fit_prior=True))],\n",
       "                                      verbose=False),\n",
       "                   iid='warn', n_iter=10, n_jobs=-1,\n",
       "                   param_distributions={'model__alpha': [1, 10, 100]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='f1_micro', verbose=0)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unpickle best model\n",
    "unpicking_out = open('/Users/greenapple/project3/models/NBmultinomial_2_cls_models_rand.pkl', 'rb')\n",
    "NBmultinomial_2_cls_models = pickle.load(unpicking_out)\n",
    "NBmultinomial_2_cls_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T23:20:52.968294Z",
     "start_time": "2019-10-21T22:48:22.725052Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train and fit SVC with RandomizedSearchCV\n",
    "from src.models import model_sel_rand_search\n",
    "\n",
    "# Function arguments:\n",
    "model = SVC(probability=True)\n",
    "transformer = RandomOverSampler(random_state=3, sampling_strategy='minority')\n",
    "CV = 5\n",
    "\n",
    "# Function arguments: classifier params\n",
    "kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "C = [0.001, 0.01, 0.1, 1, 10]\n",
    "gamma = [0.01, 0.1, 1, 10]\n",
    "degree = [2, 3, 4]\n",
    "\n",
    "param_grid = dict(model__C=C,\n",
    "                 model__kernel=kernel,\n",
    "                 model__gamma=gamma,\n",
    "                 model__degree=degree\n",
    "                 )\n",
    "\n",
    "# Call parameter selection function\n",
    "SVC_2_cls_scores_params, SVC_2_cls_model = model_sel_rand_search.train_fit_time(model,\n",
    "                                                                               param_grid,\n",
    "                                                                               transformer,\n",
    "                                                                               X_train,\n",
    "                                                                               X_test,\n",
    "                                                                               y_train,\n",
    "                                                                               y_test,\n",
    "                                                                               CV)\n",
    "\n",
    "# Pickle results\n",
    "with open('/Users/greenapple/project3/models/SVC_2_cls_scores_params_rand.pkl', 'wb') as f:\n",
    "    pickle.dump(SVC_2_cls_scores_params, f)\n",
    "    \n",
    "# Pickle model\n",
    "with open('/Users/greenapple/project3/models/SVC_2_cls_model_rand.pkl', 'wb') as f:\n",
    "    pickle.dump(SVC_2_cls_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_train_score': 0.9282729805013927,\n",
       " 'best_test_score': 0.9194444444444444,\n",
       " 'time_sec': 179.059009,\n",
       " 'time_best_fit_sec': 7.195515,\n",
       " 'best_params': {'model__kernel': 'poly',\n",
       "  'model__gamma': 0.01,\n",
       "  'model__degree': 4,\n",
       "  'model__C': 1},\n",
       " 'best_estimator': Pipeline(memory=None,\n",
       "          steps=[('transformer',\n",
       "                  RandomOverSampler(random_state=3, ratio=None,\n",
       "                                    return_indices=False,\n",
       "                                    sampling_strategy='minority')),\n",
       "                 ('model',\n",
       "                  SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                      decision_function_shape='ovr', degree=4, gamma=0.01,\n",
       "                      kernel='poly', max_iter=-1, probability=True,\n",
       "                      random_state=None, shrinking=True, tol=0.001,\n",
       "                      verbose=False))],\n",
       "          verbose=False),\n",
       " 'best_test_proba': array([[1.85874190e-01, 8.14125810e-01],\n",
       "        [9.99982674e-01, 1.73259139e-05],\n",
       "        [9.99981682e-01, 1.83175903e-05],\n",
       "        [9.99905628e-01, 9.43718218e-05],\n",
       "        [9.99999736e-01, 2.64428376e-07],\n",
       "        [9.99996317e-01, 3.68339739e-06],\n",
       "        [9.99993828e-01, 6.17195660e-06],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99998030e-01, 1.97025359e-06],\n",
       "        [3.00000090e-14, 1.00000000e+00],\n",
       "        [9.99987334e-01, 1.26656137e-05],\n",
       "        [9.99925733e-01, 7.42674318e-05],\n",
       "        [9.99999631e-01, 3.68941961e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99978013e-01, 2.19871368e-05],\n",
       "        [9.99998807e-01, 1.19344195e-06],\n",
       "        [9.38507132e-01, 6.14928681e-02],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.97254892e-01, 2.74510773e-03],\n",
       "        [9.96284972e-01, 3.71502846e-03],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [4.87489628e-01, 5.12510372e-01],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99998671e-01, 1.32909945e-06],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99991568e-01, 8.43173142e-06],\n",
       "        [9.99995363e-01, 4.63722661e-06],\n",
       "        [9.99999825e-01, 1.75387862e-07],\n",
       "        [9.99995743e-01, 4.25736081e-06],\n",
       "        [9.66782019e-01, 3.32179814e-02],\n",
       "        [9.99999789e-01, 2.10674453e-07],\n",
       "        [9.99985663e-01, 1.43366250e-05],\n",
       "        [9.99999861e-01, 1.39494206e-07],\n",
       "        [1.65080119e-06, 9.99998349e-01],\n",
       "        [9.99999681e-01, 3.18924408e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.96391500e-01, 3.60849988e-03],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999423e-01, 5.76532507e-07],\n",
       "        [9.99999687e-01, 3.13094478e-07],\n",
       "        [9.99506827e-01, 4.93172719e-04],\n",
       "        [9.91252495e-01, 8.74750539e-03],\n",
       "        [2.62052153e-01, 7.37947847e-01],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.98615699e-01, 1.38430147e-03],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [2.59511671e-03, 9.97404883e-01],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.98645905e-01, 1.35409492e-03],\n",
       "        [9.99993772e-01, 6.22762939e-06],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99996293e-01, 3.70684542e-06],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99996868e-01, 3.13172347e-06],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999846e-01, 1.54380143e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [7.33476206e-01, 2.66523794e-01],\n",
       "        [9.99944750e-01, 5.52495324e-05],\n",
       "        [4.15240688e-03, 9.95847593e-01],\n",
       "        [9.99896378e-01, 1.03621959e-04],\n",
       "        [9.99999105e-01, 8.95039138e-07],\n",
       "        [9.99999863e-01, 1.37385144e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99998503e-01, 1.49748564e-06],\n",
       "        [9.99987882e-01, 1.21184315e-05],\n",
       "        [9.98712896e-01, 1.28710447e-03],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999228e-01, 7.71916905e-07],\n",
       "        [9.99996067e-01, 3.93269381e-06],\n",
       "        [2.99523320e-02, 9.70047668e-01],\n",
       "        [2.92692365e-01, 7.07307635e-01],\n",
       "        [9.99889111e-01, 1.10888843e-04],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999788e-01, 2.12312269e-07],\n",
       "        [9.99997509e-01, 2.49099521e-06],\n",
       "        [9.99992949e-01, 7.05097817e-06],\n",
       "        [8.75320437e-02, 9.12467956e-01],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99998301e-01, 1.69936572e-06],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999666e-01, 3.33582927e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99996356e-01, 3.64437166e-06],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [4.63930841e-03, 9.95360692e-01],\n",
       "        [9.99992696e-01, 7.30363790e-06],\n",
       "        [2.81321480e-13, 1.00000000e+00],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99996229e-01, 3.77089147e-06],\n",
       "        [6.57243057e-01, 3.42756943e-01],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999478e-01, 5.21924957e-07],\n",
       "        [9.95144622e-01, 4.85537806e-03],\n",
       "        [9.99999588e-01, 4.12465410e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99995238e-01, 4.76150937e-06],\n",
       "        [4.78161649e-01, 5.21838351e-01],\n",
       "        [9.99991531e-01, 8.46921943e-06],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.97527556e-01, 2.47244364e-03],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.84636213e-01, 1.53637873e-02],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99991280e-01, 8.72039315e-06],\n",
       "        [8.58736910e-01, 1.41263090e-01],\n",
       "        [9.88988171e-01, 1.10118285e-02],\n",
       "        [9.99997909e-01, 2.09143774e-06],\n",
       "        [9.99948014e-01, 5.19864606e-05],\n",
       "        [9.99527562e-01, 4.72438329e-04],\n",
       "        [9.99587460e-01, 4.12540414e-04],\n",
       "        [9.41695934e-01, 5.83040663e-02],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.92306899e-01, 7.69310079e-03],\n",
       "        [9.79654055e-01, 2.03459449e-02],\n",
       "        [9.99855955e-01, 1.44044962e-04],\n",
       "        [9.36139261e-01, 6.38607392e-02],\n",
       "        [9.99987543e-01, 1.24567446e-05],\n",
       "        [9.99963086e-01, 3.69144415e-05],\n",
       "        [9.99808605e-01, 1.91395209e-04],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.98479992e-01, 1.52000831e-03],\n",
       "        [9.99970116e-01, 2.98844310e-05],\n",
       "        [9.99999362e-01, 6.38347988e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99969662e-01, 3.03378919e-05],\n",
       "        [9.99996595e-01, 3.40479496e-06],\n",
       "        [5.37241163e-01, 4.62758837e-01],\n",
       "        [9.99978432e-01, 2.15677837e-05],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99994158e-01, 5.84207803e-06],\n",
       "        [9.99998497e-01, 1.50270178e-06],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [2.59532793e-01, 7.40467207e-01],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.79599402e-01, 2.04005982e-02],\n",
       "        [9.94229944e-01, 5.77005565e-03],\n",
       "        [9.99985885e-01, 1.41151841e-05],\n",
       "        [9.98571301e-01, 1.42869889e-03],\n",
       "        [9.99999796e-01, 2.03778327e-07],\n",
       "        [9.99997953e-01, 2.04711552e-06],\n",
       "        [9.99996410e-01, 3.59003661e-06],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [3.24957082e-02, 9.67504292e-01],\n",
       "        [9.99998666e-01, 1.33359954e-06],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.43189127e-01, 5.68108735e-02],\n",
       "        [9.66026983e-01, 3.39730170e-02],\n",
       "        [2.05745764e-08, 9.99999979e-01],\n",
       "        [9.99982674e-01, 1.73259347e-05],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.14822942e-01, 8.51770582e-02],\n",
       "        [9.99268503e-01, 7.31497214e-04],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99213280e-01, 7.86720283e-04],\n",
       "        [9.98847561e-01, 1.15243876e-03],\n",
       "        [7.98870515e-01, 2.01129485e-01],\n",
       "        [9.99999893e-01, 1.06767995e-07],\n",
       "        [9.96460995e-01, 3.53900530e-03],\n",
       "        [9.99997937e-01, 2.06305914e-06],\n",
       "        [9.99908807e-01, 9.11928146e-05],\n",
       "        [9.99154883e-01, 8.45117079e-04],\n",
       "        [9.99998694e-01, 1.30620464e-06],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [3.00000090e-14, 1.00000000e+00],\n",
       "        [9.99870884e-01, 1.29116415e-04],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999123e-01, 8.77363241e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99474022e-01, 5.25977675e-04],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99996594e-01, 3.40587955e-06],\n",
       "        [1.43171523e-01, 8.56828477e-01],\n",
       "        [9.97056694e-01, 2.94330622e-03],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [1.17845213e-07, 9.99999882e-01],\n",
       "        [9.99999032e-01, 9.67773758e-07],\n",
       "        [9.99982689e-01, 1.73114189e-05],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99888850e-01, 1.11149788e-04],\n",
       "        [9.99999818e-01, 1.82070646e-07],\n",
       "        [8.85180631e-01, 1.14819369e-01],\n",
       "        [9.93636968e-01, 6.36303167e-03],\n",
       "        [9.99984895e-01, 1.51053812e-05],\n",
       "        [9.99966572e-01, 3.34276779e-05],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99926927e-01, 7.30733831e-05],\n",
       "        [9.99993392e-01, 6.60797170e-06],\n",
       "        [8.71263121e-01, 1.28736879e-01],\n",
       "        [9.99980599e-01, 1.94009281e-05],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [4.62682357e-02, 9.53731764e-01],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99544251e-01, 4.55749150e-04],\n",
       "        [8.68573186e-01, 1.31426814e-01],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.21294449e-01, 7.87055509e-02],\n",
       "        [9.99311610e-01, 6.88390460e-04],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99995080e-01, 4.92006979e-06],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.85819182e-01, 1.41808178e-02],\n",
       "        [9.99999881e-01, 1.18813635e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99989700e-01, 1.03002398e-05],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999687e-01, 3.13196149e-07],\n",
       "        [9.99997818e-01, 2.18163178e-06],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [2.81156855e-01, 7.18843145e-01],\n",
       "        [9.99999432e-01, 5.67512974e-07],\n",
       "        [9.99999502e-01, 4.98058000e-07],\n",
       "        [5.25624722e-02, 9.47437528e-01],\n",
       "        [9.95585746e-01, 4.41425401e-03],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.87867671e-01, 1.21323292e-02],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [3.25040505e-01, 6.74959495e-01],\n",
       "        [9.99958789e-01, 4.12110811e-05],\n",
       "        [9.43390743e-01, 5.66092568e-02],\n",
       "        [9.99999662e-01, 3.37920470e-07],\n",
       "        [9.99999880e-01, 1.20288176e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999483e-01, 5.16542559e-07],\n",
       "        [1.50225813e-02, 9.84977419e-01],\n",
       "        [9.99998313e-01, 1.68715631e-06],\n",
       "        [9.99999875e-01, 1.24876265e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999718e-01, 2.81857719e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99995968e-01, 4.03212459e-06],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999704e-01, 2.96016983e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999494e-01, 5.05760120e-07],\n",
       "        [9.99999484e-01, 5.15711392e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [7.75754130e-09, 9.99999992e-01],\n",
       "        [9.99951361e-01, 4.86392070e-05],\n",
       "        [4.94559938e-02, 9.50544006e-01],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.86931084e-01, 1.30689155e-02],\n",
       "        [9.99962524e-01, 3.74761374e-05],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.98604345e-01, 1.39565482e-03],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99995517e-01, 4.48331098e-06],\n",
       "        [2.60780918e-02, 9.73921908e-01],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [4.51792302e-03, 9.95482077e-01],\n",
       "        [3.27908406e-07, 9.99999672e-01],\n",
       "        [9.99999443e-01, 5.56634477e-07],\n",
       "        [9.99998674e-01, 1.32556742e-06],\n",
       "        [9.99999664e-01, 3.35692974e-07],\n",
       "        [9.98958353e-01, 1.04164738e-03],\n",
       "        [9.99994629e-01, 5.37124059e-06],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99994993e-01, 5.00689495e-06],\n",
       "        [9.91753241e-01, 8.24675908e-03],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99994824e-01, 5.17636441e-06],\n",
       "        [1.43276078e-05, 9.99985672e-01],\n",
       "        [9.99991224e-01, 8.77634382e-06],\n",
       "        [9.97336867e-01, 2.66313281e-03],\n",
       "        [9.99386562e-01, 6.13437683e-04],\n",
       "        [9.99999751e-01, 2.48595627e-07],\n",
       "        [9.99248703e-01, 7.51297432e-04],\n",
       "        [9.99855511e-01, 1.44488785e-04],\n",
       "        [9.99999779e-01, 2.20866924e-07],\n",
       "        [3.51961237e-10, 1.00000000e+00],\n",
       "        [5.26531406e-01, 4.73468594e-01],\n",
       "        [9.99921052e-01, 7.89482907e-05],\n",
       "        [9.98415901e-01, 1.58409851e-03],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [2.34966609e-06, 9.99997650e-01],\n",
       "        [9.87544120e-01, 1.24558798e-02],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [2.43484433e-02, 9.75651557e-01],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [7.56501199e-13, 1.00000000e+00],\n",
       "        [9.99998669e-01, 1.33094946e-06],\n",
       "        [9.99960956e-01, 3.90438355e-05],\n",
       "        [9.99999835e-01, 1.65261943e-07],\n",
       "        [3.00000090e-14, 1.00000000e+00],\n",
       "        [5.08071876e-09, 9.99999995e-01],\n",
       "        [9.99998336e-01, 1.66438449e-06],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99997045e-01, 2.95543524e-06],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99997661e-01, 2.33925984e-06],\n",
       "        [9.99912843e-01, 8.71569659e-05],\n",
       "        [9.99999451e-01, 5.48594883e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.46662136e-01, 5.33378641e-02],\n",
       "        [9.99999697e-01, 3.03070077e-07],\n",
       "        [9.99945173e-01, 5.48265631e-05],\n",
       "        [9.99997238e-01, 2.76186324e-06],\n",
       "        [9.82556362e-01, 1.74436385e-02],\n",
       "        [2.53476638e-03, 9.97465234e-01],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.93140690e-01, 6.85930983e-03],\n",
       "        [9.78105017e-01, 2.18949830e-02],\n",
       "        [9.99999163e-01, 8.37409141e-07],\n",
       "        [9.99999157e-01, 8.42874816e-07],\n",
       "        [9.99982078e-01, 1.79216194e-05],\n",
       "        [9.99989847e-01, 1.01534022e-05],\n",
       "        [9.99991378e-01, 8.62177354e-06],\n",
       "        [9.96552300e-01, 3.44769960e-03],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99988472e-01, 1.15275987e-05],\n",
       "        [9.99999747e-01, 2.53262849e-07]]),\n",
       " 'best_y_hat': array(['purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'purr', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps'], dtype=object),\n",
       " 'all_scores': {'mean_fit_time': array([ 6.00832663,  6.02895265, 28.75107174,  6.51144595,  7.4685904 ,\n",
       "         21.6446928 ,  6.4648335 ,  6.35945787,  6.28739138, 27.39994564]),\n",
       "  'std_fit_time': array([0.18302619, 0.17747063, 0.22886217, 0.24097292, 0.24673539,\n",
       "         0.16489084, 0.07492535, 0.15273202, 0.44149341, 3.40477517]),\n",
       "  'mean_score_time': array([0.14266553, 0.16690879, 0.78846598, 0.17336025, 0.20733576,\n",
       "         0.59486794, 0.16357131, 0.16629519, 0.16152687, 0.6663764 ]),\n",
       "  'std_score_time': array([0.00683557, 0.00444653, 0.00820688, 0.00838538, 0.01369166,\n",
       "         0.04651145, 0.00254655, 0.00694176, 0.03503801, 0.10131667]),\n",
       "  'param_model__kernel': masked_array(data=['linear', 'poly', 'sigmoid', 'poly', 'poly', 'rbf',\n",
       "                     'poly', 'poly', 'linear', 'sigmoid'],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__gamma': masked_array(data=[1, 0.01, 0.1, 0.01, 0.01, 10, 10, 1, 1, 0.01],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__degree': masked_array(data=[3, 2, 3, 2, 4, 4, 2, 2, 4, 4],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__C': masked_array(data=[0.001, 0.01, 0.001, 1, 1, 1, 0.01, 1, 0.1, 0.001],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'model__kernel': 'linear',\n",
       "    'model__gamma': 1,\n",
       "    'model__degree': 3,\n",
       "    'model__C': 0.001},\n",
       "   {'model__kernel': 'poly',\n",
       "    'model__gamma': 0.01,\n",
       "    'model__degree': 2,\n",
       "    'model__C': 0.01},\n",
       "   {'model__kernel': 'sigmoid',\n",
       "    'model__gamma': 0.1,\n",
       "    'model__degree': 3,\n",
       "    'model__C': 0.001},\n",
       "   {'model__kernel': 'poly',\n",
       "    'model__gamma': 0.01,\n",
       "    'model__degree': 2,\n",
       "    'model__C': 1},\n",
       "   {'model__kernel': 'poly',\n",
       "    'model__gamma': 0.01,\n",
       "    'model__degree': 4,\n",
       "    'model__C': 1},\n",
       "   {'model__kernel': 'rbf',\n",
       "    'model__gamma': 10,\n",
       "    'model__degree': 4,\n",
       "    'model__C': 1},\n",
       "   {'model__kernel': 'poly',\n",
       "    'model__gamma': 10,\n",
       "    'model__degree': 2,\n",
       "    'model__C': 0.01},\n",
       "   {'model__kernel': 'poly',\n",
       "    'model__gamma': 1,\n",
       "    'model__degree': 2,\n",
       "    'model__C': 1},\n",
       "   {'model__kernel': 'linear',\n",
       "    'model__gamma': 1,\n",
       "    'model__degree': 4,\n",
       "    'model__C': 0.1},\n",
       "   {'model__kernel': 'sigmoid',\n",
       "    'model__gamma': 0.01,\n",
       "    'model__degree': 4,\n",
       "    'model__C': 0.001}],\n",
       "  'split0_test_score': array([0.91666667, 0.92361111, 0.16666667, 0.92361111, 0.92708333,\n",
       "         0.83680556, 0.92361111, 0.92361111, 0.91666667, 0.16666667]),\n",
       "  'split1_test_score': array([0.92334495, 0.93379791, 0.16724739, 0.93379791, 0.92334495,\n",
       "         0.83623693, 0.93379791, 0.93379791, 0.92334495, 0.16724739]),\n",
       "  'split2_test_score': array([0.90592334, 0.90940767, 0.16724739, 0.90940767, 0.93379791,\n",
       "         0.83623693, 0.90940767, 0.90940767, 0.90592334, 0.16724739]),\n",
       "  'split3_test_score': array([0.88850174, 0.90592334, 0.16724739, 0.90592334, 0.8989547 ,\n",
       "         0.83623693, 0.90592334, 0.90592334, 0.88850174, 0.16724739]),\n",
       "  'split4_test_score': array([0.93031359, 0.94425087, 0.17073171, 0.94425087, 0.95818815,\n",
       "         0.83623693, 0.94425087, 0.94425087, 0.93031359, 0.17073171]),\n",
       "  'mean_test_score': array([0.91295265, 0.92339833, 0.1678273 , 0.92339833, 0.92827298,\n",
       "         0.83635097, 0.92339833, 0.92339833, 0.91295265, 0.1678273 ]),\n",
       "  'std_test_score': array([0.01462707, 0.01444584, 0.00146893, 0.01444584, 0.0190234 ,\n",
       "         0.00022769, 0.01444584, 0.01444584, 0.01462707, 0.00146893]),\n",
       "  'rank_test_score': array([6, 2, 9, 2, 1, 8, 2, 2, 6, 9], dtype=int32)}}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unpickle results\n",
    "unpicking_out = open('/Users/greenapple/project3/models/SVC_2_cls_scores_params_rand.pkl', 'rb')\n",
    "SVC_2_cls_scores_params_rand = pickle.load(unpicking_out)\n",
    "SVC_2_cls_scores_params_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('transformer',\n",
       "                                              RandomOverSampler(random_state=3,\n",
       "                                                                ratio=None,\n",
       "                                                                return_indices=False,\n",
       "                                                                sampling_strategy='minority')),\n",
       "                                             ('model',\n",
       "                                              SVC(C=1.0, cache_size=200,\n",
       "                                                  class_weight=None, coef0=0.0,\n",
       "                                                  decision_function_shape='ovr',\n",
       "                                                  degree=3,\n",
       "                                                  gamma='auto_deprecated',\n",
       "                                                  kernel='rbf', max_ite...\n",
       "                                                  shrinking=True, tol=0.001,\n",
       "                                                  verbose=False))],\n",
       "                                      verbose=False),\n",
       "                   iid='warn', n_iter=10, n_jobs=-1,\n",
       "                   param_distributions={'model__C': [0.001, 0.01, 0.1, 1, 10],\n",
       "                                        'model__degree': [2, 3, 4],\n",
       "                                        'model__gamma': [0.01, 0.1, 1, 10],\n",
       "                                        'model__kernel': ['linear', 'poly',\n",
       "                                                          'rbf', 'sigmoid']},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='f1_micro', verbose=0)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unpickle model\n",
    "unpicking_out = open('/Users/greenapple/project3/models/SVC_2_cls_model_rand.pkl', 'rb')\n",
    "SVC_2_cls_model = pickle.load(unpicking_out)\n",
    "SVC_2_cls_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T06:52:24.564264Z",
     "start_time": "2019-10-22T06:09:22.157127Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train and fit Random Forest\n",
    "from src.models import model_sel_rand_search\n",
    "\n",
    "# Function arguments:\n",
    "model = RandomForestClassifier(random_state=3)\n",
    "transformer = RandomOverSampler(random_state=3, sampling_strategy='minority')\n",
    "CV = 5\n",
    "\n",
    "# Function arguments: classifier params\n",
    "n_estimators = [10, 50, 100, 300, 500]\n",
    "criterion = ['gini', 'entropy']\n",
    "max_depth = [5, 10, 50, 100, None]\n",
    "min_samples_split = [2, 5, 10, 50]\n",
    "max_features = [5, 10, 25, 50, 100]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "                \n",
    "param_grid = dict(model__n_estimators=n_estimators,\n",
    "                  model__criterion=criterion,\n",
    "                  model__max_depth=max_depth,\n",
    "                  model__min_samples_split=min_samples_split,\n",
    "                  model__max_features=max_features,\n",
    "                  model__bootstrap=bootstrap\n",
    "                 )\n",
    "\n",
    "# Call parameter selection function\n",
    "RF_2_cls_scores_params, RF_2_cls_model = model_sel_rand_search.train_fit_time(model,\n",
    "                                                                        param_grid,\n",
    "                                                                        transformer,\n",
    "                                                                        X_train,\n",
    "                                                                        X_test,\n",
    "                                                                        y_train,\n",
    "                                                                        y_test,\n",
    "                                                                        CV)\n",
    "\n",
    "# Pickle results\n",
    "with open('/Users/greenapple/project3/models/RF_2_cls_scores_params_rand.pkl', 'wb') as f:\n",
    "    pickle.dump(RF_2_cls_scores_params, f)\n",
    "    \n",
    "# Pickle model\n",
    "with open('/Users/greenapple/project3/models/RF_2_cls_model_rand.pkl', 'wb') as f:\n",
    "    pickle.dump(RF_2_cls_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_train_score': 0.9115598885793872,\n",
       " 'best_test_score': 0.9222222222222223,\n",
       " 'time_sec': 50.344088,\n",
       " 'time_best_fit_sec': 1.3690788,\n",
       " 'best_params': {'model__n_estimators': 300,\n",
       "  'model__min_samples_split': 10,\n",
       "  'model__max_features': 10,\n",
       "  'model__max_depth': 10,\n",
       "  'model__criterion': 'gini',\n",
       "  'model__bootstrap': True},\n",
       " 'best_estimator': Pipeline(memory=None,\n",
       "          steps=[('transformer',\n",
       "                  RandomOverSampler(random_state=3, ratio=None,\n",
       "                                    return_indices=False,\n",
       "                                    sampling_strategy='minority')),\n",
       "                 ('model',\n",
       "                  RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                         criterion='gini', max_depth=10,\n",
       "                                         max_features=10, max_leaf_nodes=None,\n",
       "                                         min_impurity_decrease=0.0,\n",
       "                                         min_impurity_split=None,\n",
       "                                         min_samples_leaf=1,\n",
       "                                         min_samples_split=10,\n",
       "                                         min_weight_fraction_leaf=0.0,\n",
       "                                         n_estimators=300, n_jobs=None,\n",
       "                                         oob_score=False, random_state=3,\n",
       "                                         verbose=0, warm_start=False))],\n",
       "          verbose=False),\n",
       " 'best_test_proba': array([[0.55343493, 0.44656507],\n",
       "        [0.98829837, 0.01170163],\n",
       "        [0.78669394, 0.21330606],\n",
       "        [0.81249216, 0.18750784],\n",
       "        [0.91842026, 0.08157974],\n",
       "        [0.93076882, 0.06923118],\n",
       "        [0.8739357 , 0.1260643 ],\n",
       "        [0.96097394, 0.03902606],\n",
       "        [0.80711124, 0.19288876],\n",
       "        [0.12893258, 0.87106742],\n",
       "        [0.80476778, 0.19523222],\n",
       "        [0.62962101, 0.37037899],\n",
       "        [0.87394056, 0.12605944],\n",
       "        [0.97501986, 0.02498014],\n",
       "        [0.78613261, 0.21386739],\n",
       "        [0.71473789, 0.28526211],\n",
       "        [0.42814651, 0.57185349],\n",
       "        [0.85597866, 0.14402134],\n",
       "        [0.57374796, 0.42625204],\n",
       "        [0.78740019, 0.21259981],\n",
       "        [0.98588024, 0.01411976],\n",
       "        [0.37327005, 0.62672995],\n",
       "        [0.82019357, 0.17980643],\n",
       "        [0.95456616, 0.04543384],\n",
       "        [0.8314793 , 0.1685207 ],\n",
       "        [0.88214159, 0.11785841],\n",
       "        [0.92165582, 0.07834418],\n",
       "        [0.69921985, 0.30078015],\n",
       "        [0.69143011, 0.30856989],\n",
       "        [0.67100845, 0.32899155],\n",
       "        [0.58196524, 0.41803476],\n",
       "        [0.87348583, 0.12651417],\n",
       "        [0.79986496, 0.20013504],\n",
       "        [0.95210083, 0.04789917],\n",
       "        [0.16283484, 0.83716516],\n",
       "        [0.71406442, 0.28593558],\n",
       "        [0.90348322, 0.09651678],\n",
       "        [0.94999192, 0.05000808],\n",
       "        [0.86940208, 0.13059792],\n",
       "        [0.46917376, 0.53082624],\n",
       "        [0.96361439, 0.03638561],\n",
       "        [0.84156907, 0.15843093],\n",
       "        [0.91338822, 0.08661178],\n",
       "        [0.86891266, 0.13108734],\n",
       "        [0.39328171, 0.60671829],\n",
       "        [0.52854281, 0.47145719],\n",
       "        [0.93624652, 0.06375348],\n",
       "        [0.65575313, 0.34424687],\n",
       "        [0.88296562, 0.11703438],\n",
       "        [0.98129802, 0.01870198],\n",
       "        [0.35189152, 0.64810848],\n",
       "        [0.6518748 , 0.3481252 ],\n",
       "        [0.80265969, 0.19734031],\n",
       "        [0.77396191, 0.22603809],\n",
       "        [0.90055402, 0.09944598],\n",
       "        [0.76694295, 0.23305705],\n",
       "        [0.95342112, 0.04657888],\n",
       "        [0.81671744, 0.18328256],\n",
       "        [0.92428789, 0.07571211],\n",
       "        [0.87681586, 0.12318414],\n",
       "        [0.94424692, 0.05575308],\n",
       "        [0.89778515, 0.10221485],\n",
       "        [0.16225881, 0.83774119],\n",
       "        [0.8263654 , 0.1736346 ],\n",
       "        [0.45031051, 0.54968949],\n",
       "        [0.67693138, 0.32306862],\n",
       "        [0.85991007, 0.14008993],\n",
       "        [0.9023189 , 0.0976811 ],\n",
       "        [0.9263359 , 0.0736641 ],\n",
       "        [0.67014225, 0.32985775],\n",
       "        [0.79541536, 0.20458464],\n",
       "        [0.68532044, 0.31467956],\n",
       "        [0.95345166, 0.04654834],\n",
       "        [0.84070606, 0.15929394],\n",
       "        [0.86532596, 0.13467404],\n",
       "        [0.35487868, 0.64512132],\n",
       "        [0.36640415, 0.63359585],\n",
       "        [0.74069818, 0.25930182],\n",
       "        [0.94765438, 0.05234562],\n",
       "        [0.91538465, 0.08461535],\n",
       "        [0.77612967, 0.22387033],\n",
       "        [0.80018675, 0.19981325],\n",
       "        [0.23459519, 0.76540481],\n",
       "        [0.98631724, 0.01368276],\n",
       "        [0.80048365, 0.19951635],\n",
       "        [0.96000606, 0.03999394],\n",
       "        [0.85933579, 0.14066421],\n",
       "        [0.87905636, 0.12094364],\n",
       "        [0.9185203 , 0.0814797 ],\n",
       "        [0.92076749, 0.07923251],\n",
       "        [0.17784131, 0.82215869],\n",
       "        [0.73873492, 0.26126508],\n",
       "        [0.4880517 , 0.5119483 ],\n",
       "        [0.97200117, 0.02799883],\n",
       "        [0.85311361, 0.14688639],\n",
       "        [0.9320037 , 0.0679963 ],\n",
       "        [0.58712494, 0.41287506],\n",
       "        [0.95925356, 0.04074644],\n",
       "        [0.82745355, 0.17254645],\n",
       "        [0.83342966, 0.16657034],\n",
       "        [0.9151474 , 0.0848526 ],\n",
       "        [0.83127357, 0.16872643],\n",
       "        [0.88419718, 0.11580282],\n",
       "        [0.63474599, 0.36525401],\n",
       "        [0.87332595, 0.12667405],\n",
       "        [0.91724127, 0.08275873],\n",
       "        [0.86848811, 0.13151189],\n",
       "        [0.83677632, 0.16322368],\n",
       "        [0.42109139, 0.57890861],\n",
       "        [0.74756069, 0.25243931],\n",
       "        [0.77414447, 0.22585553],\n",
       "        [0.8960086 , 0.1039914 ],\n",
       "        [0.93131347, 0.06868653],\n",
       "        [0.87771748, 0.12228252],\n",
       "        [0.63531697, 0.36468303],\n",
       "        [0.85321527, 0.14678473],\n",
       "        [0.91013748, 0.08986252],\n",
       "        [0.46465807, 0.53534193],\n",
       "        [0.44912613, 0.55087387],\n",
       "        [0.85124034, 0.14875966],\n",
       "        [0.75680741, 0.24319259],\n",
       "        [0.8856193 , 0.1143807 ],\n",
       "        [0.87202405, 0.12797595],\n",
       "        [0.42114366, 0.57885634],\n",
       "        [0.95217937, 0.04782063],\n",
       "        [0.64632451, 0.35367549],\n",
       "        [0.54580311, 0.45419689],\n",
       "        [0.87703736, 0.12296264],\n",
       "        [0.57063263, 0.42936737],\n",
       "        [0.35747668, 0.64252332],\n",
       "        [0.60910409, 0.39089591],\n",
       "        [0.79247824, 0.20752176],\n",
       "        [0.9425655 , 0.0574345 ],\n",
       "        [0.8974432 , 0.1025568 ],\n",
       "        [0.95598725, 0.04401275],\n",
       "        [0.90270313, 0.09729687],\n",
       "        [0.76665328, 0.23334672],\n",
       "        [0.85050794, 0.14949206],\n",
       "        [0.84035866, 0.15964134],\n",
       "        [0.92203108, 0.07796892],\n",
       "        [0.86885233, 0.13114767],\n",
       "        [0.82885856, 0.17114144],\n",
       "        [0.22490595, 0.77509405],\n",
       "        [0.83825331, 0.16174669],\n",
       "        [0.89414027, 0.10585973],\n",
       "        [0.83869084, 0.16130916],\n",
       "        [0.92678862, 0.07321138],\n",
       "        [0.94332768, 0.05667232],\n",
       "        [0.88092615, 0.11907385],\n",
       "        [0.95977837, 0.04022163],\n",
       "        [0.90357475, 0.09642525],\n",
       "        [0.92178702, 0.07821298],\n",
       "        [0.34575339, 0.65424661],\n",
       "        [0.92393264, 0.07606736],\n",
       "        [0.91959142, 0.08040858],\n",
       "        [0.91659311, 0.08340689],\n",
       "        [0.57804589, 0.42195411],\n",
       "        [0.65036094, 0.34963906],\n",
       "        [0.78351662, 0.21648338],\n",
       "        [0.68662831, 0.31337169],\n",
       "        [0.74510748, 0.25489252],\n",
       "        [0.79513018, 0.20486982],\n",
       "        [0.81891802, 0.18108198],\n",
       "        [0.96877876, 0.03122124],\n",
       "        [0.15604811, 0.84395189],\n",
       "        [0.79799288, 0.20200712],\n",
       "        [0.92436999, 0.07563001],\n",
       "        [0.89899967, 0.10100033],\n",
       "        [0.79251743, 0.20748257],\n",
       "        [0.42756631, 0.57243369],\n",
       "        [0.5990716 , 0.4009284 ],\n",
       "        [0.96967487, 0.03032513],\n",
       "        [0.95687058, 0.04312942],\n",
       "        [0.60793994, 0.39206006],\n",
       "        [0.78477861, 0.21522139],\n",
       "        [0.93037876, 0.06962124],\n",
       "        [0.71175992, 0.28824008],\n",
       "        [0.86725275, 0.13274725],\n",
       "        [0.48236372, 0.51763628],\n",
       "        [0.84387715, 0.15612285],\n",
       "        [0.56499128, 0.43500872],\n",
       "        [0.95150342, 0.04849658],\n",
       "        [0.78366232, 0.21633768],\n",
       "        [0.84869021, 0.15130979],\n",
       "        [0.81136   , 0.18864   ],\n",
       "        [0.98372649, 0.01627351],\n",
       "        [0.92301781, 0.07698219],\n",
       "        [0.09527853, 0.90472147],\n",
       "        [0.92303212, 0.07696788],\n",
       "        [0.99274993, 0.00725007],\n",
       "        [0.89364798, 0.10635202],\n",
       "        [0.85777177, 0.14222823],\n",
       "        [0.90250327, 0.09749673],\n",
       "        [0.77881722, 0.22118278],\n",
       "        [0.88100973, 0.11899027],\n",
       "        [0.67272668, 0.32727332],\n",
       "        [0.8526586 , 0.1473414 ],\n",
       "        [0.86342115, 0.13657885],\n",
       "        [0.56206688, 0.43793312],\n",
       "        [0.73618246, 0.26381754],\n",
       "        [0.95521852, 0.04478148],\n",
       "        [0.34350172, 0.65649828],\n",
       "        [0.95935166, 0.04064834],\n",
       "        [0.95603982, 0.04396018],\n",
       "        [0.8347592 , 0.1652408 ],\n",
       "        [0.75530876, 0.24469124],\n",
       "        [0.82520246, 0.17479754],\n",
       "        [0.66793158, 0.33206842],\n",
       "        [0.61707542, 0.38292458],\n",
       "        [0.82319986, 0.17680014],\n",
       "        [0.48097507, 0.51902493],\n",
       "        [0.88648324, 0.11351676],\n",
       "        [0.86640946, 0.13359054],\n",
       "        [0.75457954, 0.24542046],\n",
       "        [0.18132582, 0.81867418],\n",
       "        [0.85589715, 0.14410285],\n",
       "        [0.98613981, 0.01386019],\n",
       "        [0.59097515, 0.40902485],\n",
       "        [0.89292153, 0.10707847],\n",
       "        [0.97668376, 0.02331624],\n",
       "        [0.7764384 , 0.2235616 ],\n",
       "        [0.63332533, 0.36667467],\n",
       "        [0.87427602, 0.12572398],\n",
       "        [0.43213237, 0.56786763],\n",
       "        [0.7950452 , 0.2049548 ],\n",
       "        [0.92458956, 0.07541044],\n",
       "        [0.76058764, 0.23941236],\n",
       "        [0.94295017, 0.05704983],\n",
       "        [0.95351093, 0.04648907],\n",
       "        [0.77604991, 0.22395009],\n",
       "        [0.95500609, 0.04499391],\n",
       "        [0.89999612, 0.10000388],\n",
       "        [0.96608979, 0.03391021],\n",
       "        [0.8947469 , 0.1052531 ],\n",
       "        [0.86525957, 0.13474043],\n",
       "        [0.93014862, 0.06985138],\n",
       "        [0.88234883, 0.11765117],\n",
       "        [0.95862358, 0.04137642],\n",
       "        [0.86668753, 0.13331247],\n",
       "        [0.98029316, 0.01970684],\n",
       "        [0.18469942, 0.81530058],\n",
       "        [0.83479805, 0.16520195],\n",
       "        [0.75685208, 0.24314792],\n",
       "        [0.36307075, 0.63692925],\n",
       "        [0.78919254, 0.21080746],\n",
       "        [0.94112209, 0.05887791],\n",
       "        [0.9072112 , 0.0927888 ],\n",
       "        [0.90773651, 0.09226349],\n",
       "        [0.68679438, 0.31320562],\n",
       "        [0.88163211, 0.11836789],\n",
       "        [0.95993134, 0.04006866],\n",
       "        [0.38636321, 0.61363679],\n",
       "        [0.7774739 , 0.2225261 ],\n",
       "        [0.59239801, 0.40760199],\n",
       "        [0.68852461, 0.31147539],\n",
       "        [0.92113757, 0.07886243],\n",
       "        [0.88050561, 0.11949439],\n",
       "        [0.93112005, 0.06887995],\n",
       "        [0.63652104, 0.36347896],\n",
       "        [0.41975674, 0.58024326],\n",
       "        [0.83662056, 0.16337944],\n",
       "        [0.89744715, 0.10255285],\n",
       "        [0.96451359, 0.03548641],\n",
       "        [0.92361702, 0.07638298],\n",
       "        [0.89827067, 0.10172933],\n",
       "        [0.78775168, 0.21224832],\n",
       "        [0.96085769, 0.03914231],\n",
       "        [0.90130564, 0.09869436],\n",
       "        [0.857212  , 0.142788  ],\n",
       "        [0.82239886, 0.17760114],\n",
       "        [0.85103498, 0.14896502],\n",
       "        [0.90753403, 0.09246597],\n",
       "        [0.24690765, 0.75309235],\n",
       "        [0.76995266, 0.23004734],\n",
       "        [0.54796638, 0.45203362],\n",
       "        [0.90148737, 0.09851263],\n",
       "        [0.66985983, 0.33014017],\n",
       "        [0.83979319, 0.16020681],\n",
       "        [0.80176394, 0.19823606],\n",
       "        [0.68565525, 0.31434475],\n",
       "        [0.93253481, 0.06746519],\n",
       "        [0.93138854, 0.06861146],\n",
       "        [0.96017206, 0.03982794],\n",
       "        [0.94196097, 0.05803903],\n",
       "        [0.94637989, 0.05362011],\n",
       "        [0.78079925, 0.21920075],\n",
       "        [0.26219405, 0.73780595],\n",
       "        [0.8972506 , 0.1027494 ],\n",
       "        [0.24144324, 0.75855676],\n",
       "        [0.29462563, 0.70537437],\n",
       "        [0.88048564, 0.11951436],\n",
       "        [0.7478481 , 0.2521519 ],\n",
       "        [0.7259391 , 0.2740609 ],\n",
       "        [0.61977061, 0.38022939],\n",
       "        [0.80826638, 0.19173362],\n",
       "        [0.77300806, 0.22699194],\n",
       "        [0.96804272, 0.03195728],\n",
       "        [0.95288269, 0.04711731],\n",
       "        [0.93531301, 0.06468699],\n",
       "        [0.85889626, 0.14110374],\n",
       "        [0.70068477, 0.29931523],\n",
       "        [0.90876691, 0.09123309],\n",
       "        [0.70449822, 0.29550178],\n",
       "        [0.12674157, 0.87325843],\n",
       "        [0.77549357, 0.22450643],\n",
       "        [0.66097435, 0.33902565],\n",
       "        [0.80179741, 0.19820259],\n",
       "        [0.95730244, 0.04269756],\n",
       "        [0.62514976, 0.37485024],\n",
       "        [0.78078948, 0.21921052],\n",
       "        [0.82592449, 0.17407551],\n",
       "        [0.19861045, 0.80138955],\n",
       "        [0.64948196, 0.35051804],\n",
       "        [0.76122355, 0.23877645],\n",
       "        [0.75087709, 0.24912291],\n",
       "        [0.98555303, 0.01444697],\n",
       "        [0.92449037, 0.07550963],\n",
       "        [0.23411635, 0.76588365],\n",
       "        [0.81319463, 0.18680537],\n",
       "        [0.83628061, 0.16371939],\n",
       "        [0.44379142, 0.55620858],\n",
       "        [0.88000192, 0.11999808],\n",
       "        [0.17882329, 0.82117671],\n",
       "        [0.80899269, 0.19100731],\n",
       "        [0.82416528, 0.17583472],\n",
       "        [0.9200852 , 0.0799148 ],\n",
       "        [0.17473836, 0.82526164],\n",
       "        [0.08731254, 0.91268746],\n",
       "        [0.61909047, 0.38090953],\n",
       "        [0.97173925, 0.02826075],\n",
       "        [0.8934221 , 0.1065779 ],\n",
       "        [0.73406368, 0.26593632],\n",
       "        [0.94260604, 0.05739396],\n",
       "        [0.76201867, 0.23798133],\n",
       "        [0.93832886, 0.06167114],\n",
       "        [0.86759292, 0.13240708],\n",
       "        [0.84894058, 0.15105942],\n",
       "        [0.88208172, 0.11791828],\n",
       "        [0.82124939, 0.17875061],\n",
       "        [0.93730556, 0.06269444],\n",
       "        [0.82788244, 0.17211756],\n",
       "        [0.87049083, 0.12950917],\n",
       "        [0.79865765, 0.20134235],\n",
       "        [0.91410891, 0.08589109],\n",
       "        [0.67401169, 0.32598831],\n",
       "        [0.69756133, 0.30243867],\n",
       "        [0.83830908, 0.16169092],\n",
       "        [0.53249426, 0.46750574],\n",
       "        [0.89136212, 0.10863788],\n",
       "        [0.71684678, 0.28315322],\n",
       "        [0.34738579, 0.65261421],\n",
       "        [0.92353649, 0.07646351],\n",
       "        [0.91771413, 0.08228587],\n",
       "        [0.84720322, 0.15279678],\n",
       "        [0.82427993, 0.17572007],\n",
       "        [0.80036237, 0.19963763],\n",
       "        [0.76863864, 0.23136136],\n",
       "        [0.98199223, 0.01800777],\n",
       "        [0.79539874, 0.20460126],\n",
       "        [0.77435856, 0.22564144]]),\n",
       " 'best_y_hat': array(['footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'purr', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'purr', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps'], dtype=object),\n",
       " 'all_scores': {'mean_fit_time': array([ 0.85248022,  3.0849349 ,  0.64863873,  0.100175  ,  2.05574179,\n",
       "          0.80082135,  0.42566948,  0.53219037,  5.84465518, 15.44057178]),\n",
       "  'std_fit_time': array([2.29442993e-02, 1.20368009e-02, 1.86571021e-02, 1.93246071e-03,\n",
       "         2.31961260e-02, 1.37080358e-02, 2.01113210e-02, 4.01670121e-03,\n",
       "         9.27342832e-02, 2.36899803e+00]),\n",
       "  'mean_score_time': array([0.01418014, 0.05240059, 0.00681515, 0.00688944, 0.0516798 ,\n",
       "         0.0142971 , 0.00707545, 0.01284838, 0.01258292, 0.0637702 ]),\n",
       "  'std_score_time': array([0.00160552, 0.00494271, 0.00021793, 0.00011778, 0.00243029,\n",
       "         0.00212444, 0.00075171, 0.00084427, 0.00034114, 0.01697292]),\n",
       "  'param_model__n_estimators': masked_array(data=[50, 300, 10, 10, 300, 50, 10, 50, 50, 500],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__min_samples_split': masked_array(data=[10, 10, 2, 2, 10, 5, 50, 5, 2, 10],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__max_features': masked_array(data=[10, 10, 50, 5, 5, 10, 50, 10, 100, 25],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__max_depth': masked_array(data=[None, 10, 100, None, 10, 50, 5, 10, 100, 100],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__criterion': masked_array(data=['entropy', 'gini', 'entropy', 'entropy', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'entropy', 'entropy'],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__bootstrap': masked_array(data=[False, True, False, True, True, False, False, True,\n",
       "                     False, False],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'model__n_estimators': 50,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__max_depth': None,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__bootstrap': False},\n",
       "   {'model__n_estimators': 300,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__max_depth': 10,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__bootstrap': True},\n",
       "   {'model__n_estimators': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__max_features': 50,\n",
       "    'model__max_depth': 100,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__bootstrap': False},\n",
       "   {'model__n_estimators': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__max_features': 5,\n",
       "    'model__max_depth': None,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__bootstrap': True},\n",
       "   {'model__n_estimators': 300,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__max_depth': 10,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__bootstrap': True},\n",
       "   {'model__n_estimators': 50,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__max_depth': 50,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__bootstrap': False},\n",
       "   {'model__n_estimators': 10,\n",
       "    'model__min_samples_split': 50,\n",
       "    'model__max_features': 50,\n",
       "    'model__max_depth': 5,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__bootstrap': False},\n",
       "   {'model__n_estimators': 50,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__max_depth': 10,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__bootstrap': True},\n",
       "   {'model__n_estimators': 50,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__max_features': 100,\n",
       "    'model__max_depth': 100,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__bootstrap': False},\n",
       "   {'model__n_estimators': 500,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__max_depth': 100,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__bootstrap': False}],\n",
       "  'split0_test_score': array([0.86805556, 0.88541667, 0.875     , 0.875     , 0.88194444,\n",
       "         0.86458333, 0.89236111, 0.86805556, 0.88541667, 0.875     ]),\n",
       "  'split1_test_score': array([0.91289199, 0.91986063, 0.90243902, 0.90940767, 0.92334495,\n",
       "         0.90940767, 0.90940767, 0.92682927, 0.91637631, 0.91637631]),\n",
       "  'split2_test_score': array([0.89547038, 0.90243902, 0.90243902, 0.87456446, 0.90243902,\n",
       "         0.88501742, 0.90940767, 0.91289199, 0.89547038, 0.90592334]),\n",
       "  'split3_test_score': array([0.8989547 , 0.91637631, 0.8989547 , 0.89198606, 0.90940767,\n",
       "         0.8989547 , 0.87804878, 0.90940767, 0.89547038, 0.91289199]),\n",
       "  'split4_test_score': array([0.92334495, 0.93379791, 0.91637631, 0.91637631, 0.93379791,\n",
       "         0.8989547 , 0.88850174, 0.93728223, 0.92334495, 0.92334495]),\n",
       "  'mean_test_score': array([0.89972145, 0.91155989, 0.89902507, 0.89345404, 0.91016713,\n",
       "         0.8913649 , 0.89554318, 0.91086351, 0.90320334, 0.90668524]),\n",
       "  'std_test_score': array([0.01873602, 0.01646041, 0.0134385 , 0.01720248, 0.01783567,\n",
       "         0.01549166, 0.01224518, 0.0236476 , 0.0142518 , 0.01683468]),\n",
       "  'rank_test_score': array([ 6,  1,  7,  9,  3, 10,  8,  2,  5,  4], dtype=int32)}}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unpickle results\n",
    "unpicking_out = open('/Users/greenapple/project3/models/RF_2_cls_scores_params_rand.pkl', 'rb')\n",
    "RF_2_cls_scores_params_rand = pickle.load(unpicking_out)\n",
    "RF_2_cls_scores_params_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpickle model\n",
    "unpicking_out = open('/Users/greenapple/project3/models/RF_2_cls_model_rand.pkl', 'rb')\n",
    "RF_2_cls_model = pickle.load(unpicking_out)\n",
    "RF_2_cls_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T07:00:45.462798Z",
     "start_time": "2019-10-22T06:52:24.566680Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train and fit Gradient Boosting\n",
    "from src.models import model_sel_rand_search\n",
    "\n",
    "# Function arguments:\n",
    "model = GradientBoostingClassifier(random_state=3)\n",
    "transformer = RandomOverSampler(random_state=3, sampling_strategy='minority')\n",
    "CV = 5\n",
    "\n",
    "# Function arguments: classifier params\n",
    "n_estimators = [50, 100, 300, 500]\n",
    "max_depth = [5, 10, 50, 100, None]\n",
    "min_samples_split = [2, 5, 10, 20, 50]\n",
    "max_features = [5, 10, 25, 50, 100]\n",
    "\n",
    "\n",
    "param_grid = dict(model__n_estimators=n_estimators,\n",
    "                  model__max_depth=max_depth,\n",
    "                  model__min_samples_split=min_samples_split,\n",
    "                  model__max_features=max_features,\n",
    "                 )\n",
    "\n",
    "# Call parameter selection function\n",
    "GBM_2_cls_scores_params, GBM_2_cls_model = model_sel_rand_search.train_fit_time(model,\n",
    "                                                                        param_grid,\n",
    "                                                                        transformer,\n",
    "                                                                        X_train,\n",
    "                                                                        X_test,\n",
    "                                                                        y_train,\n",
    "                                                                        y_test,\n",
    "                                                                        CV)\n",
    "\n",
    "# Pickle results\n",
    "with open('/Users/greenapple/project3/models/GBM_2_cls_scores_params_rand.pkl', 'wb') as f:\n",
    "    pickle.dump(GBM_2_cls_scores_params, f)\n",
    "    \n",
    "# Pickle model\n",
    "with open('/Users/greenapple/project3/models/GBM_2_cls_model_rand.pkl', 'wb') as f:\n",
    "    pickle.dump(GBM_2_cls_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_train_score': 0.9220055710306406,\n",
       " 'best_test_score': 0.9333333333333333,\n",
       " 'time_sec': 64.064161,\n",
       " 'time_best_fit_sec': 2.9993064,\n",
       " 'best_params': {'model__n_estimators': 500,\n",
       "  'model__min_samples_split': 20,\n",
       "  'model__max_features': 50,\n",
       "  'model__max_depth': 5},\n",
       " 'best_estimator': Pipeline(memory=None,\n",
       "          steps=[('transformer',\n",
       "                  RandomOverSampler(random_state=3, ratio=None,\n",
       "                                    return_indices=False,\n",
       "                                    sampling_strategy='minority')),\n",
       "                 ('model',\n",
       "                  GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                                             learning_rate=0.1, loss='deviance',\n",
       "                                             max_depth=5, max_features=50,\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=20,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             n_estimators=500,\n",
       "                                             n_iter_no_change=None,\n",
       "                                             presort='auto', random_state=3,\n",
       "                                             subsample=1.0, tol=0.0001,\n",
       "                                             validation_fraction=0.1, verbose=0,\n",
       "                                             warm_start=False))],\n",
       "          verbose=False),\n",
       " 'best_test_proba': array([[4.67169409e-01, 5.32830591e-01],\n",
       "        [9.99938501e-01, 6.14994743e-05],\n",
       "        [9.99718833e-01, 2.81167026e-04],\n",
       "        [9.99898806e-01, 1.01194410e-04],\n",
       "        [9.99938858e-01, 6.11422418e-05],\n",
       "        [9.99970740e-01, 2.92600950e-05],\n",
       "        [9.99283242e-01, 7.16758170e-04],\n",
       "        [9.99985821e-01, 1.41793908e-05],\n",
       "        [9.99299358e-01, 7.00642489e-04],\n",
       "        [1.40778985e-04, 9.99859221e-01],\n",
       "        [9.94220519e-01, 5.77948089e-03],\n",
       "        [8.85332586e-01, 1.14667414e-01],\n",
       "        [9.99715165e-01, 2.84834973e-04],\n",
       "        [9.99988770e-01, 1.12300433e-05],\n",
       "        [9.98919643e-01, 1.08035669e-03],\n",
       "        [9.98317497e-01, 1.68250261e-03],\n",
       "        [4.75958828e-02, 9.52404117e-01],\n",
       "        [9.99968604e-01, 3.13959548e-05],\n",
       "        [9.26999673e-01, 7.30003274e-02],\n",
       "        [9.97990960e-01, 2.00904015e-03],\n",
       "        [9.99990570e-01, 9.42960021e-06],\n",
       "        [3.10992465e-01, 6.89007535e-01],\n",
       "        [9.99703350e-01, 2.96649905e-04],\n",
       "        [9.99974583e-01, 2.54171036e-05],\n",
       "        [9.99801713e-01, 1.98287439e-04],\n",
       "        [9.99874217e-01, 1.25783161e-04],\n",
       "        [9.99834716e-01, 1.65284370e-04],\n",
       "        [9.97131724e-01, 2.86827606e-03],\n",
       "        [9.97305756e-01, 2.69424350e-03],\n",
       "        [9.99244899e-01, 7.55100517e-04],\n",
       "        [7.51645662e-01, 2.48354338e-01],\n",
       "        [9.99354394e-01, 6.45605795e-04],\n",
       "        [9.99411052e-01, 5.88947692e-04],\n",
       "        [9.99980052e-01, 1.99476491e-05],\n",
       "        [1.07512996e-03, 9.98924870e-01],\n",
       "        [9.99474999e-01, 5.25000600e-04],\n",
       "        [9.99883587e-01, 1.16412506e-04],\n",
       "        [9.99986814e-01, 1.31861173e-05],\n",
       "        [9.99975231e-01, 2.47693338e-05],\n",
       "        [8.30475987e-01, 1.69524013e-01],\n",
       "        [9.99974388e-01, 2.56115967e-05],\n",
       "        [9.98820312e-01, 1.17968841e-03],\n",
       "        [9.99974218e-01, 2.57821686e-05],\n",
       "        [9.99616917e-01, 3.83083319e-04],\n",
       "        [5.01092272e-01, 4.98907728e-01],\n",
       "        [2.31486379e-01, 7.68513621e-01],\n",
       "        [9.99971294e-01, 2.87058497e-05],\n",
       "        [9.85208808e-01, 1.47911919e-02],\n",
       "        [9.99883861e-01, 1.16138545e-04],\n",
       "        [9.99952645e-01, 4.73545025e-05],\n",
       "        [3.54831682e-02, 9.64516832e-01],\n",
       "        [9.97791730e-01, 2.20827042e-03],\n",
       "        [9.98842368e-01, 1.15763205e-03],\n",
       "        [9.99564344e-01, 4.35656091e-04],\n",
       "        [9.99961374e-01, 3.86258358e-05],\n",
       "        [9.90575476e-01, 9.42452450e-03],\n",
       "        [9.99911832e-01, 8.81681819e-05],\n",
       "        [9.99782285e-01, 2.17714696e-04],\n",
       "        [9.99963084e-01, 3.69162833e-05],\n",
       "        [9.99904190e-01, 9.58096591e-05],\n",
       "        [9.99777680e-01, 2.22319676e-04],\n",
       "        [9.99951549e-01, 4.84509960e-05],\n",
       "        [7.37628494e-03, 9.92623715e-01],\n",
       "        [9.99142347e-01, 8.57653402e-04],\n",
       "        [1.20723997e-01, 8.79276003e-01],\n",
       "        [9.96734335e-01, 3.26566517e-03],\n",
       "        [9.98709994e-01, 1.29000598e-03],\n",
       "        [9.99962693e-01, 3.73069067e-05],\n",
       "        [9.99990375e-01, 9.62509147e-06],\n",
       "        [9.39055574e-01, 6.09444264e-02],\n",
       "        [9.97312122e-01, 2.68787751e-03],\n",
       "        [9.46108070e-01, 5.38919298e-02],\n",
       "        [9.99928609e-01, 7.13906491e-05],\n",
       "        [9.99785832e-01, 2.14167698e-04],\n",
       "        [9.98612622e-01, 1.38737805e-03],\n",
       "        [5.90097108e-03, 9.94099029e-01],\n",
       "        [4.03171062e-03, 9.95968289e-01],\n",
       "        [9.94593756e-01, 5.40624430e-03],\n",
       "        [9.99984256e-01, 1.57438819e-05],\n",
       "        [9.99922538e-01, 7.74623403e-05],\n",
       "        [9.94417620e-01, 5.58238023e-03],\n",
       "        [9.96779870e-01, 3.22013042e-03],\n",
       "        [2.00412189e-03, 9.97995878e-01],\n",
       "        [9.99982236e-01, 1.77638671e-05],\n",
       "        [9.97915276e-01, 2.08472374e-03],\n",
       "        [9.99964924e-01, 3.50759179e-05],\n",
       "        [9.99704809e-01, 2.95191450e-04],\n",
       "        [9.99955127e-01, 4.48731141e-05],\n",
       "        [9.99895209e-01, 1.04791413e-04],\n",
       "        [9.99982002e-01, 1.79978474e-05],\n",
       "        [3.26432626e-04, 9.99673567e-01],\n",
       "        [9.99371442e-01, 6.28558127e-04],\n",
       "        [4.95840792e-02, 9.50415921e-01],\n",
       "        [9.99967239e-01, 3.27605329e-05],\n",
       "        [9.99903279e-01, 9.67214447e-05],\n",
       "        [9.99969272e-01, 3.07275965e-05],\n",
       "        [6.78369915e-01, 3.21630085e-01],\n",
       "        [9.99958142e-01, 4.18575482e-05],\n",
       "        [9.99986032e-01, 1.39679776e-05],\n",
       "        [9.99891585e-01, 1.08415001e-04],\n",
       "        [9.99985853e-01, 1.41465799e-05],\n",
       "        [9.99928344e-01, 7.16558114e-05],\n",
       "        [9.99976402e-01, 2.35982595e-05],\n",
       "        [9.70445871e-01, 2.95541293e-02],\n",
       "        [9.99765640e-01, 2.34360200e-04],\n",
       "        [9.99895908e-01, 1.04091527e-04],\n",
       "        [9.99871881e-01, 1.28118700e-04],\n",
       "        [9.99848200e-01, 1.51799816e-04],\n",
       "        [3.14163133e-01, 6.85836867e-01],\n",
       "        [9.74142615e-01, 2.58573847e-02],\n",
       "        [9.99456570e-01, 5.43429931e-04],\n",
       "        [9.99493742e-01, 5.06257758e-04],\n",
       "        [9.99980134e-01, 1.98663522e-05],\n",
       "        [9.99486748e-01, 5.13251711e-04],\n",
       "        [4.09059762e-01, 5.90940238e-01],\n",
       "        [9.99829729e-01, 1.70271082e-04],\n",
       "        [9.99822400e-01, 1.77599611e-04],\n",
       "        [6.21540096e-01, 3.78459904e-01],\n",
       "        [8.71146849e-02, 9.12885315e-01],\n",
       "        [9.99873246e-01, 1.26754054e-04],\n",
       "        [9.97373869e-01, 2.62613064e-03],\n",
       "        [9.99861630e-01, 1.38370141e-04],\n",
       "        [9.99526387e-01, 4.73613341e-04],\n",
       "        [6.11125757e-02, 9.38887424e-01],\n",
       "        [9.99969305e-01, 3.06954763e-05],\n",
       "        [9.93656494e-01, 6.34350579e-03],\n",
       "        [2.14012215e-01, 7.85987785e-01],\n",
       "        [9.99802641e-01, 1.97358950e-04],\n",
       "        [6.58967565e-01, 3.41032435e-01],\n",
       "        [7.80172358e-01, 2.19827642e-01],\n",
       "        [9.57361561e-01, 4.26384385e-02],\n",
       "        [9.98222749e-01, 1.77725077e-03],\n",
       "        [9.99946219e-01, 5.37811252e-05],\n",
       "        [9.99780304e-01, 2.19696331e-04],\n",
       "        [9.99967841e-01, 3.21589520e-05],\n",
       "        [9.99899810e-01, 1.00190033e-04],\n",
       "        [9.98640454e-01, 1.35954568e-03],\n",
       "        [9.99969555e-01, 3.04450179e-05],\n",
       "        [9.98393559e-01, 1.60644146e-03],\n",
       "        [9.99967845e-01, 3.21551333e-05],\n",
       "        [9.99871538e-01, 1.28461505e-04],\n",
       "        [9.99932218e-01, 6.77821515e-05],\n",
       "        [1.58049063e-03, 9.98419509e-01],\n",
       "        [9.98776037e-01, 1.22396302e-03],\n",
       "        [9.99938844e-01, 6.11557933e-05],\n",
       "        [9.99895432e-01, 1.04567507e-04],\n",
       "        [9.99965399e-01, 3.46010704e-05],\n",
       "        [9.99840922e-01, 1.59078073e-04],\n",
       "        [9.99933233e-01, 6.67669163e-05],\n",
       "        [9.99932997e-01, 6.70032310e-05],\n",
       "        [9.99948549e-01, 5.14513730e-05],\n",
       "        [9.99883924e-01, 1.16075572e-04],\n",
       "        [4.49472046e-02, 9.55052795e-01],\n",
       "        [9.99936614e-01, 6.33862483e-05],\n",
       "        [9.99982634e-01, 1.73655908e-05],\n",
       "        [9.99879560e-01, 1.20440473e-04],\n",
       "        [6.86796718e-01, 3.13203282e-01],\n",
       "        [9.71383934e-01, 2.86160663e-02],\n",
       "        [9.97224745e-01, 2.77525476e-03],\n",
       "        [8.23638552e-01, 1.76361448e-01],\n",
       "        [9.95526321e-01, 4.47367860e-03],\n",
       "        [9.86690180e-01, 1.33098198e-02],\n",
       "        [9.99861333e-01, 1.38666844e-04],\n",
       "        [9.99987208e-01, 1.27924074e-05],\n",
       "        [4.79526391e-04, 9.99520474e-01],\n",
       "        [9.99557181e-01, 4.42818610e-04],\n",
       "        [9.99979573e-01, 2.04272236e-05],\n",
       "        [9.99983490e-01, 1.65103065e-05],\n",
       "        [9.99241446e-01, 7.58554334e-04],\n",
       "        [3.83838416e-01, 6.16161584e-01],\n",
       "        [1.01815333e-01, 8.98184667e-01],\n",
       "        [9.99927254e-01, 7.27462753e-05],\n",
       "        [9.99990471e-01, 9.52924582e-06],\n",
       "        [9.13688918e-01, 8.63110822e-02],\n",
       "        [9.97785490e-01, 2.21451047e-03],\n",
       "        [9.99982141e-01, 1.78589471e-05],\n",
       "        [9.98221435e-01, 1.77856459e-03],\n",
       "        [9.99626379e-01, 3.73620577e-04],\n",
       "        [6.04312110e-01, 3.95687890e-01],\n",
       "        [9.99919746e-01, 8.02535381e-05],\n",
       "        [2.91509860e-01, 7.08490140e-01],\n",
       "        [9.99956499e-01, 4.35014769e-05],\n",
       "        [9.94230688e-01, 5.76931152e-03],\n",
       "        [9.99811055e-01, 1.88944664e-04],\n",
       "        [9.96384448e-01, 3.61555201e-03],\n",
       "        [9.99986160e-01, 1.38399833e-05],\n",
       "        [9.99962536e-01, 3.74636280e-05],\n",
       "        [5.01678412e-05, 9.99949832e-01],\n",
       "        [9.99377918e-01, 6.22081697e-04],\n",
       "        [9.99970233e-01, 2.97671148e-05],\n",
       "        [9.99893909e-01, 1.06091302e-04],\n",
       "        [9.99866920e-01, 1.33079701e-04],\n",
       "        [9.99943596e-01, 5.64036885e-05],\n",
       "        [9.93995141e-01, 6.00485923e-03],\n",
       "        [9.99903336e-01, 9.66643018e-05],\n",
       "        [9.64763553e-01, 3.52364469e-02],\n",
       "        [9.99885753e-01, 1.14247470e-04],\n",
       "        [9.99911941e-01, 8.80588300e-05],\n",
       "        [4.86259433e-01, 5.13740567e-01],\n",
       "        [9.94084132e-01, 5.91586792e-03],\n",
       "        [9.99954046e-01, 4.59539367e-05],\n",
       "        [7.05096061e-02, 9.29490394e-01],\n",
       "        [9.99976195e-01, 2.38051234e-05],\n",
       "        [9.99982755e-01, 1.72445957e-05],\n",
       "        [9.99652262e-01, 3.47738016e-04],\n",
       "        [9.95338687e-01, 4.66131332e-03],\n",
       "        [9.99977400e-01, 2.25996062e-05],\n",
       "        [9.58181910e-01, 4.18180897e-02],\n",
       "        [9.78254238e-01, 2.17457618e-02],\n",
       "        [9.99386935e-01, 6.13064593e-04],\n",
       "        [4.14383663e-01, 5.85616337e-01],\n",
       "        [9.99891627e-01, 1.08373412e-04],\n",
       "        [9.99687335e-01, 3.12665175e-04],\n",
       "        [9.96719529e-01, 3.28047113e-03],\n",
       "        [1.60723829e-03, 9.98392762e-01],\n",
       "        [9.99399444e-01, 6.00556405e-04],\n",
       "        [9.99983496e-01, 1.65036973e-05],\n",
       "        [8.14388818e-02, 9.18561118e-01],\n",
       "        [9.99968024e-01, 3.19759292e-05],\n",
       "        [9.99994858e-01, 5.14153440e-06],\n",
       "        [9.98076984e-01, 1.92301620e-03],\n",
       "        [7.95876382e-01, 2.04123618e-01],\n",
       "        [9.99961171e-01, 3.88287911e-05],\n",
       "        [5.59052754e-02, 9.44094725e-01],\n",
       "        [9.98800729e-01, 1.19927148e-03],\n",
       "        [9.99916882e-01, 8.31183738e-05],\n",
       "        [9.97781220e-01, 2.21877988e-03],\n",
       "        [9.99957752e-01, 4.22477056e-05],\n",
       "        [9.99986071e-01, 1.39293368e-05],\n",
       "        [9.99344848e-01, 6.55151736e-04],\n",
       "        [9.99981550e-01, 1.84497462e-05],\n",
       "        [9.99969395e-01, 3.06051299e-05],\n",
       "        [9.99975548e-01, 2.44522631e-05],\n",
       "        [9.99968006e-01, 3.19938860e-05],\n",
       "        [9.99930255e-01, 6.97453012e-05],\n",
       "        [9.99952859e-01, 4.71407668e-05],\n",
       "        [9.99752017e-01, 2.47982565e-04],\n",
       "        [9.99981683e-01, 1.83165648e-05],\n",
       "        [9.99964926e-01, 3.50743234e-05],\n",
       "        [9.99993242e-01, 6.75806436e-06],\n",
       "        [1.29763942e-04, 9.99870236e-01],\n",
       "        [9.99903015e-01, 9.69845265e-05],\n",
       "        [9.96155969e-01, 3.84403142e-03],\n",
       "        [1.52019796e-01, 8.47980204e-01],\n",
       "        [9.83715346e-01, 1.62846538e-02],\n",
       "        [9.99979235e-01, 2.07648483e-05],\n",
       "        [9.99918898e-01, 8.11024670e-05],\n",
       "        [9.99974223e-01, 2.57766076e-05],\n",
       "        [8.73067406e-01, 1.26932594e-01],\n",
       "        [9.99899483e-01, 1.00516713e-04],\n",
       "        [9.99976168e-01, 2.38317223e-05],\n",
       "        [6.12486293e-02, 9.38751371e-01],\n",
       "        [9.99815961e-01, 1.84039396e-04],\n",
       "        [6.63326055e-01, 3.36673945e-01],\n",
       "        [9.99320512e-01, 6.79487554e-04],\n",
       "        [9.99902245e-01, 9.77550290e-05],\n",
       "        [9.99747662e-01, 2.52337653e-04],\n",
       "        [9.99963973e-01, 3.60269466e-05],\n",
       "        [9.97603143e-01, 2.39685674e-03],\n",
       "        [2.75075190e-01, 7.24924810e-01],\n",
       "        [9.99379590e-01, 6.20410100e-04],\n",
       "        [9.99956946e-01, 4.30544228e-05],\n",
       "        [9.99982077e-01, 1.79228128e-05],\n",
       "        [9.99605486e-01, 3.94514419e-04],\n",
       "        [9.99883221e-01, 1.16778630e-04],\n",
       "        [9.99771435e-01, 2.28565483e-04],\n",
       "        [9.99981543e-01, 1.84570720e-05],\n",
       "        [9.99395052e-01, 6.04948174e-04],\n",
       "        [9.99837130e-01, 1.62870305e-04],\n",
       "        [9.99239194e-01, 7.60806010e-04],\n",
       "        [9.99979146e-01, 2.08541424e-05],\n",
       "        [9.99844724e-01, 1.55275580e-04],\n",
       "        [6.66494866e-04, 9.99333505e-01],\n",
       "        [9.99046642e-01, 9.53358441e-04],\n",
       "        [4.66704398e-01, 5.33295602e-01],\n",
       "        [9.99850939e-01, 1.49061358e-04],\n",
       "        [9.81178188e-01, 1.88218115e-02],\n",
       "        [9.99469433e-01, 5.30566671e-04],\n",
       "        [9.99127335e-01, 8.72664989e-04],\n",
       "        [9.79110196e-01, 2.08898035e-02],\n",
       "        [9.99975827e-01, 2.41732267e-05],\n",
       "        [9.99978900e-01, 2.11003325e-05],\n",
       "        [9.99980834e-01, 1.91658474e-05],\n",
       "        [9.99952714e-01, 4.72862147e-05],\n",
       "        [9.99979222e-01, 2.07776538e-05],\n",
       "        [9.97850357e-01, 2.14964317e-03],\n",
       "        [1.91874973e-02, 9.80812503e-01],\n",
       "        [9.99972838e-01, 2.71616570e-05],\n",
       "        [2.40257371e-03, 9.97597426e-01],\n",
       "        [2.80699388e-03, 9.97193006e-01],\n",
       "        [9.99644146e-01, 3.55854367e-04],\n",
       "        [9.93671213e-01, 6.32878739e-03],\n",
       "        [9.87685449e-01, 1.23145514e-02],\n",
       "        [9.89314001e-01, 1.06859986e-02],\n",
       "        [9.99181597e-01, 8.18402983e-04],\n",
       "        [9.99546465e-01, 4.53535218e-04],\n",
       "        [9.99938779e-01, 6.12211063e-05],\n",
       "        [9.99959645e-01, 4.03549172e-05],\n",
       "        [9.99981287e-01, 1.87130969e-05],\n",
       "        [9.99228786e-01, 7.71214119e-04],\n",
       "        [8.66390976e-01, 1.33609024e-01],\n",
       "        [9.99965391e-01, 3.46091948e-05],\n",
       "        [9.86459510e-01, 1.35404901e-02],\n",
       "        [3.52756547e-04, 9.99647243e-01],\n",
       "        [9.99427674e-01, 5.72325714e-04],\n",
       "        [9.71973456e-01, 2.80265442e-02],\n",
       "        [9.99693835e-01, 3.06164951e-04],\n",
       "        [9.99674866e-01, 3.25133601e-04],\n",
       "        [9.94091580e-01, 5.90842024e-03],\n",
       "        [9.79657277e-01, 2.03427230e-02],\n",
       "        [9.99599678e-01, 4.00321618e-04],\n",
       "        [7.54312653e-04, 9.99245687e-01],\n",
       "        [7.26600317e-01, 2.73399683e-01],\n",
       "        [9.98388155e-01, 1.61184495e-03],\n",
       "        [9.93083835e-01, 6.91616542e-03],\n",
       "        [9.99992905e-01, 7.09505992e-06],\n",
       "        [9.99937676e-01, 6.23237763e-05],\n",
       "        [1.82489284e-03, 9.98175107e-01],\n",
       "        [9.99560355e-01, 4.39644560e-04],\n",
       "        [9.99948672e-01, 5.13280463e-05],\n",
       "        [5.93183552e-02, 9.40681645e-01],\n",
       "        [9.99530120e-01, 4.69879701e-04],\n",
       "        [9.68667660e-04, 9.99031332e-01],\n",
       "        [9.99916641e-01, 8.33591517e-05],\n",
       "        [9.98334378e-01, 1.66562154e-03],\n",
       "        [9.99979436e-01, 2.05644277e-05],\n",
       "        [2.55438462e-04, 9.99744562e-01],\n",
       "        [7.66142315e-05, 9.99923386e-01],\n",
       "        [9.10337164e-01, 8.96628355e-02],\n",
       "        [9.99976060e-01, 2.39400919e-05],\n",
       "        [9.99956249e-01, 4.37510304e-05],\n",
       "        [9.98031899e-01, 1.96810096e-03],\n",
       "        [9.99939894e-01, 6.01059821e-05],\n",
       "        [9.99902466e-01, 9.75336696e-05],\n",
       "        [9.99982058e-01, 1.79423693e-05],\n",
       "        [9.99912036e-01, 8.79642094e-05],\n",
       "        [9.99976118e-01, 2.38823617e-05],\n",
       "        [9.99788796e-01, 2.11203922e-04],\n",
       "        [9.92089489e-01, 7.91051110e-03],\n",
       "        [9.99958848e-01, 4.11523268e-05],\n",
       "        [9.99754623e-01, 2.45377346e-04],\n",
       "        [9.99808661e-01, 1.91338784e-04],\n",
       "        [9.88183816e-01, 1.18161841e-02],\n",
       "        [9.99933491e-01, 6.65091831e-05],\n",
       "        [9.10831043e-01, 8.91689568e-02],\n",
       "        [9.98552052e-01, 1.44794829e-03],\n",
       "        [9.98780097e-01, 1.21990268e-03],\n",
       "        [6.04288059e-01, 3.95711941e-01],\n",
       "        [9.99797614e-01, 2.02385877e-04],\n",
       "        [9.98472921e-01, 1.52707868e-03],\n",
       "        [6.04449639e-02, 9.39555036e-01],\n",
       "        [9.99980524e-01, 1.94756565e-05],\n",
       "        [9.99896197e-01, 1.03802995e-04],\n",
       "        [9.99779012e-01, 2.20988289e-04],\n",
       "        [9.97255131e-01, 2.74486917e-03],\n",
       "        [9.99830866e-01, 1.69133505e-04],\n",
       "        [9.97823666e-01, 2.17633443e-03],\n",
       "        [9.99986617e-01, 1.33827907e-05],\n",
       "        [9.99386453e-01, 6.13547396e-04],\n",
       "        [9.97223000e-01, 2.77700005e-03]]),\n",
       " 'best_y_hat': array(['purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'purr', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'purr', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps'], dtype=object),\n",
       " 'all_scores': {'mean_fit_time': array([ 1.94895253,  2.12138739,  2.89835129,  4.88256855,  0.82843013,\n",
       "          1.43877883,  0.41998038, 14.22098207,  2.65475307, 10.19826345]),\n",
       "  'std_fit_time': array([0.01971149, 0.02735933, 0.0642155 , 0.18561144, 0.020156  ,\n",
       "         0.03925939, 0.01230741, 0.19496239, 0.09846966, 1.88020573]),\n",
       "  'mean_score_time': array([0.01006241, 0.00750141, 0.00792074, 0.00915861, 0.0076448 ,\n",
       "         0.00903153, 0.00681844, 0.01115313, 0.01273103, 0.00808015]),\n",
       "  'std_score_time': array([0.00066484, 0.00033963, 0.00045166, 0.00054353, 0.00028962,\n",
       "         0.00072749, 0.00029814, 0.00192227, 0.00553724, 0.00114259]),\n",
       "  'param_model__n_estimators': masked_array(data=[500, 50, 50, 500, 50, 500, 50, 300, 300, 300],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__min_samples_split': masked_array(data=[20, 50, 10, 20, 50, 2, 5, 50, 2, 2],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__max_features': masked_array(data=[5, 25, 25, 50, 5, 5, 5, 100, 5, 100],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__max_depth': masked_array(data=[50, 100, None, 5, 50, 50, 5, None, 10, 10],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'model__n_estimators': 500,\n",
       "    'model__min_samples_split': 20,\n",
       "    'model__max_features': 5,\n",
       "    'model__max_depth': 50},\n",
       "   {'model__n_estimators': 50,\n",
       "    'model__min_samples_split': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__max_depth': 100},\n",
       "   {'model__n_estimators': 50,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__max_depth': None},\n",
       "   {'model__n_estimators': 500,\n",
       "    'model__min_samples_split': 20,\n",
       "    'model__max_features': 50,\n",
       "    'model__max_depth': 5},\n",
       "   {'model__n_estimators': 50,\n",
       "    'model__min_samples_split': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__max_depth': 50},\n",
       "   {'model__n_estimators': 500,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__max_features': 5,\n",
       "    'model__max_depth': 50},\n",
       "   {'model__n_estimators': 50,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__max_depth': 5},\n",
       "   {'model__n_estimators': 300,\n",
       "    'model__min_samples_split': 50,\n",
       "    'model__max_features': 100,\n",
       "    'model__max_depth': None},\n",
       "   {'model__n_estimators': 300,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__max_features': 5,\n",
       "    'model__max_depth': 10},\n",
       "   {'model__n_estimators': 300,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__max_features': 100,\n",
       "    'model__max_depth': 10}],\n",
       "  'split0_test_score': array([0.86111111, 0.88194444, 0.86458333, 0.90277778, 0.86805556,\n",
       "         0.86458333, 0.89236111, 0.87152778, 0.86805556, 0.875     ]),\n",
       "  'split1_test_score': array([0.90243902, 0.91986063, 0.90940767, 0.93379791, 0.91637631,\n",
       "         0.89198606, 0.92682927, 0.92682927, 0.90592334, 0.93379791]),\n",
       "  'split2_test_score': array([0.88850174, 0.8989547 , 0.89198606, 0.90940767, 0.8989547 ,\n",
       "         0.89198606, 0.90243902, 0.89198606, 0.90940767, 0.90592334]),\n",
       "  'split3_test_score': array([0.91289199, 0.90940767, 0.91289199, 0.91289199, 0.8989547 ,\n",
       "         0.90592334, 0.91637631, 0.92334495, 0.91289199, 0.90592334]),\n",
       "  'split4_test_score': array([0.8989547 , 0.91986063, 0.91637631, 0.95121951, 0.90592334,\n",
       "         0.90592334, 0.93031359, 0.93031359, 0.90940767, 0.92682927]),\n",
       "  'mean_test_score': array([0.89275766, 0.90598886, 0.89902507, 0.92200557, 0.89763231,\n",
       "         0.89206128, 0.91364903, 0.90877437, 0.90111421, 0.90947075]),\n",
       "  'std_test_score': array([0.01766093, 0.01432099, 0.01918222, 0.01791176, 0.01612763,\n",
       "         0.0151076 , 0.01441221, 0.02312724, 0.01670399, 0.02053874]),\n",
       "  'rank_test_score': array([ 9,  5,  7,  1,  8, 10,  2,  4,  6,  3], dtype=int32)}}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unpickle results\n",
    "unpicking_out = open('/Users/greenapple/project3/models/GBM_2_cls_scores_params_rand.pkl', 'rb')\n",
    "GBM_2_cls_scores_params_rand = pickle.load(unpicking_out)\n",
    "GBM_2_cls_scores_params_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('transformer',\n",
       "                                              RandomOverSampler(random_state=3,\n",
       "                                                                ratio=None,\n",
       "                                                                return_indices=False,\n",
       "                                                                sampling_strategy='minority')),\n",
       "                                             ('model',\n",
       "                                              GradientBoostingClassifier(criterion='friedman_mse',\n",
       "                                                                         init=None,\n",
       "                                                                         learning_rate=0.1,\n",
       "                                                                         loss='deviance',\n",
       "                                                                         max_depth=3,\n",
       "                                                                         max_features=None,\n",
       "                                                                         max_leaf_n...\n",
       "                                                                         warm_start=False))],\n",
       "                                      verbose=False),\n",
       "                   iid='warn', n_iter=10, n_jobs=-1,\n",
       "                   param_distributions={'model__max_depth': [5, 10, 50, 100,\n",
       "                                                             None],\n",
       "                                        'model__max_features': [5, 10, 25, 50,\n",
       "                                                                100],\n",
       "                                        'model__min_samples_split': [2, 5, 10,\n",
       "                                                                     20, 50],\n",
       "                                        'model__n_estimators': [50, 100, 300,\n",
       "                                                                500]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='f1_micro', verbose=0)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unpickle model\n",
    "unpicking_out = open('/Users/greenapple/project3/models/GBM_2_cls_model_rand.pkl', 'rb')\n",
    "GBM_2_cls_model = pickle.load(unpicking_out)\n",
    "GBM_2_cls_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T00:07:18.304982Z",
     "start_time": "2019-10-22T00:07:18.048965Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:266: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Train and fit Dummy classifier\n",
    "from src.models import model_sel_rand_search\n",
    "\n",
    "# Function arguments:\n",
    "model = DummyClassifier(random_state=3, strategy='stratified')\n",
    "transformer = RandomOverSampler(random_state=3, sampling_strategy='minority')\n",
    "CV = 5\n",
    "\n",
    "# Function arguments: classifier params\n",
    "\n",
    "param_grid = dict()\n",
    "\n",
    "# Call parameter selection function\n",
    "Dummy_2_cls_scores_params, Dummy_2_cls_model = model_sel_rand_search.train_fit_time(model,\n",
    "                                                                        param_grid,\n",
    "                                                                        transformer,\n",
    "                                                                        X_train,\n",
    "                                                                        X_test,\n",
    "                                                                        y_train,\n",
    "                                                                        y_test,\n",
    "                                                                        CV)\n",
    "\n",
    "# Pickle results\n",
    "with open('/Users/greenapple/project3/models/Dummy_2_cls_scores_params_rand.pkl', 'wb') as f:\n",
    "    pickle.dump(Dummy_2_cls_scores_params, f)\n",
    "    \n",
    "# Pickle model\n",
    "with open('/Users/greenapple/project3/models/Dummy_2_cls_model_rand.pkl', 'wb') as f:\n",
    "    pickle.dump(Dummy_2_cls_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T00:07:29.791703Z",
     "start_time": "2019-10-22T00:07:29.707075Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_train_score': 0.4742339832869081,\n",
       " 'best_test_score': 0.4888888888888889,\n",
       " 'time_sec': 4.429952,\n",
       " 'time_best_fit_sec': 0.0040272,\n",
       " 'best_params': {},\n",
       " 'best_estimator': Pipeline(memory=None,\n",
       "          steps=[('transformer',\n",
       "                  RandomOverSampler(random_state=3, ratio=None,\n",
       "                                    return_indices=False,\n",
       "                                    sampling_strategy='minority')),\n",
       "                 ('model',\n",
       "                  DummyClassifier(constant=None, random_state=3,\n",
       "                                  strategy='stratified'))],\n",
       "          verbose=False),\n",
       " 'best_test_proba': array([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]]),\n",
       " 'best_y_hat': array(['footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'purr', 'purr', 'purr', 'purr', 'purr',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'purr', 'purr', 'purr', 'footsteps', 'purr', 'purr', 'footsteps',\n",
       "        'footsteps', 'purr', 'purr', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'purr', 'footsteps',\n",
       "        'footsteps', 'purr', 'purr', 'purr', 'purr', 'purr', 'purr',\n",
       "        'purr', 'footsteps', 'footsteps', 'purr', 'purr', 'purr', 'purr',\n",
       "        'purr', 'footsteps', 'purr', 'purr', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps', 'purr',\n",
       "        'footsteps', 'purr', 'purr', 'purr', 'purr', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps', 'purr',\n",
       "        'purr', 'purr', 'purr', 'purr', 'purr', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'purr', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'purr', 'footsteps', 'footsteps',\n",
       "        'purr', 'purr', 'purr', 'purr', 'purr', 'footsteps', 'footsteps',\n",
       "        'purr', 'purr', 'purr', 'purr', 'footsteps', 'footsteps', 'purr',\n",
       "        'purr', 'footsteps', 'footsteps', 'purr', 'purr', 'purr', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'purr', 'footsteps',\n",
       "        'footsteps', 'purr', 'purr', 'footsteps', 'purr', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'purr', 'purr', 'purr', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'purr', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'purr', 'footsteps', 'footsteps',\n",
       "        'purr', 'purr', 'footsteps', 'footsteps', 'purr', 'purr', 'purr',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'purr', 'footsteps', 'purr', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'purr', 'purr',\n",
       "        'purr', 'footsteps', 'purr', 'purr', 'purr', 'footsteps', 'purr',\n",
       "        'purr', 'purr', 'purr', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'purr', 'purr', 'footsteps', 'purr', 'purr', 'purr',\n",
       "        'purr', 'purr', 'purr', 'purr', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'purr', 'purr', 'purr',\n",
       "        'footsteps', 'purr', 'purr', 'footsteps', 'purr', 'purr',\n",
       "        'footsteps', 'purr', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'purr', 'purr', 'purr', 'footsteps', 'purr', 'purr',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'purr', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'purr', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'purr', 'footsteps', 'purr',\n",
       "        'purr', 'footsteps', 'purr', 'footsteps', 'purr', 'footsteps',\n",
       "        'purr', 'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'purr', 'footsteps', 'purr', 'purr', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'purr', 'purr', 'purr', 'purr',\n",
       "        'purr', 'purr', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'purr', 'purr', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps', 'purr',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'purr', 'purr',\n",
       "        'purr', 'purr', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'purr', 'purr', 'footsteps'], dtype=object),\n",
       " 'all_scores': {'mean_fit_time': array([0.01425071]),\n",
       "  'std_fit_time': array([0.00066257]),\n",
       "  'mean_score_time': array([0.00504794]),\n",
       "  'std_score_time': array([0.0005967]),\n",
       "  'params': [{}],\n",
       "  'split0_test_score': array([0.48958333]),\n",
       "  'split1_test_score': array([0.48083624]),\n",
       "  'split2_test_score': array([0.48083624]),\n",
       "  'split3_test_score': array([0.45296167]),\n",
       "  'split4_test_score': array([0.46689895]),\n",
       "  'mean_test_score': array([0.47423398]),\n",
       "  'std_test_score': array([0.01287897]),\n",
       "  'rank_test_score': array([1], dtype=int32)}}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dummy_2_cls_scores_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T00:07:45.861782Z",
     "start_time": "2019-10-22T00:07:45.782856Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dummy classifier\n",
    "dummy = DummyClassifier()\n",
    "dummy.fit(X_train, y_train)\n",
    "f1_dummy = f1_score(y_test, dummy.predict(X_test), average='micro')\n",
    "accuracy_dummy = accuracy_score(y_test, dummy.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T00:07:46.368892Z",
     "start_time": "2019-10-22T00:07:46.285594Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy classifier F1 score:  0.6805555555555556\n",
      "Dummy classifier accuracy score:  0.675\n"
     ]
    }
   ],
   "source": [
    "print('Dummy classifier F1 score: ', f1_dummy)\n",
    "print('Dummy classifier accuracy score: ', accuracy_dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "%config InlineBackend.figure_formats = ['retina']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [\n",
    "    ('logreg', logreg_2_cls_model),\n",
    "    ('KNN', KNN_2_cls_models_rand),\n",
    "    ('NBmultinomial', NBmultinomial_2_cls_models),\n",
    "    ('SVC', SVC_2_cls_model),\n",
    "    ('RF', RF_2_cls_model),\n",
    "    ('GBM', GBM_2_cls_model)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max voting classifier\n",
    "\n",
    "# Max voting classifier\n",
    "average_voting_classifer = VotingClassifier(estimators=model_list,\n",
    "                                    voting='hard',\n",
    "                                    n_jobs=-1)\n",
    "\n",
    "f1_train = cross_val_score(max_voting_classifer, \n",
    "            X_train, y_train, scoring='f1_micro', cv=5).mean()\n",
    "\n",
    "max_voting_classifer.fit(X_train, y_train)\n",
    "y_hat = max_voting_classifer.predict(X_test) \n",
    "\n",
    "f1_test = f1_score(y_test, y_hat, average='micro')\n",
    "# f1_test_s = f1_score(y_test, y_hat, average='samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9234030197444831, 0.9138888888888888)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_train, f1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average voting classifier\n",
    "average_voting_classifer = VotingClassifier(estimators=model_list,\n",
    "                                    voting='soft',\n",
    "                                    n_jobs=-1)\n",
    "\n",
    "f1_train = cross_val_score(max_voting_classifer, \n",
    "            X_train, y_train, scoring='f1_micro', cv=5).mean()\n",
    "\n",
    "max_voting_classifer.fit(X_train, y_train)\n",
    "y_hat = max_voting_classifer.predict(X_test) \n",
    "\n",
    "f1_test = f1_score(y_test, y_hat, average='micro')\n",
    "# f1_test_s = f1_score(y_test, y_hat, average='samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9234030197444831, 0.9138888888888888)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_train, f1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacked classifier\n",
    "model = logreg_2_cls_model\n",
    "\n",
    "stacked_classifier = StackingClassifier(classifiers=model_list, \n",
    "                                        meta_classifier=model, \n",
    "                                        use_probas=False)\n",
    "\n",
    "\n",
    "f1_train = cross_val_score(max_voting_classifer, \n",
    "            X_train, y_train, scoring='f1_micro', cv=5).mean()\n",
    "\n",
    "max_voting_classifer.fit(X_train, y_train)\n",
    "y_hat = max_voting_classifer.predict(X_test) \n",
    "\n",
    "f1_test = f1_score(y_test, y_hat, average='micro')\n",
    "# f1_test_s = f1_score(y_test, y_hat, average='samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9227061556329849, 0.9138888888888888)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_train, f1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list of tuples onto a dictionary\n",
    "classifier_list = [x[1] for x in model_list]\n",
    "classifier_names = [x[0] for x in model_list]\n",
    "classifier_dict = dict(zip(classifier_names, classifier_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg 0.9227061556329849 0.9138888888888888\n",
      "KNN 0.9227061556329849 0.9138888888888888\n",
      "NBmultinomial 0.9227061556329849 0.9138888888888888\n",
      "SVC 0.9227061556329849 0.9138888888888888\n",
      "RF 0.9234030197444831 0.9138888888888888\n",
      "GBM 0.9227061556329849 0.9138888888888888\n"
     ]
    }
   ],
   "source": [
    "for name, classifier in classifier_dict.items():\n",
    "    \n",
    "    # Stacked classifier\n",
    "    model = classifier\n",
    "\n",
    "    stacked_classifier = StackingClassifier(classifiers=model_list, \n",
    "                                        meta_classifier=model, \n",
    "                                        use_probas=False)\n",
    "\n",
    "\n",
    "    f1_train = cross_val_score(max_voting_classifer, \n",
    "            X_train, y_train, scoring='f1_micro', cv=5).mean()\n",
    "\n",
    "    max_voting_classifer.fit(X_train, y_train)\n",
    "    y_hat = max_voting_classifer.predict(X_test) \n",
    "\n",
    "    f1_test = f1_score(y_test, y_hat, average='micro')\n",
    "    # f1_test_s = f1_score(y_test, y_hat, average='samples')\n",
    "    \n",
    "    print(name, f1_train, f1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T00:08:32.095083Z",
     "start_time": "2019-10-22T00:08:32.017383Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "footsteps    291\n",
       "purr          69\n",
       "Name: y_name, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T00:08:32.523590Z",
     "start_time": "2019-10-22T00:08:32.381869Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null accuracy:  footsteps    0.808333\n",
      "Name: y_name, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "null_accuracy = y_test.value_counts().head(1) / len(y_test)\n",
    "print('Null accuracy: ', null_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T00:21:38.099861Z",
     "start_time": "2019-10-22T00:21:38.018427Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>F1_score_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Models, F1_score_train]\n",
       "Index: []"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_score_table = pd.DataFrame(columns=['Models', 'F1_score_train'])\n",
    "model_score_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T00:21:40.108964Z",
     "start_time": "2019-10-22T00:21:40.037780Z"
    }
   },
   "outputs": [],
   "source": [
    "model_score_table['Models'] = ['Logistis_Regression',\n",
    "                              'KNN',\n",
    "                              'Multinomial_NB',\n",
    "                              'SVC_poly',\n",
    "                              'Random_Forest',\n",
    "                               'GBM',\n",
    "                               'Dummy'\n",
    "                              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T00:23:29.707450Z",
     "start_time": "2019-10-22T00:23:29.642848Z"
    }
   },
   "outputs": [],
   "source": [
    "model_score_table['F1_score_train'] = trainin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T00:23:33.700648Z",
     "start_time": "2019-10-22T00:23:33.629584Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>F1_score_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Logistis_Regression</td>\n",
       "      <td>0.914345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>KNN</td>\n",
       "      <td>0.903900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Multinomial_NB</td>\n",
       "      <td>0.870474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>SVC_poly</td>\n",
       "      <td>0.926184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>0.916435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>GBM</td>\n",
       "      <td>0.924095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>0.474234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Models  F1_score_train\n",
       "0  Logistis_Regression        0.914345\n",
       "1                  KNN        0.903900\n",
       "2       Multinomial_NB        0.870474\n",
       "3             SVC_poly        0.926184\n",
       "4        Random_Forest        0.916435\n",
       "5                  GBM        0.924095\n",
       "6                Dummy        0.474234"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_score_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T00:31:20.145737Z",
     "start_time": "2019-10-22T00:31:20.084893Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pickle results\n",
    "with open('/Users/greenapple/project3/reports/figures/model_score_table_MVP.pkl', 'wb') as f:\n",
    "    pickle.dump(model_score_table, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project3",
   "language": "python",
   "name": "project3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "287.986px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
