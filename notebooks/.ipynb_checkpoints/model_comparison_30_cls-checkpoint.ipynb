{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T13:14:18.751252Z",
     "start_time": "2019-10-22T13:14:15.530312Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T13:14:20.197292Z",
     "start_time": "2019-10-22T13:14:20.118020Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data formatting for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T13:14:21.955359Z",
     "start_time": "2019-10-22T13:14:21.827192Z"
    }
   },
   "outputs": [],
   "source": [
    "# Unpickle data \n",
    "with open('/Users/greenapple/project3/data/processed/house_bal.pkl', 'rb') as f:\n",
    "    house_bal = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T13:14:22.646867Z",
     "start_time": "2019-10-22T13:14:22.556131Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id_list</th>\n",
       "      <th>y</th>\n",
       "      <th>y_name</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>630</th>\n",
       "      <th>631</th>\n",
       "      <th>632</th>\n",
       "      <th>633</th>\n",
       "      <th>634</th>\n",
       "      <th>635</th>\n",
       "      <th>636</th>\n",
       "      <th>637</th>\n",
       "      <th>638</th>\n",
       "      <th>639</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>b'--ZhevVpy1s'</td>\n",
       "      <td>375</td>\n",
       "      <td>toothbrush</td>\n",
       "      <td>117</td>\n",
       "      <td>35</td>\n",
       "      <td>163</td>\n",
       "      <td>90</td>\n",
       "      <td>198</td>\n",
       "      <td>103</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>202</td>\n",
       "      <td>9</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>247</td>\n",
       "      <td>72</td>\n",
       "      <td>44</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>b'-2hQKCE-oTI'</td>\n",
       "      <td>53</td>\n",
       "      <td>footsteps</td>\n",
       "      <td>30</td>\n",
       "      <td>162</td>\n",
       "      <td>44</td>\n",
       "      <td>7</td>\n",
       "      <td>216</td>\n",
       "      <td>116</td>\n",
       "      <td>206</td>\n",
       "      <td>...</td>\n",
       "      <td>213</td>\n",
       "      <td>109</td>\n",
       "      <td>50</td>\n",
       "      <td>88</td>\n",
       "      <td>19</td>\n",
       "      <td>46</td>\n",
       "      <td>54</td>\n",
       "      <td>154</td>\n",
       "      <td>42</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>b'-3pPrlCm6gg'</td>\n",
       "      <td>198</td>\n",
       "      <td>clarinet</td>\n",
       "      <td>179</td>\n",
       "      <td>190</td>\n",
       "      <td>122</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>58</td>\n",
       "      <td>15</td>\n",
       "      <td>207</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>43</td>\n",
       "      <td>97</td>\n",
       "      <td>57</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>b'-70wVF5u-gg'</td>\n",
       "      <td>366</td>\n",
       "      <td>chopping_food</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>186</td>\n",
       "      <td>34</td>\n",
       "      <td>87</td>\n",
       "      <td>250</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>144</td>\n",
       "      <td>63</td>\n",
       "      <td>110</td>\n",
       "      <td>255</td>\n",
       "      <td>139</td>\n",
       "      <td>138</td>\n",
       "      <td>59</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>b'-ASYwidRD7M'</td>\n",
       "      <td>43</td>\n",
       "      <td>snoring</td>\n",
       "      <td>53</td>\n",
       "      <td>100</td>\n",
       "      <td>144</td>\n",
       "      <td>84</td>\n",
       "      <td>223</td>\n",
       "      <td>68</td>\n",
       "      <td>95</td>\n",
       "      <td>...</td>\n",
       "      <td>56</td>\n",
       "      <td>78</td>\n",
       "      <td>153</td>\n",
       "      <td>65</td>\n",
       "      <td>208</td>\n",
       "      <td>207</td>\n",
       "      <td>200</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 643 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     video_id_list    y         y_name    0    1    2   3    4    5    6  ...  \\\n",
       "5   b'--ZhevVpy1s'  375     toothbrush  117   35  163  90  198  103   63  ...   \n",
       "20  b'-2hQKCE-oTI'   53      footsteps   30  162   44   7  216  116  206  ...   \n",
       "28  b'-3pPrlCm6gg'  198       clarinet  179  190  122  19    0  114  255  ...   \n",
       "63  b'-70wVF5u-gg'  366  chopping_food    0  114  186  34   87  250   58  ...   \n",
       "82  b'-ASYwidRD7M'   43        snoring   53  100  144  84  223   68   95  ...   \n",
       "\n",
       "    630  631  632  633  634  635  636  637  638  639  \n",
       "5     0    1  202    9  116    0  247   72   44  166  \n",
       "20  213  109   50   88   19   46   54  154   42  211  \n",
       "28   58   15  207    0  108   43   97   57   42    0  \n",
       "63    0  122  144   63  110  255  139  138   59  154  \n",
       "82   56   78  153   65  208  207  200  255  255   66  \n",
       "\n",
       "[5 rows x 643 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_bal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T13:14:23.637888Z",
     "start_time": "2019-10-22T13:14:23.569034Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45717, 643)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_bal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T13:14:25.034705Z",
     "start_time": "2019-10-22T13:14:24.966615Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(house_bal.y_name.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T13:14:25.457824Z",
     "start_time": "2019-10-22T13:14:25.382236Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speech            4042\n",
       "music             3781\n",
       "laughter          3772\n",
       "snoring           3370\n",
       "vacuum_cleaner    3054\n",
       "typing            2644\n",
       "dishes_pots       2560\n",
       "frying_food       2102\n",
       "blender           1884\n",
       "toilet_flush      1882\n",
       "door              1868\n",
       "whoop             1736\n",
       "footsteps         1492\n",
       "baby_cry          1414\n",
       "screeming         1116\n",
       "whispering         972\n",
       "clarinet           960\n",
       "crying             918\n",
       "microwave          894\n",
       "television         866\n",
       "hair_dryer         772\n",
       "video_games        592\n",
       "shaving            552\n",
       "bathtab            472\n",
       "water_tap          458\n",
       "chopping_food      410\n",
       "meow               388\n",
       "dog                358\n",
       "purr               304\n",
       "toothbrush          84\n",
       "Name: y_name, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_bal.y_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T13:14:41.859423Z",
     "start_time": "2019-10-22T13:14:41.757553Z"
    }
   },
   "outputs": [],
   "source": [
    "# Assign features X and target y\n",
    "X = house_bal[house_bal.columns[3:643]]\n",
    "y = house_bal.y_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T13:14:48.290339Z",
     "start_time": "2019-10-22T13:14:48.136955Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36573, 640), (36573,), (9144, 640), (9144,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and evaluate models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T17:35:29.887767Z",
     "start_time": "2019-10-19T17:35:29.883261Z"
    }
   },
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T22:40:41.750284Z",
     "start_time": "2019-10-21T22:40:26.667154Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/greenapple/anaconda3/envs/metis/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/greenapple/anaconda3/envs/metis/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/greenapple/anaconda3/envs/metis/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/greenapple/anaconda3/envs/metis/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/greenapple/anaconda3/envs/metis/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/greenapple/anaconda3/envs/metis/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Train and fit logistic regression\n",
    "from src.models import model_sel_grid\n",
    "\n",
    "# Function arguments:\n",
    "model = LogisticRegression(random_state=3)\n",
    "transformer = RandomOverSampler(random_state=3, sampling_strategy='minority')\n",
    "CV = 5\n",
    "\n",
    "# Function arguments: classifier params\n",
    "penalty = ['l1', 'l2']\n",
    "C = np.logspace(0, 4, 10)\n",
    "\n",
    "param_grid = dict(\n",
    "        model__C = C, \n",
    "        model__penalty = penalty)\n",
    "\n",
    "# Call parameter selection function\n",
    "logreg_2_cls_scores_params, logreg_2_cls_model = model_sel_grid.train_fit_time(model,\n",
    "                                                                               param_grid,\n",
    "                                                                               transformer,\n",
    "                                                                               X_train,\n",
    "                                                                               X_test,\n",
    "                                                                               y_train,\n",
    "                                                                               y_test,\n",
    "                                                                               CV)\n",
    "\n",
    "# Pickle results\n",
    "with open('/Users/greenapple/project3/models/logreg_2_cls_scores_params.pkl', 'wb') as f:\n",
    "    pickle.dump(logreg_2_cls_scores_params, f)\n",
    "    \n",
    "# Pickle model\n",
    "with open('/Users/greenapple/project3/models/logreg_2_cls_model.pkl', 'wb') as f:\n",
    "    pickle.dump(logreg_2_cls_model, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T04:08:58.711750Z",
     "start_time": "2019-10-19T04:08:58.704570Z"
    }
   },
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T22:44:05.517998Z",
     "start_time": "2019-10-21T22:43:22.018705Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train and fit KNN\n",
    "from src.models import model_sel_grid\n",
    "\n",
    "# Function arguments:\n",
    "model = KNeighborsClassifier()\n",
    "transformer = RandomOverSampler(random_state=3, sampling_strategy='minority')\n",
    "CV = 5\n",
    "\n",
    "# Function arguments: classifier params\n",
    "k_range = range(1, 31)\n",
    "\n",
    "param_grid = dict(model__n_neighbors=k_range)\n",
    "\n",
    "# Call parameter selection function\n",
    "KNN_2_cls_scores_params, KNN_2_cls_models = model_sel_grid.train_fit_time(model,\n",
    "                                                                               param_grid,\n",
    "                                                                               transformer,\n",
    "                                                                               X_train,\n",
    "                                                                               X_test,\n",
    "                                                                               y_train,\n",
    "                                                                               y_test,\n",
    "                                                                               CV)\n",
    "\n",
    "# Pickle results\n",
    "with open('/Users/greenapple/project3/models/KNN_2_cls_scores_params.pkl', 'wb') as f:\n",
    "    pickle.dump(KNN_2_cls_scores_params, f)\n",
    "    \n",
    "# Pickle model\n",
    "with open('/Users/greenapple/project3/models/KNN_2_cls_models.pkl', 'wb') as f:\n",
    "    pickle.dump(KNN_2_cls_models, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes MultiNomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T22:46:31.708756Z",
     "start_time": "2019-10-21T22:46:31.269131Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train and fit naive Bayes MultiNomial\n",
    "from src.models import model_sel_grid\n",
    "\n",
    "# Function arguments:\n",
    "model = MultinomialNB()\n",
    "transformer = RandomOverSampler(random_state=3, sampling_strategy='minority')\n",
    "CV = 5\n",
    "\n",
    "# Function arguments: classifier params\n",
    "alphas = [1, 10, 100]\n",
    "# Selects the min alpha. Keep alpha = 1 to make sure the model can take data it has not seen before \n",
    "# from the test set.\n",
    "\n",
    "param_grid = dict(model__alpha=alphas)\n",
    "\n",
    "# Call parameter selection function\n",
    "NBmultinomial_2_cls_scores_params, NBmultinomial_2_cls_models = model_sel_grid.train_fit_time(model,\n",
    "                                                                               param_grid,\n",
    "                                                                               transformer,\n",
    "                                                                               X_train,\n",
    "                                                                               X_test,\n",
    "                                                                               y_train,\n",
    "                                                                               y_test,\n",
    "                                                                               CV)\n",
    "\n",
    "# Pickle results\n",
    "with open('/Users/greenapple/project3/models/NBmultinomial_2_cls_scores_params.pkl', 'wb') as f:\n",
    "    pickle.dump(NBmultinomial_2_cls_scores_params, f)\n",
    "    \n",
    "# Pickle model\n",
    "with open('/Users/greenapple/project3/models/NBmultinomial_2_cls_models.pkl', 'wb') as f:\n",
    "    pickle.dump(NBmultinomial_2_cls_models, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T23:20:52.968294Z",
     "start_time": "2019-10-21T22:48:22.725052Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-2d26fc75e0b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m                                                                                \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                                                                                \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                                                                                CV)\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Pickle results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/project3/src/models/model_sel_grid.py\u001b[0m in \u001b[0;36mtrain_fit_time\u001b[0;34m(model, param_grid, transformer, X_train, X_test, y_train, y_test, CV)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;31m# Parameter grid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f1_micro'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Time the function: record end time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metis/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    686\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metis/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metis/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    665\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 667\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metis/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metis/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metis/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metis/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metis/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train and fit SVC\n",
    "from src.models import model_sel_grid\n",
    "\n",
    "# Function arguments:\n",
    "model = svm.SVC(probability=True)\n",
    "transformer = RandomOverSampler(random_state=3, sampling_strategy='minority')\n",
    "CV = 5\n",
    "\n",
    "# Function arguments: classifier params\n",
    "kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "C = [0.001, 0.01, 0.1, 1, 10]\n",
    "gamma = [0.001, 0.01, 0.1, 1]\n",
    "degree = [2, 3]\n",
    "\n",
    "param_grid = dict(model__C=C,\n",
    "                 model__kernel=kernel,\n",
    "                 model__gamma=gamma,\n",
    "                 model__degree=degree\n",
    "                 )\n",
    "\n",
    "# Call parameter selection function\n",
    "SVC_2_cls_scores_params, SVC_2_cls_models = model_sel_grid.train_fit_time(model,\n",
    "                                                                               param_grid,\n",
    "                                                                               transformer,\n",
    "                                                                               X_train,\n",
    "                                                                               X_test,\n",
    "                                                                               y_train,\n",
    "                                                                               y_test,\n",
    "                                                                               CV)\n",
    "\n",
    "# Pickle results\n",
    "with open('/Users/greenapple/project3/models/SVC_2_cls_scores_params.pkl', 'wb') as f:\n",
    "    pickle.dump(SVC_2_cls_scores_params, f)\n",
    "    \n",
    "# Pickle model\n",
    "with open('/Users/greenapple/project3/models/SVC_2_cls_models.pkl', 'wb') as f:\n",
    "    pickle.dump(SVC_2_cls_models, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T23:20:52.971650Z",
     "start_time": "2019-10-21T22:48:23.406Z"
    }
   },
   "outputs": [],
   "source": [
    "SVC_2_cls_scores_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T23:23:56.875816Z",
     "start_time": "2019-10-21T23:23:56.779212Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_score': 0.9261838440111421,\n",
       " 'test_score': 0.9166666666666666,\n",
       " 'params': {'model__C': 0.001,\n",
       "  'model__degree': 3,\n",
       "  'model__gamma': 0.001,\n",
       "  'model__kernel': 'poly'},\n",
       " 'estimator': Pipeline(memory=None,\n",
       "          steps=[('transformer',\n",
       "                  RandomOverSampler(random_state=3, ratio=None,\n",
       "                                    return_indices=False,\n",
       "                                    sampling_strategy='minority')),\n",
       "                 ('model',\n",
       "                  SVC(C=0.001, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                      decision_function_shape='ovr', degree=3, gamma=0.001,\n",
       "                      kernel='poly', max_iter=-1, probability=True,\n",
       "                      random_state=None, shrinking=True, tol=0.001,\n",
       "                      verbose=False))],\n",
       "          verbose=False),\n",
       " 'test_proba': array([[5.71174124e-02, 9.42882588e-01],\n",
       "        [9.99982371e-01, 1.76286963e-05],\n",
       "        [9.99997796e-01, 2.20390074e-06],\n",
       "        [9.99902262e-01, 9.77382165e-05],\n",
       "        [9.99999795e-01, 2.04584564e-07],\n",
       "        [9.99998520e-01, 1.47959799e-06],\n",
       "        [9.99998935e-01, 1.06485921e-06],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99998866e-01, 1.13415334e-06],\n",
       "        [3.00000090e-14, 1.00000000e+00],\n",
       "        [9.99994527e-01, 5.47317148e-06],\n",
       "        [9.99975078e-01, 2.49216005e-05],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99991429e-01, 8.57054399e-06],\n",
       "        [9.99999591e-01, 4.08822721e-07],\n",
       "        [9.89792240e-01, 1.02077597e-02],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.98270035e-01, 1.72996520e-03],\n",
       "        [9.95175950e-01, 4.82405047e-03],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [2.79596714e-01, 7.20403286e-01],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999610e-01, 3.90385377e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99997282e-01, 2.71820601e-06],\n",
       "        [9.99998318e-01, 1.68183240e-06],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999035e-01, 9.65244892e-07],\n",
       "        [9.66441151e-01, 3.35588495e-02],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99977668e-01, 2.23315221e-05],\n",
       "        [9.99999880e-01, 1.19548236e-07],\n",
       "        [5.60571286e-07, 9.99999439e-01],\n",
       "        [9.99999821e-01, 1.79117226e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.97436276e-01, 2.56372411e-03],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999807e-01, 1.93340236e-07],\n",
       "        [9.99999773e-01, 2.26688449e-07],\n",
       "        [9.99054550e-01, 9.45450358e-04],\n",
       "        [9.90159445e-01, 9.84055489e-03],\n",
       "        [1.42254880e-01, 8.57745120e-01],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.98383268e-01, 1.61673179e-03],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [1.65910782e-05, 9.99983409e-01],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.98165932e-01, 1.83406813e-03],\n",
       "        [9.99996428e-01, 3.57214900e-06],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99998238e-01, 1.76155422e-06],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99998382e-01, 1.61783530e-06],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [6.24987043e-01, 3.75012957e-01],\n",
       "        [9.99918071e-01, 8.19289921e-05],\n",
       "        [4.00692575e-06, 9.99995993e-01],\n",
       "        [9.99968183e-01, 3.18171974e-05],\n",
       "        [9.99999718e-01, 2.81894190e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999578e-01, 4.21990261e-07],\n",
       "        [9.99994465e-01, 5.53487921e-06],\n",
       "        [9.98717860e-01, 1.28214001e-03],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999842e-01, 1.57628077e-07],\n",
       "        [9.99997932e-01, 2.06799257e-06],\n",
       "        [1.75315396e-02, 9.82468460e-01],\n",
       "        [6.33684423e-01, 3.66315577e-01],\n",
       "        [9.99934705e-01, 6.52953690e-05],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999860e-01, 1.39777577e-07],\n",
       "        [9.99999517e-01, 4.82684739e-07],\n",
       "        [9.99996848e-01, 3.15204442e-06],\n",
       "        [7.07606289e-02, 9.29239371e-01],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99998016e-01, 1.98353927e-06],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999881e-01, 1.19246230e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99998563e-01, 1.43739611e-06],\n",
       "        [9.99999896e-01, 1.03591243e-07],\n",
       "        [7.13935706e-03, 9.92860643e-01],\n",
       "        [9.99994664e-01, 5.33575573e-06],\n",
       "        [3.00000090e-14, 1.00000000e+00],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99997167e-01, 2.83292746e-06],\n",
       "        [5.58744791e-01, 4.41255209e-01],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.93884211e-01, 6.11578947e-03],\n",
       "        [9.99999856e-01, 1.43917246e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99997313e-01, 2.68722310e-06],\n",
       "        [1.66702175e-01, 8.33297825e-01],\n",
       "        [9.99995793e-01, 4.20715181e-06],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.98405988e-01, 1.59401211e-03],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.84298250e-01, 1.57017503e-02],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99995921e-01, 4.07885224e-06],\n",
       "        [8.95049535e-01, 1.04950465e-01],\n",
       "        [9.93510388e-01, 6.48961173e-03],\n",
       "        [9.99998614e-01, 1.38608157e-06],\n",
       "        [9.99965583e-01, 3.44165977e-05],\n",
       "        [9.99023657e-01, 9.76343329e-04],\n",
       "        [9.99540587e-01, 4.59413288e-04],\n",
       "        [9.32350168e-01, 6.76498320e-02],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.85188584e-01, 1.48114163e-02],\n",
       "        [9.84944077e-01, 1.50559229e-02],\n",
       "        [9.99863058e-01, 1.36941691e-04],\n",
       "        [9.48362741e-01, 5.16372585e-02],\n",
       "        [9.99994619e-01, 5.38074059e-06],\n",
       "        [9.99984517e-01, 1.54827459e-05],\n",
       "        [9.99742209e-01, 2.57790683e-04],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99235842e-01, 7.64158025e-04],\n",
       "        [9.99988150e-01, 1.18497400e-05],\n",
       "        [9.99999856e-01, 1.43983193e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99975030e-01, 2.49698969e-05],\n",
       "        [9.99998011e-01, 1.98921627e-06],\n",
       "        [6.23177337e-01, 3.76822663e-01],\n",
       "        [9.99971296e-01, 2.87035603e-05],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99998271e-01, 1.72947078e-06],\n",
       "        [9.99999187e-01, 8.13347723e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [1.86467833e-01, 8.13532167e-01],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.75291056e-01, 2.47089441e-02],\n",
       "        [9.93240168e-01, 6.75983202e-03],\n",
       "        [9.99996877e-01, 3.12298398e-06],\n",
       "        [9.98588682e-01, 1.41131795e-03],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99998961e-01, 1.03862426e-06],\n",
       "        [9.99998258e-01, 1.74220369e-06],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [4.75582888e-02, 9.52441711e-01],\n",
       "        [9.99999712e-01, 2.87679946e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [3.48714918e-01, 6.51285082e-01],\n",
       "        [9.60400022e-01, 3.95999781e-02],\n",
       "        [3.76745069e-09, 9.99999996e-01],\n",
       "        [9.99982372e-01, 1.76279713e-05],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [8.78815708e-01, 1.21184292e-01],\n",
       "        [9.99471933e-01, 5.28067045e-04],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99632719e-01, 3.67280530e-04],\n",
       "        [9.98095321e-01, 1.90467882e-03],\n",
       "        [6.24309038e-01, 3.75690962e-01],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.95018518e-01, 4.98148168e-03],\n",
       "        [9.99998488e-01, 1.51207584e-06],\n",
       "        [9.99955000e-01, 4.50002948e-05],\n",
       "        [9.98768044e-01, 1.23195573e-03],\n",
       "        [9.99999676e-01, 3.23635018e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [3.00000090e-14, 1.00000000e+00],\n",
       "        [9.99914758e-01, 8.52417054e-05],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99397248e-01, 6.02751829e-04],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99997665e-01, 2.33548038e-06],\n",
       "        [6.01623934e-02, 9.39837607e-01],\n",
       "        [9.95952358e-01, 4.04764195e-03],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [2.30235456e-10, 1.00000000e+00],\n",
       "        [9.99999563e-01, 4.36925169e-07],\n",
       "        [9.99982396e-01, 1.76038630e-05],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99954524e-01, 4.54759245e-05],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [7.34705808e-01, 2.65294192e-01],\n",
       "        [9.93136380e-01, 6.86362036e-03],\n",
       "        [9.99990787e-01, 9.21312158e-06],\n",
       "        [9.99994541e-01, 5.45868704e-06],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99853234e-01, 1.46766093e-04],\n",
       "        [9.99998462e-01, 1.53827004e-06],\n",
       "        [8.62344252e-01, 1.37655748e-01],\n",
       "        [9.99983230e-01, 1.67699017e-05],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [5.62159687e-02, 9.43784031e-01],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99269514e-01, 7.30486186e-04],\n",
       "        [8.04703890e-01, 1.95296110e-01],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.59362017e-01, 4.06379833e-02],\n",
       "        [9.98944183e-01, 1.05581683e-03],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99995962e-01, 4.03773785e-06],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.69632988e-01, 3.03670121e-02],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99991895e-01, 8.10547155e-06],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99998930e-01, 1.06959942e-06],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [3.22755837e-01, 6.77244163e-01],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [7.60527056e-02, 9.23947294e-01],\n",
       "        [9.95110506e-01, 4.88949358e-03],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.78586361e-01, 2.14136392e-02],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [4.50836201e-01, 5.49163799e-01],\n",
       "        [9.99948813e-01, 5.11867583e-05],\n",
       "        [8.46670213e-01, 1.53329787e-01],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999714e-01, 2.85785674e-07],\n",
       "        [1.19228278e-02, 9.88077172e-01],\n",
       "        [9.99998464e-01, 1.53597659e-06],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99997591e-01, 2.40868146e-06],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999869e-01, 1.31109843e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [2.50648701e-09, 9.99999997e-01],\n",
       "        [9.99965685e-01, 3.43152679e-05],\n",
       "        [1.53973465e-02, 9.84602653e-01],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.88257730e-01, 1.17422702e-02],\n",
       "        [9.99982658e-01, 1.73421162e-05],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99168366e-01, 8.31633654e-04],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99998489e-01, 1.51092670e-06],\n",
       "        [1.02362931e-02, 9.89763707e-01],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [1.83323642e-05, 9.99981668e-01],\n",
       "        [3.75806991e-08, 9.99999962e-01],\n",
       "        [9.99999449e-01, 5.50873325e-07],\n",
       "        [9.99999058e-01, 9.41609951e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.98357049e-01, 1.64295148e-03],\n",
       "        [9.99997872e-01, 2.12837378e-06],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99996410e-01, 3.58966069e-06],\n",
       "        [9.96942686e-01, 3.05731354e-03],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99998603e-01, 1.39745255e-06],\n",
       "        [1.29820468e-05, 9.99987018e-01],\n",
       "        [9.99997339e-01, 2.66111269e-06],\n",
       "        [9.97544940e-01, 2.45506049e-03],\n",
       "        [9.98038086e-01, 1.96191397e-03],\n",
       "        [9.99999763e-01, 2.36922310e-07],\n",
       "        [9.99356536e-01, 6.43463686e-04],\n",
       "        [9.99884865e-01, 1.15135409e-04],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [1.07147600e-11, 1.00000000e+00],\n",
       "        [4.94657936e-01, 5.05342064e-01],\n",
       "        [9.99943807e-01, 5.61929374e-05],\n",
       "        [9.98620479e-01, 1.37952102e-03],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [2.34102679e-06, 9.99997659e-01],\n",
       "        [9.27916215e-01, 7.20837851e-02],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [2.08517747e-02, 9.79148225e-01],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [4.23910682e-13, 1.00000000e+00],\n",
       "        [9.99999745e-01, 2.55312711e-07],\n",
       "        [9.99986794e-01, 1.32059093e-05],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [3.00000090e-14, 1.00000000e+00],\n",
       "        [6.43277409e-10, 9.99999999e-01],\n",
       "        [9.99999668e-01, 3.32266290e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999636e-01, 3.63985524e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99998730e-01, 1.27040897e-06],\n",
       "        [9.99935168e-01, 6.48319834e-05],\n",
       "        [9.99999770e-01, 2.29545816e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [7.94534607e-01, 2.05465393e-01],\n",
       "        [9.99999792e-01, 2.08082591e-07],\n",
       "        [9.99978856e-01, 2.11439292e-05],\n",
       "        [9.99999140e-01, 8.59925180e-07],\n",
       "        [9.69083496e-01, 3.09165037e-02],\n",
       "        [3.10634229e-03, 9.96893658e-01],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.95815829e-01, 4.18417056e-03],\n",
       "        [9.62545027e-01, 3.74549731e-02],\n",
       "        [9.99999638e-01, 3.61942756e-07],\n",
       "        [9.99999648e-01, 3.52131799e-07],\n",
       "        [9.99978633e-01, 2.13670026e-05],\n",
       "        [9.99987016e-01, 1.29843591e-05],\n",
       "        [9.99998132e-01, 1.86838319e-06],\n",
       "        [9.88177611e-01, 1.18223895e-02],\n",
       "        [9.99999900e-01, 1.00000010e-07],\n",
       "        [9.99997140e-01, 2.86024943e-06],\n",
       "        [9.99999900e-01, 1.00000010e-07]]),\n",
       " 'y_hat': array(['purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'purr', 'purr',\n",
       "        'purr', 'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'purr', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'purr', 'footsteps',\n",
       "        'purr', 'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps'], dtype=object)}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unpickle data \n",
    "with open('/Users/greenapple/project3/models/SVC_2_classes.pkl', 'rb') as f:\n",
    "    SVC_2_classes = pickle.load(f)\n",
    "SVC_2_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T14:22:08.476653Z",
     "start_time": "2019-10-22T13:15:46.751574Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6c335f9e09b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m                                                                         \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                                                                         \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                                                                         CV)\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# Pickle results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/project3/src/models/model_sel_grid.py\u001b[0m in \u001b[0;36mtrain_fit_time\u001b[0;34m(model, param_grid, transformer, X_train, X_test, y_train, y_test, CV)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;31m# Parameter grid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f1_micro'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Time the function: record end time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metis/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    686\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metis/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metis/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    665\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 667\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metis/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metis/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metis/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metis/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metis/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#HAVE NOT RUN THIS SEARCH!!!!\n",
    "\n",
    "# Train and fit Random Forest\n",
    "from src.models import model_sel_grid\n",
    "\n",
    "# Function arguments:\n",
    "model = RandomForestClassifier(random_state=3)\n",
    "transformer = RandomOverSampler(random_state=3, sampling_strategy='minority')\n",
    "CV = 5\n",
    "\n",
    "# Function arguments: classifier params\n",
    "n_estimators = [50, 100, 200, 300]\n",
    "criterion = ['gini', 'entropy']\n",
    "max_depth = [5, 10, 50, 100, None]\n",
    "min_samples_split = [2, 5, 10]\n",
    "max_features = [5, 10, 25]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "                \n",
    "param_grid = dict(model__n_estimators=n_estimators,\n",
    "                  model__criterion=criterion,\n",
    "                  model__max_depth=max_depth,\n",
    "                  model__min_samples_split=min_samples_split,\n",
    "                  model__max_features=max_features,\n",
    "                  model__bootstrap=bootstrap\n",
    "                 )\n",
    "\n",
    "# Call parameter selection function\n",
    "RF_30_cls_scores_params, RF_30_cls_models = model_sel_grid.train_fit_time(model,\n",
    "                                                                        param_grid,\n",
    "                                                                        transformer,\n",
    "                                                                        X_train,\n",
    "                                                                        X_test,\n",
    "                                                                        y_train,\n",
    "                                                                        y_test,\n",
    "                                                                        CV)\n",
    "\n",
    "# Pickle results\n",
    "with open('/Users/greenapple/project3/models/RF_30_cls_scores_params.pkl', 'wb') as f:\n",
    "    pickle.dump(RF_30_cls_scores_params, f)\n",
    "    \n",
    "# Pickle model\n",
    "with open('/Users/greenapple/project3/models/RF_30_cls_models.pkl', 'wb') as f:\n",
    "    pickle.dump(RF_30_cls_models, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T13:10:00.433181Z",
     "start_time": "2019-10-22T13:10:00.180621Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_train_score': 0.9192200557103064,\n",
       " 'best_test_score': 0.9166666666666666,\n",
       " 'time_sec': 2577.827588,\n",
       " 'time_best_fit_sec': 0.48924120000000004,\n",
       " 'best_params': {'model__bootstrap': True,\n",
       "  'model__criterion': 'gini',\n",
       "  'model__max_depth': 10,\n",
       "  'model__max_features': 25,\n",
       "  'model__min_samples_split': 10,\n",
       "  'model__n_estimators': 50},\n",
       " 'best_estimator': Pipeline(memory=None,\n",
       "          steps=[('transformer',\n",
       "                  RandomOverSampler(random_state=3, ratio=None,\n",
       "                                    return_indices=False,\n",
       "                                    sampling_strategy='minority')),\n",
       "                 ('model',\n",
       "                  RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                         criterion='gini', max_depth=10,\n",
       "                                         max_features=25, max_leaf_nodes=None,\n",
       "                                         min_impurity_decrease=0.0,\n",
       "                                         min_impurity_split=None,\n",
       "                                         min_samples_leaf=1,\n",
       "                                         min_samples_split=10,\n",
       "                                         min_weight_fraction_leaf=0.0,\n",
       "                                         n_estimators=50, n_jobs=None,\n",
       "                                         oob_score=False, random_state=3,\n",
       "                                         verbose=0, warm_start=False))],\n",
       "          verbose=False),\n",
       " 'best_test_proba': array([[5.58474550e-01, 4.41525450e-01],\n",
       "        [9.84761905e-01, 1.52380952e-02],\n",
       "        [8.11031600e-01, 1.88968400e-01],\n",
       "        [8.02659132e-01, 1.97340868e-01],\n",
       "        [9.81082474e-01, 1.89175258e-02],\n",
       "        [9.99873418e-01, 1.26582278e-04],\n",
       "        [9.49500000e-01, 5.05000000e-02],\n",
       "        [9.96521739e-01, 3.47826087e-03],\n",
       "        [8.21303794e-01, 1.78696206e-01],\n",
       "        [1.28266280e-01, 8.71733720e-01],\n",
       "        [6.95288814e-01, 3.04711186e-01],\n",
       "        [4.59660100e-01, 5.40339900e-01],\n",
       "        [9.35367106e-01, 6.46328938e-02],\n",
       "        [1.00000000e+00, 0.00000000e+00],\n",
       "        [8.30996448e-01, 1.69003552e-01],\n",
       "        [7.68874934e-01, 2.31125066e-01],\n",
       "        [4.00515478e-01, 5.99484522e-01],\n",
       "        [8.76948356e-01, 1.23051644e-01],\n",
       "        [5.00800856e-01, 4.99199144e-01],\n",
       "        [7.80789721e-01, 2.19210279e-01],\n",
       "        [9.80000000e-01, 2.00000000e-02],\n",
       "        [3.31711061e-01, 6.68288939e-01],\n",
       "        [7.66602607e-01, 2.33397393e-01],\n",
       "        [9.42950341e-01, 5.70496592e-02],\n",
       "        [8.62787454e-01, 1.37212546e-01],\n",
       "        [9.55984529e-01, 4.40154712e-02],\n",
       "        [9.01504747e-01, 9.84952525e-02],\n",
       "        [8.09833230e-01, 1.90166770e-01],\n",
       "        [7.10379246e-01, 2.89620754e-01],\n",
       "        [6.43692480e-01, 3.56307520e-01],\n",
       "        [6.37186025e-01, 3.62813975e-01],\n",
       "        [9.10000000e-01, 9.00000000e-02],\n",
       "        [7.77861668e-01, 2.22138332e-01],\n",
       "        [9.73131313e-01, 2.68686869e-02],\n",
       "        [1.58050866e-01, 8.41949134e-01],\n",
       "        [7.30365474e-01, 2.69634526e-01],\n",
       "        [8.58131313e-01, 1.41868687e-01],\n",
       "        [8.47111111e-01, 1.52888889e-01],\n",
       "        [8.95793651e-01, 1.04206349e-01],\n",
       "        [3.38854761e-01, 6.61145239e-01],\n",
       "        [9.04491228e-01, 9.55087719e-02],\n",
       "        [7.79805095e-01, 2.20194905e-01],\n",
       "        [9.12888889e-01, 8.71111111e-02],\n",
       "        [8.92814190e-01, 1.07185810e-01],\n",
       "        [3.69365440e-01, 6.30634560e-01],\n",
       "        [6.41417879e-01, 3.58582121e-01],\n",
       "        [9.61283644e-01, 3.87163561e-02],\n",
       "        [7.35059589e-01, 2.64940411e-01],\n",
       "        [9.55425532e-01, 4.45744681e-02],\n",
       "        [1.00000000e+00, 0.00000000e+00],\n",
       "        [3.11812269e-01, 6.88187731e-01],\n",
       "        [7.43021404e-01, 2.56978596e-01],\n",
       "        [8.44300868e-01, 1.55699132e-01],\n",
       "        [8.37407934e-01, 1.62592066e-01],\n",
       "        [9.59577295e-01, 4.04227053e-02],\n",
       "        [7.54821465e-01, 2.45178535e-01],\n",
       "        [9.76000000e-01, 2.40000000e-02],\n",
       "        [8.19736426e-01, 1.80263574e-01],\n",
       "        [9.00000000e-01, 1.00000000e-01],\n",
       "        [8.66773504e-01, 1.33226496e-01],\n",
       "        [8.84903225e-01, 1.15096775e-01],\n",
       "        [8.86834378e-01, 1.13165622e-01],\n",
       "        [1.10058127e-01, 8.89941873e-01],\n",
       "        [7.92399822e-01, 2.07600178e-01],\n",
       "        [3.72789324e-01, 6.27210676e-01],\n",
       "        [7.41632611e-01, 2.58367389e-01],\n",
       "        [8.46464327e-01, 1.53535673e-01],\n",
       "        [9.43484848e-01, 5.65151515e-02],\n",
       "        [9.61128205e-01, 3.88717949e-02],\n",
       "        [4.56006342e-01, 5.43993658e-01],\n",
       "        [7.83216568e-01, 2.16783432e-01],\n",
       "        [6.69607410e-01, 3.30392590e-01],\n",
       "        [9.49873418e-01, 5.01265823e-02],\n",
       "        [8.56270492e-01, 1.43729508e-01],\n",
       "        [8.93863636e-01, 1.06136364e-01],\n",
       "        [2.87621109e-01, 7.12378891e-01],\n",
       "        [3.22344902e-01, 6.77655098e-01],\n",
       "        [7.58274716e-01, 2.41725284e-01],\n",
       "        [9.67979798e-01, 3.20202020e-02],\n",
       "        [9.25587703e-01, 7.44122966e-02],\n",
       "        [8.81303158e-01, 1.18696842e-01],\n",
       "        [7.94485746e-01, 2.05514254e-01],\n",
       "        [3.10335298e-01, 6.89664702e-01],\n",
       "        [1.00000000e+00, 0.00000000e+00],\n",
       "        [7.84675325e-01, 2.15324675e-01],\n",
       "        [9.99873418e-01, 1.26582278e-04],\n",
       "        [8.60727076e-01, 1.39272924e-01],\n",
       "        [9.30714286e-01, 6.92857143e-02],\n",
       "        [8.59904762e-01, 1.40095238e-01],\n",
       "        [1.00000000e+00, 0.00000000e+00],\n",
       "        [1.64112725e-01, 8.35887275e-01],\n",
       "        [7.99618385e-01, 2.00381615e-01],\n",
       "        [4.88379921e-01, 5.11620079e-01],\n",
       "        [9.62000000e-01, 3.80000000e-02],\n",
       "        [8.11244200e-01, 1.88755800e-01],\n",
       "        [9.50718488e-01, 4.92815119e-02],\n",
       "        [6.21086310e-01, 3.78913690e-01],\n",
       "        [9.99873418e-01, 1.26582278e-04],\n",
       "        [8.07126984e-01, 1.92873016e-01],\n",
       "        [9.13520804e-01, 8.64791965e-02],\n",
       "        [9.24646465e-01, 7.53535354e-02],\n",
       "        [9.40206751e-01, 5.97932489e-02],\n",
       "        [8.63888889e-01, 1.36111111e-01],\n",
       "        [7.33524613e-01, 2.66475387e-01],\n",
       "        [8.79994767e-01, 1.20005233e-01],\n",
       "        [9.47111111e-01, 5.28888889e-02],\n",
       "        [8.31452991e-01, 1.68547009e-01],\n",
       "        [8.26826454e-01, 1.73173546e-01],\n",
       "        [3.74478030e-01, 6.25521970e-01],\n",
       "        [5.34350023e-01, 4.65649977e-01],\n",
       "        [7.24997603e-01, 2.75002397e-01],\n",
       "        [8.83636364e-01, 1.16363636e-01],\n",
       "        [9.43090072e-01, 5.69099277e-02],\n",
       "        [8.95362082e-01, 1.04637918e-01],\n",
       "        [5.77787167e-01, 4.22212833e-01],\n",
       "        [9.00878880e-01, 9.91211205e-02],\n",
       "        [9.34327391e-01, 6.56726086e-02],\n",
       "        [3.39267526e-01, 6.60732474e-01],\n",
       "        [3.93045224e-01, 6.06954776e-01],\n",
       "        [9.13664336e-01, 8.63356643e-02],\n",
       "        [7.94639555e-01, 2.05360445e-01],\n",
       "        [8.88694073e-01, 1.11305927e-01],\n",
       "        [8.79333333e-01, 1.20666667e-01],\n",
       "        [3.05305455e-01, 6.94694545e-01],\n",
       "        [9.72857143e-01, 2.71428571e-02],\n",
       "        [6.65255368e-01, 3.34744632e-01],\n",
       "        [3.75900693e-01, 6.24099307e-01],\n",
       "        [8.70939394e-01, 1.29060606e-01],\n",
       "        [6.17553645e-01, 3.82446355e-01],\n",
       "        [2.94246407e-01, 7.05753593e-01],\n",
       "        [5.61912351e-01, 4.38087649e-01],\n",
       "        [8.41293657e-01, 1.58706343e-01],\n",
       "        [9.96000000e-01, 4.00000000e-03],\n",
       "        [9.31428699e-01, 6.85713012e-02],\n",
       "        [9.33206751e-01, 6.67932489e-02],\n",
       "        [8.72103896e-01, 1.27896104e-01],\n",
       "        [7.15044733e-01, 2.84955267e-01],\n",
       "        [8.58572277e-01, 1.41427723e-01],\n",
       "        [7.92118803e-01, 2.07881197e-01],\n",
       "        [8.78603175e-01, 1.21396825e-01],\n",
       "        [9.01545859e-01, 9.84541408e-02],\n",
       "        [8.48751424e-01, 1.51248576e-01],\n",
       "        [1.75188434e-01, 8.24811566e-01],\n",
       "        [8.03715262e-01, 1.96284738e-01],\n",
       "        [9.11225637e-01, 8.87743630e-02],\n",
       "        [8.61361199e-01, 1.38638801e-01],\n",
       "        [9.72117552e-01, 2.78824477e-02],\n",
       "        [9.88166667e-01, 1.18333333e-02],\n",
       "        [9.73333333e-01, 2.66666667e-02],\n",
       "        [9.48741830e-01, 5.12581699e-02],\n",
       "        [8.94873418e-01, 1.05126582e-01],\n",
       "        [9.60000000e-01, 4.00000000e-02],\n",
       "        [2.91475221e-01, 7.08524779e-01],\n",
       "        [9.39457850e-01, 6.05421504e-02],\n",
       "        [8.73333333e-01, 1.26666667e-01],\n",
       "        [9.37650938e-01, 6.23490616e-02],\n",
       "        [5.58325289e-01, 4.41674711e-01],\n",
       "        [6.80525929e-01, 3.19474071e-01],\n",
       "        [7.87846964e-01, 2.12153036e-01],\n",
       "        [7.04619111e-01, 2.95380889e-01],\n",
       "        [7.69425272e-01, 2.30574728e-01],\n",
       "        [7.75269683e-01, 2.24730317e-01],\n",
       "        [8.48000000e-01, 1.52000000e-01],\n",
       "        [9.76666667e-01, 2.33333333e-02],\n",
       "        [1.08264653e-01, 8.91735347e-01],\n",
       "        [8.28660185e-01, 1.71339815e-01],\n",
       "        [9.47043682e-01, 5.29563185e-02],\n",
       "        [8.75949328e-01, 1.24050672e-01],\n",
       "        [8.04601732e-01, 1.95398268e-01],\n",
       "        [5.24454344e-01, 4.75545656e-01],\n",
       "        [4.93160591e-01, 5.06839409e-01],\n",
       "        [9.87111111e-01, 1.28888889e-02],\n",
       "        [9.74873418e-01, 2.51265823e-02],\n",
       "        [6.30466462e-01, 3.69533538e-01],\n",
       "        [7.60963995e-01, 2.39036005e-01],\n",
       "        [1.00000000e+00, 0.00000000e+00],\n",
       "        [8.09168908e-01, 1.90831092e-01],\n",
       "        [8.63142857e-01, 1.36857143e-01],\n",
       "        [5.09710916e-01, 4.90289084e-01],\n",
       "        [9.09852941e-01, 9.01470588e-02],\n",
       "        [5.98820896e-01, 4.01179104e-01],\n",
       "        [9.69873418e-01, 3.01265823e-02],\n",
       "        [7.13487597e-01, 2.86512403e-01],\n",
       "        [7.75533172e-01, 2.24466828e-01],\n",
       "        [7.71154952e-01, 2.28845048e-01],\n",
       "        [9.91301989e-01, 8.69801085e-03],\n",
       "        [9.34852941e-01, 6.51470588e-02],\n",
       "        [5.05049656e-02, 9.49495034e-01],\n",
       "        [9.28228144e-01, 7.17718565e-02],\n",
       "        [1.00000000e+00, 0.00000000e+00],\n",
       "        [9.13188406e-01, 8.68115942e-02],\n",
       "        [9.69090909e-01, 3.09090909e-02],\n",
       "        [8.59076923e-01, 1.40923077e-01],\n",
       "        [7.25533961e-01, 2.74466039e-01],\n",
       "        [8.98691151e-01, 1.01308849e-01],\n",
       "        [6.47695249e-01, 3.52304751e-01],\n",
       "        [9.17744073e-01, 8.22559270e-02],\n",
       "        [8.70185415e-01, 1.29814585e-01],\n",
       "        [4.70151995e-01, 5.29848005e-01],\n",
       "        [7.96195018e-01, 2.03804982e-01],\n",
       "        [1.00000000e+00, 0.00000000e+00],\n",
       "        [3.79389686e-01, 6.20610314e-01],\n",
       "        [9.89890110e-01, 1.01098901e-02],\n",
       "        [9.99873418e-01, 1.26582278e-04],\n",
       "        [8.53333333e-01, 1.46666667e-01],\n",
       "        [7.42904762e-01, 2.57095238e-01],\n",
       "        [8.99400560e-01, 1.00599440e-01],\n",
       "        [7.76203317e-01, 2.23796683e-01],\n",
       "        [6.64040361e-01, 3.35959639e-01],\n",
       "        [8.04927076e-01, 1.95072924e-01],\n",
       "        [4.34196235e-01, 5.65803765e-01],\n",
       "        [8.48693277e-01, 1.51306723e-01],\n",
       "        [8.78607143e-01, 1.21392857e-01],\n",
       "        [8.58881291e-01, 1.41118709e-01],\n",
       "        [1.62348286e-01, 8.37651714e-01],\n",
       "        [7.70667381e-01, 2.29332619e-01],\n",
       "        [9.79873418e-01, 2.01265823e-02],\n",
       "        [6.37999444e-01, 3.62000556e-01],\n",
       "        [9.46159420e-01, 5.38405797e-02],\n",
       "        [9.80000000e-01, 2.00000000e-02],\n",
       "        [7.63131069e-01, 2.36868931e-01],\n",
       "        [6.05162774e-01, 3.94837226e-01],\n",
       "        [9.51924700e-01, 4.80753002e-02],\n",
       "        [5.17490901e-01, 4.82509099e-01],\n",
       "        [8.82693001e-01, 1.17306999e-01],\n",
       "        [9.39619449e-01, 6.03805505e-02],\n",
       "        [7.43124312e-01, 2.56875688e-01],\n",
       "        [9.48000000e-01, 5.20000000e-02],\n",
       "        [9.73206751e-01, 2.67932489e-02],\n",
       "        [8.73274092e-01, 1.26725908e-01],\n",
       "        [9.80718488e-01, 1.92815119e-02],\n",
       "        [9.14040084e-01, 8.59599156e-02],\n",
       "        [9.99873418e-01, 1.26582278e-04],\n",
       "        [8.98277778e-01, 1.01722222e-01],\n",
       "        [8.72381870e-01, 1.27618130e-01],\n",
       "        [9.57651195e-01, 4.23488045e-02],\n",
       "        [9.23804291e-01, 7.61957094e-02],\n",
       "        [9.95714286e-01, 4.28571429e-03],\n",
       "        [9.23873418e-01, 7.61265823e-02],\n",
       "        [9.86666667e-01, 1.33333333e-02],\n",
       "        [9.48398082e-02, 9.05160192e-01],\n",
       "        [8.39633946e-01, 1.60366054e-01],\n",
       "        [8.65884125e-01, 1.34115875e-01],\n",
       "        [3.75716016e-01, 6.24283984e-01],\n",
       "        [7.42971971e-01, 2.57028029e-01],\n",
       "        [9.29852941e-01, 7.01470588e-02],\n",
       "        [9.20667069e-01, 7.93329315e-02],\n",
       "        [9.53630719e-01, 4.63692810e-02],\n",
       "        [7.04768458e-01, 2.95231542e-01],\n",
       "        [9.19873418e-01, 8.01265823e-02],\n",
       "        [9.79726359e-01, 2.02736411e-02],\n",
       "        [3.32819891e-01, 6.67180109e-01],\n",
       "        [7.16335500e-01, 2.83664500e-01],\n",
       "        [5.52966270e-01, 4.47033730e-01],\n",
       "        [7.50336345e-01, 2.49663655e-01],\n",
       "        [9.31301989e-01, 6.86980108e-02],\n",
       "        [9.33206751e-01, 6.67932489e-02],\n",
       "        [9.72000000e-01, 2.80000000e-02],\n",
       "        [7.43232090e-01, 2.56767910e-01],\n",
       "        [5.27097542e-01, 4.72902458e-01],\n",
       "        [8.12636715e-01, 1.87363285e-01],\n",
       "        [9.60000000e-01, 4.00000000e-02],\n",
       "        [9.63157895e-01, 3.68421053e-02],\n",
       "        [9.59873418e-01, 4.01265823e-02],\n",
       "        [9.29567227e-01, 7.04327731e-02],\n",
       "        [8.07808112e-01, 1.92191888e-01],\n",
       "        [9.47818182e-01, 5.21818182e-02],\n",
       "        [9.20432900e-01, 7.95670996e-02],\n",
       "        [8.02937225e-01, 1.97062775e-01],\n",
       "        [8.91666667e-01, 1.08333333e-01],\n",
       "        [9.06875902e-01, 9.31240981e-02],\n",
       "        [9.57777778e-01, 4.22222222e-02],\n",
       "        [1.23218095e-01, 8.76781905e-01],\n",
       "        [8.67215089e-01, 1.32784911e-01],\n",
       "        [4.17421154e-01, 5.82578846e-01],\n",
       "        [9.57142857e-01, 4.28571429e-02],\n",
       "        [8.25503115e-01, 1.74496885e-01],\n",
       "        [8.48656308e-01, 1.51343692e-01],\n",
       "        [7.33975023e-01, 2.66024977e-01],\n",
       "        [6.77243626e-01, 3.22756374e-01],\n",
       "        [9.30886818e-01, 6.91131815e-02],\n",
       "        [9.28583333e-01, 7.14166667e-02],\n",
       "        [9.80000000e-01, 2.00000000e-02],\n",
       "        [9.82950341e-01, 1.70496592e-02],\n",
       "        [9.67146145e-01, 3.28538550e-02],\n",
       "        [8.71422382e-01, 1.28577618e-01],\n",
       "        [2.54681007e-01, 7.45318993e-01],\n",
       "        [9.44873418e-01, 5.51265823e-02],\n",
       "        [1.67811912e-01, 8.32188088e-01],\n",
       "        [3.08003809e-01, 6.91996191e-01],\n",
       "        [9.34332579e-01, 6.56674208e-02],\n",
       "        [7.51838383e-01, 2.48161617e-01],\n",
       "        [7.05738253e-01, 2.94261747e-01],\n",
       "        [5.58157180e-01, 4.41842820e-01],\n",
       "        [9.07394639e-01, 9.26053614e-02],\n",
       "        [7.57741220e-01, 2.42258780e-01],\n",
       "        [9.90000000e-01, 1.00000000e-02],\n",
       "        [9.99873418e-01, 1.26582278e-04],\n",
       "        [9.48726790e-01, 5.12732095e-02],\n",
       "        [9.08755803e-01, 9.12441973e-02],\n",
       "        [5.93817898e-01, 4.06182102e-01],\n",
       "        [8.03812295e-01, 1.96187705e-01],\n",
       "        [7.84119591e-01, 2.15880409e-01],\n",
       "        [1.41145992e-01, 8.58854008e-01],\n",
       "        [7.91994490e-01, 2.08005510e-01],\n",
       "        [6.64697487e-01, 3.35302513e-01],\n",
       "        [8.46666667e-01, 1.53333333e-01],\n",
       "        [9.88794118e-01, 1.12058824e-02],\n",
       "        [6.50049221e-01, 3.49950779e-01],\n",
       "        [7.87520730e-01, 2.12479270e-01],\n",
       "        [9.46519608e-01, 5.34803922e-02],\n",
       "        [2.49068115e-01, 7.50931885e-01],\n",
       "        [5.64143140e-01, 4.35856860e-01],\n",
       "        [8.56873706e-01, 1.43126294e-01],\n",
       "        [7.60303987e-01, 2.39696013e-01],\n",
       "        [9.73333333e-01, 2.66666667e-02],\n",
       "        [9.43333333e-01, 5.66666667e-02],\n",
       "        [2.48392531e-01, 7.51607469e-01],\n",
       "        [7.45633478e-01, 2.54366522e-01],\n",
       "        [8.00928387e-01, 1.99071613e-01],\n",
       "        [4.32141991e-01, 5.67858009e-01],\n",
       "        [9.20256410e-01, 7.97435897e-02],\n",
       "        [9.95286205e-02, 9.00471380e-01],\n",
       "        [8.98060644e-01, 1.01939356e-01],\n",
       "        [7.27208791e-01, 2.72791209e-01],\n",
       "        [9.19059692e-01, 8.09403078e-02],\n",
       "        [1.33440022e-01, 8.66559978e-01],\n",
       "        [7.75846639e-02, 9.22415336e-01],\n",
       "        [7.70201236e-01, 2.29798764e-01],\n",
       "        [9.55000000e-01, 4.50000000e-02],\n",
       "        [9.61506410e-01, 3.84935897e-02],\n",
       "        [8.02003259e-01, 1.97996741e-01],\n",
       "        [9.79873418e-01, 2.01265823e-02],\n",
       "        [8.73855693e-01, 1.26144307e-01],\n",
       "        [9.51262307e-01, 4.87376934e-02],\n",
       "        [8.75815533e-01, 1.24184467e-01],\n",
       "        [8.98287879e-01, 1.01712121e-01],\n",
       "        [8.52164364e-01, 1.47835636e-01],\n",
       "        [7.43159577e-01, 2.56840423e-01],\n",
       "        [9.58206751e-01, 4.17932489e-02],\n",
       "        [8.46979798e-01, 1.53020202e-01],\n",
       "        [9.48743354e-01, 5.12566462e-02],\n",
       "        [7.39547493e-01, 2.60452507e-01],\n",
       "        [9.61111111e-01, 3.88888889e-02],\n",
       "        [7.67199297e-01, 2.32800703e-01],\n",
       "        [8.06983965e-01, 1.93016035e-01],\n",
       "        [7.48215479e-01, 2.51784521e-01],\n",
       "        [6.06051689e-01, 3.93948311e-01],\n",
       "        [9.18972828e-01, 8.10271721e-02],\n",
       "        [7.62659514e-01, 2.37340486e-01],\n",
       "        [2.49178905e-01, 7.50821095e-01],\n",
       "        [9.81411879e-01, 1.85881207e-02],\n",
       "        [9.19873418e-01, 8.01265823e-02],\n",
       "        [8.10343585e-01, 1.89656415e-01],\n",
       "        [8.50331183e-01, 1.49668817e-01],\n",
       "        [9.29268636e-01, 7.07313643e-02],\n",
       "        [7.38525560e-01, 2.61474440e-01],\n",
       "        [9.99852941e-01, 1.47058824e-04],\n",
       "        [7.90761249e-01, 2.09238751e-01],\n",
       "        [7.75897147e-01, 2.24102853e-01]]),\n",
       " 'best_y_hat': array(['footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'purr', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps'],\n",
       "       dtype=object),\n",
       " 'all_scores': {'mean_fit_time': array([ 0.25601454,  0.54695377,  1.11312985,  1.61458936,  0.24356251,\n",
       "          0.66938524,  0.93912039,  1.24085488,  0.22563734,  0.43706102,\n",
       "          0.86381507,  1.34090838,  0.39578876,  0.98487997,  1.36564755,\n",
       "          2.00264387,  0.34838166,  0.67407494,  1.34182401,  2.02764544,\n",
       "          0.36567974,  0.74955482,  1.6087204 ,  2.17571979,  0.75976624,\n",
       "          1.51640496,  3.01437798,  4.59882231,  0.7822001 ,  1.70353389,\n",
       "          3.15235844,  4.77001762,  0.8136456 ,  1.71229577,  3.3424263 ,\n",
       "          4.84343629,  0.34952397,  0.67620411,  1.32414851,  1.98962755,\n",
       "          0.35451975,  0.6949966 ,  1.32346258,  1.95914106,  0.34814868,\n",
       "          0.66629858,  1.32674947,  1.97728252,  0.5815187 ,  1.09669423,\n",
       "          2.19104438,  3.25679488,  0.5590457 ,  1.10214782,  2.17230587,\n",
       "          3.2760097 ,  0.55853324,  1.10502701,  2.17862735,  3.26897364,\n",
       "          1.20450878,  2.43935227,  4.69230404,  7.09589295,  1.20243459,\n",
       "          2.39556069,  4.78569226,  7.14797244,  1.18629298,  2.37268963,\n",
       "          4.68603425,  7.14963994,  0.40799031,  0.77807579,  1.55194311,\n",
       "          2.30124111,  0.40536041,  0.76408434,  1.49469247,  2.23567896,\n",
       "          0.39192867,  0.76112604,  1.49044399,  2.22419906,  0.64703898,\n",
       "          1.41941433,  3.22565255,  4.83238215,  0.74121323,  1.30888443,\n",
       "          2.53779125,  3.78977833,  0.65276442,  1.28556519,  2.46573062,\n",
       "          3.72831316,  1.37385578,  2.75103693,  5.51179051,  8.22189798,\n",
       "          1.37970495,  2.74432125,  5.474898  ,  8.24256363,  1.38606524,\n",
       "          2.71064935,  5.3402081 ,  8.023104  ,  0.38637843,  0.76648641,\n",
       "          1.486203  ,  2.27663074,  0.39417248,  0.82405877,  1.53510761,\n",
       "          2.22432036,  0.38726878,  0.75585537,  1.48720875,  2.23199387,\n",
       "          0.6547904 ,  1.26834702,  2.45960011,  3.72672963,  0.63528986,\n",
       "          1.26409063,  2.47545338,  3.78370624,  0.6328402 ,  1.24770074,\n",
       "          2.44935842,  3.64943295,  1.37493958,  2.72875457,  5.43964643,\n",
       "          8.2081306 ,  1.35604415,  2.69520054,  5.41844544,  8.12454219,\n",
       "          1.3516757 ,  2.7328227 ,  5.33888936,  7.94126372,  0.38797393,\n",
       "          0.74636579,  1.47783556,  2.21141481,  0.39047179,  0.78288512,\n",
       "          1.49054375,  2.19432554,  0.38287535,  0.74321265,  1.4551116 ,\n",
       "          2.16850791,  0.63278856,  1.22799025,  2.46616325,  3.64712858,\n",
       "          0.62176542,  1.22253442,  2.44254766,  3.67134314,  0.64226532,\n",
       "          1.21033568,  2.43201036,  3.61757779,  1.34762368,  2.67426391,\n",
       "          5.30361452,  8.01142249,  1.35595021,  2.65918546,  5.29920878,\n",
       "          7.99263806,  1.3426712 ,  2.66562796,  5.28079805,  7.89219928,\n",
       "          0.29446335,  0.60100899,  1.14892993,  1.65675979,  0.287326  ,\n",
       "          0.56436625,  1.10123034,  1.65511861,  0.30200629,  0.57174077,\n",
       "          1.11093793,  1.68260641,  0.48195729,  0.92867961,  1.80811172,\n",
       "          2.71126771,  0.47030563,  0.92228127,  1.8167007 ,  2.73412218,\n",
       "          0.46789598,  0.92398648,  1.80979095,  2.69246922,  0.99062924,\n",
       "          1.97988448,  3.93663177,  5.84456906,  0.99126596,  1.97327271,\n",
       "          3.86450253,  5.79232965,  0.98998942,  1.98717818,  3.86673064,\n",
       "          5.74714065,  0.39989634,  0.78750105,  1.55414629,  2.31000257,\n",
       "          0.40411062,  0.78480959,  1.53436084,  2.29455972,  0.40063429,\n",
       "          0.78743281,  1.55276141,  2.32661939,  0.65120215,  1.28255458,\n",
       "          2.53771453,  3.78283472,  0.64928427,  1.2706645 ,  2.54284554,\n",
       "          3.79387107,  0.64109926,  1.27170734,  2.57048569,  3.77252402,\n",
       "          1.34442167,  2.67048974,  5.26750321,  7.91516118,  1.32582259,\n",
       "          2.64330487,  5.24327803,  7.87390833,  1.32959881,  2.63842134,\n",
       "          5.26463761,  7.85925722,  0.42084002,  0.81450396,  1.61722364,\n",
       "          2.42067804,  0.43657484,  0.8298018 ,  1.6212379 ,  2.41219769,\n",
       "          0.41836934,  0.8152154 ,  1.61807671,  2.43032002,  0.6715836 ,\n",
       "          1.33170972,  2.6292592 ,  3.92125721,  0.67960739,  1.30597825,\n",
       "          2.61070166,  3.90704713,  0.68224115,  1.31120167,  2.61361561,\n",
       "          3.90750966,  1.35704246,  2.6983736 ,  5.34214206,  8.02102361,\n",
       "          1.34515448,  2.71005917,  5.42477784,  8.02290239,  1.37138205,\n",
       "          2.67709436,  5.39684973,  7.99271441,  0.42733922,  0.82179365,\n",
       "          1.61013851,  2.396808  ,  0.43376493,  0.83561325,  1.63447161,\n",
       "          2.40999923,  0.42212672,  0.81511054,  1.60733991,  2.43004637,\n",
       "          0.69317145,  1.33105459,  2.625491  ,  3.92482953,  0.66823916,\n",
       "          1.31593804,  2.60360761,  3.91553907,  0.66518784,  1.30373116,\n",
       "          2.59884043,  3.97851963,  1.37464976,  2.72178912,  5.38764439,\n",
       "          8.08549294,  1.35438957,  2.72349706,  5.38478417,  8.03895378,\n",
       "          1.35662489,  2.67774835,  5.43269067,  8.09601879,  0.42283473,\n",
       "          0.82554822,  1.62149119,  2.40866861,  0.43084497,  0.84778857,\n",
       "          1.62783566,  2.41506801,  0.42271314,  0.81352816,  1.60577335,\n",
       "          2.43911729,  0.68099861,  1.37783537,  2.62113538,  3.92357674,\n",
       "          0.66716895,  1.32165537,  2.60681548,  3.90850468,  0.66777778,\n",
       "          1.31740699,  2.58182311,  3.94618535,  1.40510793,  2.695891  ,\n",
       "          5.3355547 ,  8.0393455 ,  1.3463522 ,  2.70201492,  5.40641842,\n",
       "          8.00996346,  1.34011374,  2.68103123,  5.32555342,  8.28038402,\n",
       "          0.32859383,  0.60724225,  1.20817389,  1.80577865,  0.317522  ,\n",
       "          0.61839786,  1.2211432 ,  1.8204267 ,  0.32273436,  0.61805258,\n",
       "          1.22283397,  1.81563902,  0.52793121,  1.04144931,  2.08052044,\n",
       "          3.14421053,  0.54162693,  1.03496041,  2.08993216,  3.09774914,\n",
       "          0.53075924,  1.04306078,  2.05397897,  3.08722687,  1.15097737,\n",
       "          2.29454403,  4.56703377,  6.84961839,  1.15861545,  2.28199601,\n",
       "          4.56964345,  6.81319857,  1.15869884,  2.33837037,  4.59178395,\n",
       "          6.80471416,  0.44504619,  0.87689943,  1.7116497 ,  2.57577109,\n",
       "          0.45548406,  0.88028493,  1.736163  ,  2.60026608,  0.45639677,\n",
       "          0.92475762,  1.71773129,  2.59066157,  0.76042824,  1.4990809 ,\n",
       "          2.92542481,  4.42250228,  0.75120797,  1.50213928,  2.98694963,\n",
       "          4.46639128,  0.75043764,  1.48295798,  3.04269204,  4.45243449,\n",
       "          1.62773204,  3.21986289,  6.6912035 , 11.24890962,  1.64323773,\n",
       "          3.22747092,  6.36162438,  9.48737516,  1.5972496 ,  3.18486819,\n",
       "          6.31222034,  9.50238533,  0.50295954,  0.98846827,  1.944348  ,\n",
       "          2.93719077,  0.52098083,  0.99446645,  1.98598208,  2.92406516,\n",
       "          0.5047226 ,  0.98451304,  1.97028842,  2.890344  ,  0.8551631 ,\n",
       "          1.70162868,  3.36523261,  5.04093862,  0.85370984,  1.70053492,\n",
       "          3.36566992,  5.06980681,  0.84772868,  1.69836702,  3.36499634,\n",
       "          5.05024271,  1.92779694,  3.87735705,  7.66217704, 11.49878736,\n",
       "          1.90752468,  3.78946867,  7.65909781, 11.45006332,  1.88148155,\n",
       "          3.82728348,  7.71828227, 11.42777085,  0.50392375,  0.99171243,\n",
       "          1.94621086,  2.92813668,  0.50256   ,  1.00701261,  1.96874557,\n",
       "          2.9250371 ,  0.50954275,  0.98832946,  1.93754683,  2.92066607,\n",
       "          0.86158442,  1.68774185,  3.40988803,  5.08148336,  0.85377178,\n",
       "          1.71901155,  3.36660862,  5.05819044,  0.84325318,  1.69732442,\n",
       "          3.36393013,  5.02706308,  1.92236242,  3.86530452,  7.68050694,\n",
       "         11.48429327,  1.93156939,  3.82582231,  7.59938378, 11.4066824 ,\n",
       "          1.91988821,  3.78003592,  7.55386782, 11.40529847,  0.50634899,\n",
       "          1.00203238,  1.97271533,  2.92382398,  0.50296154,  0.99331846,\n",
       "          1.93823299,  2.90591879,  0.50720229,  0.98512421,  1.94602046,\n",
       "          2.89251299,  0.85515871,  1.6875514 ,  3.3931848 ,  5.03285379,\n",
       "          0.85166507,  1.70390382,  3.3674027 ,  5.03988996,  0.85572343,\n",
       "          1.69128561,  3.35166664,  5.07145958,  1.95905924,  3.85612912,\n",
       "          7.72598252, 11.53505979,  1.91396308,  3.85516539,  7.63394384,\n",
       "         11.4874002 ,  1.91674705,  3.80267005,  7.58601904, 11.41051002,\n",
       "          0.36514034,  0.7026185 ,  1.37708964,  2.06199541,  0.3630785 ,\n",
       "          0.7000711 ,  1.36596971,  2.07993441,  0.3608449 ,  0.69477897,\n",
       "          1.3806963 ,  2.0711102 ,  0.60585537,  1.2223805 ,  2.36002302,\n",
       "          3.51672926,  0.60421057,  1.19087958,  2.39507003,  3.54105935,\n",
       "          0.61087728,  1.18115616,  2.36084805,  3.52508936,  1.33046937,\n",
       "          2.65568743,  5.24258127,  7.77610879,  1.31400447,  2.63510056,\n",
       "          5.20116196,  7.80200953,  1.32134171,  2.63959584,  5.20160122,\n",
       "          7.77763672,  0.53627429,  1.00808349,  2.01162629,  2.99034152,\n",
       "          0.5183064 ,  1.01502581,  2.01438007,  2.98905134,  0.5152483 ,\n",
       "          1.01915588,  2.00513225,  2.99367309,  0.86820083,  1.75068145,\n",
       "          3.39734917,  5.10303588,  0.86770535,  1.71100392,  3.44995823,\n",
       "          5.09874144,  0.87851081,  1.74163299,  3.43759127,  5.1069427 ,\n",
       "          1.86271234,  3.6696043 ,  7.3110188 , 10.93689184,  1.85228219,\n",
       "          3.67064838,  7.31365571, 10.95603952,  1.84466395,  3.63990202,\n",
       "          7.28951135, 10.92459574,  0.5642848 ,  1.09523025,  2.16911578,\n",
       "          3.25373235,  0.56851563,  1.10814347,  2.19488683,  3.26909165,\n",
       "          0.5553998 ,  1.09651151,  2.20418859,  3.24647059,  0.94648314,\n",
       "          1.82017078,  3.59843664,  5.41800723,  0.93099651,  1.80254297,\n",
       "          3.62368069,  5.41324701,  0.91887417,  1.80124555,  3.58371406,\n",
       "          5.37064528,  1.89496484,  3.82240496,  7.59887462, 11.35853744,\n",
       "          1.89895654,  3.78976336,  7.53134489, 11.26935582,  1.89939365,\n",
       "          3.79933143,  7.52392683, 11.28426571,  0.56264181,  1.09857917,\n",
       "          2.17357798,  3.29074073,  0.55925889,  1.09561653,  2.18145652,\n",
       "          3.25215492,  0.56022182,  1.09104452,  2.17077565,  3.2316411 ,\n",
       "          0.92226768,  1.8105402 ,  3.61155038,  5.42084417,  0.91817069,\n",
       "          1.82466121,  3.61981544,  5.39342227,  0.92992802,  1.81434565,\n",
       "          3.60119705,  5.38632011,  1.92442951,  3.9437438 ,  7.57341394,\n",
       "         11.32508173,  1.90328369,  3.81912899,  7.56919441, 11.33699431,\n",
       "          1.91778727,  3.7768939 ,  7.50610676, 11.32463655,  0.55996342,\n",
       "          1.09822874,  2.16637135,  3.30110641,  0.57075038,  1.10717182,\n",
       "          2.1993556 ,  3.25515299,  0.5614418 ,  1.09015198,  2.21229811,\n",
       "          3.24193215,  0.91507044,  1.81504736,  3.59025283,  5.40943561,\n",
       "          0.92769642,  1.80923433,  3.60885739,  5.44899421,  0.9226943 ,\n",
       "          1.84152241,  3.57119517,  5.41005597,  1.91584001,  3.78441558,\n",
       "          7.54740047, 11.32855606,  1.90589614,  3.77983642,  7.58639026,\n",
       "         11.29609232,  1.91868382,  3.77929001,  7.50234404, 10.33058496]),\n",
       "  'std_fit_time': array([0.05321529, 0.02162098, 0.08886989, 0.13820352, 0.01669319,\n",
       "         0.05651556, 0.04870022, 0.01229535, 0.00836708, 0.00246341,\n",
       "         0.01203559, 0.19615372, 0.0542605 , 0.17570136, 0.01503292,\n",
       "         0.01012419, 0.0022199 , 0.00462133, 0.00669779, 0.04827255,\n",
       "         0.00889612, 0.02174273, 0.05440464, 0.04259021, 0.01205236,\n",
       "         0.00940511, 0.01590119, 0.06067365, 0.00786655, 0.06712618,\n",
       "         0.04228753, 0.06732028, 0.00554866, 0.02539403, 0.03784288,\n",
       "         0.01831847, 0.00371849, 0.00660868, 0.01106122, 0.02060453,\n",
       "         0.00435859, 0.01145015, 0.01085456, 0.01478933, 0.00958912,\n",
       "         0.00732806, 0.00961565, 0.03010189, 0.0262057 , 0.01450761,\n",
       "         0.01073689, 0.01706155, 0.00658811, 0.01290952, 0.01096473,\n",
       "         0.03030906, 0.00582495, 0.01282158, 0.01849267, 0.02160557,\n",
       "         0.00713196, 0.04113408, 0.03657203, 0.03267363, 0.02668566,\n",
       "         0.03131439, 0.02979804, 0.05260421, 0.01381921, 0.02656794,\n",
       "         0.03393357, 0.09937386, 0.01293718, 0.02241576, 0.01461751,\n",
       "         0.03155332, 0.01437571, 0.01101825, 0.01828062, 0.02717573,\n",
       "         0.01315332, 0.00641624, 0.01629779, 0.03786398, 0.00720659,\n",
       "         0.01201201, 0.15280913, 0.24855455, 0.07685932, 0.03224375,\n",
       "         0.03256402, 0.05054622, 0.01303065, 0.01311111, 0.03737844,\n",
       "         0.03068777, 0.02776374, 0.05167355, 0.09680169, 0.11965586,\n",
       "         0.02816264, 0.04718613, 0.06212442, 0.16891846, 0.03749373,\n",
       "         0.02437298, 0.06356921, 0.11941206, 0.0054359 , 0.00753652,\n",
       "         0.01169466, 0.03376052, 0.01592922, 0.05830501, 0.04165238,\n",
       "         0.02660876, 0.00518873, 0.00642253, 0.02346112, 0.03871312,\n",
       "         0.02033509, 0.01833211, 0.03750558, 0.0629564 , 0.01023376,\n",
       "         0.01098645, 0.06608773, 0.03895621, 0.0092093 , 0.01650492,\n",
       "         0.02643831, 0.03121757, 0.02497712, 0.04244619, 0.09594422,\n",
       "         0.06345234, 0.01826192, 0.04262703, 0.0605226 , 0.13930364,\n",
       "         0.0248982 , 0.02567098, 0.05062044, 0.09570713, 0.00745966,\n",
       "         0.0048001 , 0.02680469, 0.00826769, 0.00884498, 0.03612718,\n",
       "         0.01645314, 0.0168317 , 0.01077681, 0.00730132, 0.01118957,\n",
       "         0.03288612, 0.00998716, 0.01837963, 0.05403268, 0.0370085 ,\n",
       "         0.00902224, 0.01386571, 0.03459569, 0.06363373, 0.02234498,\n",
       "         0.01625688, 0.03393215, 0.03988987, 0.01288514, 0.03988452,\n",
       "         0.09613154, 0.10246083, 0.03784361, 0.00987937, 0.06774191,\n",
       "         0.13010961, 0.03805883, 0.03870371, 0.09211507, 0.12406762,\n",
       "         0.00367642, 0.05672538, 0.03977594, 0.01608392, 0.00388626,\n",
       "         0.00424179, 0.00806072, 0.01014619, 0.00815313, 0.00586707,\n",
       "         0.00824735, 0.0232489 , 0.02521509, 0.00695773, 0.01111041,\n",
       "         0.00655404, 0.0053797 , 0.00592787, 0.00575586, 0.01510424,\n",
       "         0.00834169, 0.01888858, 0.01843616, 0.01405999, 0.00290505,\n",
       "         0.02250945, 0.03920175, 0.01815199, 0.01295349, 0.01458897,\n",
       "         0.01484282, 0.05050117, 0.00899927, 0.02129006, 0.01430949,\n",
       "         0.03487347, 0.00551564, 0.00759575, 0.03773021, 0.01296608,\n",
       "         0.00821094, 0.00955409, 0.01346922, 0.03115411, 0.00966006,\n",
       "         0.00753423, 0.02495291, 0.02331592, 0.0120087 , 0.01276058,\n",
       "         0.03212899, 0.03707521, 0.00786612, 0.01799828, 0.02406043,\n",
       "         0.0096747 , 0.0052183 , 0.0146304 , 0.02589633, 0.03984125,\n",
       "         0.02836475, 0.01888539, 0.05510995, 0.1106151 , 0.01509422,\n",
       "         0.02652919, 0.04039247, 0.0853829 , 0.01757814, 0.01295383,\n",
       "         0.08464507, 0.07934733, 0.00750295, 0.00725598, 0.01835725,\n",
       "         0.03662383, 0.01632065, 0.01140709, 0.02234141, 0.03080787,\n",
       "         0.0057974 , 0.01300786, 0.00597742, 0.01771955, 0.01072608,\n",
       "         0.02517349, 0.03053276, 0.03262935, 0.0107584 , 0.02710241,\n",
       "         0.0350393 , 0.05845074, 0.01060173, 0.00952651, 0.03905034,\n",
       "         0.04348958, 0.00911316, 0.02393418, 0.07948873, 0.08843241,\n",
       "         0.01299309, 0.04978086, 0.05700122, 0.05955986, 0.02262836,\n",
       "         0.02938974, 0.07449965, 0.08910057, 0.00578161, 0.00803211,\n",
       "         0.01972046, 0.02661238, 0.01456565, 0.00898237, 0.02503444,\n",
       "         0.03478067, 0.008944  , 0.01232722, 0.01923772, 0.03562648,\n",
       "         0.03398028, 0.03206439, 0.02893355, 0.04245166, 0.01007148,\n",
       "         0.01331597, 0.04581198, 0.05634099, 0.00466352, 0.01864107,\n",
       "         0.05144923, 0.03152418, 0.02195803, 0.01454572, 0.06194542,\n",
       "         0.06401266, 0.02190998, 0.04790125, 0.07029977, 0.09040102,\n",
       "         0.02337967, 0.02920733, 0.07728741, 0.09455157, 0.00437529,\n",
       "         0.01117337, 0.02564219, 0.02668966, 0.00678669, 0.04049304,\n",
       "         0.01604662, 0.02928151, 0.00234379, 0.01004365, 0.01917258,\n",
       "         0.04456523, 0.01813382, 0.02187256, 0.03266667, 0.04256634,\n",
       "         0.01059983, 0.01493181, 0.03523302, 0.0416947 , 0.01061871,\n",
       "         0.01606918, 0.04513869, 0.07851969, 0.01713206, 0.03003365,\n",
       "         0.07085432, 0.10089386, 0.01522181, 0.04694516, 0.07287485,\n",
       "         0.07075752, 0.01239758, 0.02994548, 0.07497922, 0.11577098,\n",
       "         0.01014801, 0.00541978, 0.00572911, 0.01089974, 0.00627081,\n",
       "         0.00307824, 0.01334626, 0.01164993, 0.00614339, 0.00589798,\n",
       "         0.0187697 , 0.01914428, 0.00557271, 0.00618238, 0.02161868,\n",
       "         0.01317123, 0.01819345, 0.00304033, 0.00569491, 0.02321387,\n",
       "         0.00789724, 0.01305319, 0.01053889, 0.01231215, 0.00881421,\n",
       "         0.01351077, 0.03800724, 0.04331571, 0.0225737 , 0.01484968,\n",
       "         0.05001978, 0.04646225, 0.012382  , 0.05611261, 0.02227839,\n",
       "         0.03912691, 0.00340578, 0.00542948, 0.00886843, 0.03158393,\n",
       "         0.00490424, 0.00929193, 0.01898411, 0.03774515, 0.00873077,\n",
       "         0.02863223, 0.01995844, 0.04489317, 0.01310457, 0.01377692,\n",
       "         0.01188808, 0.02426499, 0.00818536, 0.02813705, 0.01299856,\n",
       "         0.01227367, 0.01195338, 0.01662498, 0.04096899, 0.05212267,\n",
       "         0.01371689, 0.03441127, 0.3827418 , 0.74624818, 0.02027518,\n",
       "         0.05368188, 0.02820812, 0.02700678, 0.01636137, 0.008888  ,\n",
       "         0.03867973, 0.04243222, 0.00473553, 0.01439412, 0.02703891,\n",
       "         0.05492646, 0.01877929, 0.01244508, 0.02397831, 0.03578664,\n",
       "         0.01200376, 0.00916857, 0.04818304, 0.03416778, 0.02430908,\n",
       "         0.01427206, 0.03978799, 0.04141502, 0.02515835, 0.02779893,\n",
       "         0.05176764, 0.06695113, 0.01161067, 0.0342675 , 0.03283321,\n",
       "         0.10026121, 0.01713942, 0.0482848 , 0.09929667, 0.10194292,\n",
       "         0.03091436, 0.05702359, 0.10241046, 0.19101521, 0.04395688,\n",
       "         0.06074092, 0.14814884, 0.11300778, 0.00750609, 0.01477024,\n",
       "         0.01544759, 0.02298402, 0.00482062, 0.03383877, 0.00998228,\n",
       "         0.02612239, 0.00660462, 0.01956485, 0.03055778, 0.03446897,\n",
       "         0.01383057, 0.01084687, 0.05724321, 0.04706485, 0.01152671,\n",
       "         0.01020072, 0.03805185, 0.06357364, 0.01092718, 0.02727671,\n",
       "         0.03863022, 0.05843014, 0.01835806, 0.04052002, 0.09139057,\n",
       "         0.13786958, 0.03730628, 0.04225143, 0.11379614, 0.19706612,\n",
       "         0.06597782, 0.08198546, 0.11334654, 0.19021537, 0.0056059 ,\n",
       "         0.02106122, 0.01528325, 0.04285485, 0.01124539, 0.01213266,\n",
       "         0.02403701, 0.02392256, 0.01009116, 0.01058213, 0.02002745,\n",
       "         0.04811861, 0.01616299, 0.01097261, 0.03459867, 0.05024829,\n",
       "         0.01377677, 0.03293438, 0.02212029, 0.05772836, 0.01957833,\n",
       "         0.03279337, 0.06073511, 0.10140848, 0.01715813, 0.04635088,\n",
       "         0.07360798, 0.14010063, 0.02228344, 0.05124632, 0.15080402,\n",
       "         0.14450406, 0.02571661, 0.06597357, 0.1172439 , 0.11098127,\n",
       "         0.00634547, 0.00425384, 0.01553135, 0.01304267, 0.00662839,\n",
       "         0.0033732 , 0.00644947, 0.01043066, 0.00912178, 0.01434414,\n",
       "         0.01307125, 0.00750507, 0.00719822, 0.02161825, 0.01133011,\n",
       "         0.01385058, 0.00193071, 0.01595083, 0.01035158, 0.0227343 ,\n",
       "         0.00962058, 0.01307851, 0.00964363, 0.0240742 , 0.02011542,\n",
       "         0.03995256, 0.0421035 , 0.04754006, 0.01552906, 0.0282849 ,\n",
       "         0.02288102, 0.04685991, 0.01505963, 0.02227649, 0.01957352,\n",
       "         0.03489547, 0.02070363, 0.01167442, 0.02172537, 0.0275445 ,\n",
       "         0.00916217, 0.01186185, 0.02793995, 0.02927909, 0.00314826,\n",
       "         0.02420758, 0.01564045, 0.0227264 , 0.00637097, 0.04726686,\n",
       "         0.02568178, 0.03693898, 0.01193253, 0.02262935, 0.03608106,\n",
       "         0.04529045, 0.02932763, 0.03003766, 0.03005915, 0.03816761,\n",
       "         0.02106552, 0.04194855, 0.08343232, 0.10393438, 0.0224765 ,\n",
       "         0.03698839, 0.04586667, 0.08523638, 0.015848  , 0.03782324,\n",
       "         0.06294367, 0.06586933, 0.00654909, 0.01573887, 0.0277479 ,\n",
       "         0.02213569, 0.01833758, 0.01845802, 0.046894  , 0.03936874,\n",
       "         0.00903066, 0.02319315, 0.0248229 , 0.06385337, 0.01967525,\n",
       "         0.03025927, 0.04653855, 0.06980713, 0.01989504, 0.02979691,\n",
       "         0.05690784, 0.04626696, 0.01082119, 0.01730742, 0.03439476,\n",
       "         0.0541824 , 0.01856975, 0.06254862, 0.13367183, 0.12341411,\n",
       "         0.04019578, 0.06101756, 0.08151541, 0.12502222, 0.01648812,\n",
       "         0.0680203 , 0.07233265, 0.18182415, 0.00873471, 0.01529682,\n",
       "         0.03535681, 0.0229154 , 0.00982411, 0.01787901, 0.03226682,\n",
       "         0.02593563, 0.0135523 , 0.0122819 , 0.01993996, 0.03267053,\n",
       "         0.01825585, 0.0241387 , 0.05350017, 0.05188918, 0.00856009,\n",
       "         0.02780534, 0.02354243, 0.08249895, 0.01273685, 0.0215992 ,\n",
       "         0.05392822, 0.05470339, 0.04117558, 0.04086801, 0.10396605,\n",
       "         0.16829166, 0.02240671, 0.0539891 , 0.06670786, 0.13322149,\n",
       "         0.02716278, 0.04542279, 0.08724343, 0.14167522, 0.01006448,\n",
       "         0.01762502, 0.0149117 , 0.02925015, 0.01098691, 0.01803358,\n",
       "         0.01995089, 0.03218345, 0.01160345, 0.02224067, 0.01494787,\n",
       "         0.04302975, 0.01202105, 0.03762157, 0.04121294, 0.0661953 ,\n",
       "         0.02147889, 0.02112944, 0.06693951, 0.09029784, 0.01132815,\n",
       "         0.01482845, 0.03119477, 0.05416296, 0.01720305, 0.05397727,\n",
       "         0.10902454, 0.17207126, 0.02427962, 0.07369353, 0.0751701 ,\n",
       "         0.14636006, 0.03890235, 0.05819417, 0.09133185, 1.15447497]),\n",
       "  'mean_score_time': array([0.0147366 , 0.02792277, 0.04886765, 0.05869708, 0.01257439,\n",
       "         0.0307642 , 0.03370223, 0.04700618, 0.01209364, 0.02036967,\n",
       "         0.03640347, 0.06053724, 0.01673059, 0.01867943, 0.03209858,\n",
       "         0.04678574, 0.01231785, 0.01880503, 0.03393493, 0.04723511,\n",
       "         0.01335177, 0.03221402, 0.03750963, 0.04877858, 0.01289773,\n",
       "         0.02293563, 0.03574061, 0.05024295, 0.0131671 , 0.02330623,\n",
       "         0.03759685, 0.05169435, 0.01483641, 0.02365222, 0.0419723 ,\n",
       "         0.05459232, 0.01495724, 0.024087  , 0.04282923, 0.06533995,\n",
       "         0.01532116, 0.02488036, 0.04218183, 0.05751157, 0.01814823,\n",
       "         0.02415748, 0.04303269, 0.06040049, 0.01561303, 0.02618632,\n",
       "         0.04349012, 0.06091022, 0.01620278, 0.0237937 , 0.04075279,\n",
       "         0.06047235, 0.01513257, 0.02447977, 0.0412066 , 0.06149235,\n",
       "         0.01561966, 0.02372408, 0.04096794, 0.060007  , 0.01531782,\n",
       "         0.0234344 , 0.04314795, 0.05980086, 0.01518846, 0.02424607,\n",
       "         0.04023318, 0.06517901, 0.01980476, 0.02900081, 0.04338117,\n",
       "         0.07171359, 0.01715803, 0.02584562, 0.04460168, 0.06374059,\n",
       "         0.01665854, 0.02555294, 0.04456148, 0.06519046, 0.0157732 ,\n",
       "         0.02683454, 0.0557785 , 0.07526822, 0.01848822, 0.02562432,\n",
       "         0.04639893, 0.06503239, 0.01666703, 0.02512441, 0.04487715,\n",
       "         0.06038661, 0.01514053, 0.02489271, 0.04262638, 0.06104617,\n",
       "         0.01593223, 0.02318382, 0.04179564, 0.05931177, 0.01601267,\n",
       "         0.02376084, 0.04093204, 0.06165586, 0.01968665, 0.02511373,\n",
       "         0.04538684, 0.06359053, 0.01557202, 0.03386745, 0.045226  ,\n",
       "         0.06703267, 0.016081  , 0.02533541, 0.04502525, 0.06637692,\n",
       "         0.01614418, 0.02405343, 0.04331999, 0.06466284, 0.01597247,\n",
       "         0.02502055, 0.04359865, 0.06214304, 0.01623559, 0.025279  ,\n",
       "         0.04454074, 0.06192884, 0.01669416, 0.02391815, 0.04307556,\n",
       "         0.0609304 , 0.01569128, 0.02294893, 0.04257174, 0.0601903 ,\n",
       "         0.01680832, 0.02474866, 0.04087496, 0.05974655, 0.01606345,\n",
       "         0.02524643, 0.04388604, 0.0637084 , 0.01585846, 0.02556405,\n",
       "         0.0451014 , 0.06227741, 0.01581459, 0.02498221, 0.04359779,\n",
       "         0.06235962, 0.0155808 , 0.02472801, 0.04292254, 0.06114411,\n",
       "         0.01543317, 0.0244844 , 0.04313574, 0.06211257, 0.01511083,\n",
       "         0.02573791, 0.04430938, 0.05980506, 0.01583266, 0.024649  ,\n",
       "         0.03967648, 0.0576077 , 0.01507177, 0.02348976, 0.0405848 ,\n",
       "         0.05957513, 0.01541185, 0.02436099, 0.04148474, 0.06092677,\n",
       "         0.01408677, 0.02381339, 0.03622136, 0.05270891, 0.013941  ,\n",
       "         0.02144442, 0.03893085, 0.05331192, 0.01368446, 0.02228975,\n",
       "         0.04339752, 0.05429811, 0.01395626, 0.02164278, 0.03878431,\n",
       "         0.05292435, 0.01430445, 0.02145476, 0.03686218, 0.05299788,\n",
       "         0.01429858, 0.02402258, 0.03767762, 0.05279193, 0.01393552,\n",
       "         0.02107549, 0.03744373, 0.05277085, 0.01392255, 0.0211729 ,\n",
       "         0.03601995, 0.05172062, 0.01407714, 0.02130489, 0.03571286,\n",
       "         0.05195422, 0.01511679, 0.02701735, 0.04083552, 0.06180377,\n",
       "         0.01474614, 0.02313685, 0.04075642, 0.06063333, 0.01450548,\n",
       "         0.02412214, 0.04279466, 0.05726304, 0.01511855, 0.02300544,\n",
       "         0.04293818, 0.05786409, 0.01457138, 0.02332549, 0.04039345,\n",
       "         0.05804133, 0.01478167, 0.02364941, 0.039503  , 0.0554204 ,\n",
       "         0.01430297, 0.02236519, 0.0381124 , 0.05725245, 0.01456795,\n",
       "         0.02227225, 0.03851624, 0.05713396, 0.01472273, 0.02242022,\n",
       "         0.0385272 , 0.05520773, 0.01474462, 0.02419319, 0.04096498,\n",
       "         0.05930619, 0.0167779 , 0.02417197, 0.04108143, 0.06098294,\n",
       "         0.01516514, 0.02512817, 0.04193697, 0.05863557, 0.0148396 ,\n",
       "         0.02380667, 0.04048238, 0.0610878 , 0.01505723, 0.02325583,\n",
       "         0.04037905, 0.05706267, 0.01558666, 0.02329721, 0.04063883,\n",
       "         0.05773363, 0.01516895, 0.02255025, 0.03857579, 0.05887094,\n",
       "         0.01447253, 0.0225884 , 0.03851266, 0.05688024, 0.01424851,\n",
       "         0.02267675, 0.03868241, 0.05487599, 0.01503558, 0.02340574,\n",
       "         0.04366975, 0.06373177, 0.01639495, 0.02452168, 0.04083543,\n",
       "         0.06003537, 0.01476364, 0.02520022, 0.04217396, 0.05923042,\n",
       "         0.01502399, 0.02616582, 0.04094133, 0.0588418 , 0.01523118,\n",
       "         0.02338319, 0.03999138, 0.05827394, 0.01493521, 0.02319417,\n",
       "         0.04069548, 0.06040187, 0.01467285, 0.02322536, 0.03886523,\n",
       "         0.05779037, 0.01463389, 0.02289815, 0.03790317, 0.053932  ,\n",
       "         0.01532826, 0.02255263, 0.03996339, 0.0585928 , 0.01438599,\n",
       "         0.02321062, 0.04176412, 0.05890074, 0.01471887, 0.02406063,\n",
       "         0.04187407, 0.06101799, 0.01545558, 0.02450337, 0.04169278,\n",
       "         0.05465732, 0.01599755, 0.02581878, 0.04046741, 0.05930443,\n",
       "         0.01681557, 0.02405233, 0.04131446, 0.0578002 , 0.01452389,\n",
       "         0.0247746 , 0.04080162, 0.05999198, 0.01598783, 0.02240176,\n",
       "         0.03933544, 0.05537424, 0.01448283, 0.02282023, 0.03848596,\n",
       "         0.05442791, 0.0143147 , 0.02280402, 0.03853436, 0.05794382,\n",
       "         0.0151988 , 0.02096925, 0.03712597, 0.05215359, 0.01372581,\n",
       "         0.02228513, 0.03826785, 0.05249033, 0.01485047, 0.02217197,\n",
       "         0.03752217, 0.05826397, 0.01424704, 0.02181034, 0.03750982,\n",
       "         0.05476751, 0.01413331, 0.02249174, 0.03865485, 0.05300822,\n",
       "         0.01422415, 0.02200842, 0.0388082 , 0.0513536 , 0.01389213,\n",
       "         0.0230392 , 0.03734293, 0.05187263, 0.01649117, 0.02145333,\n",
       "         0.035853  , 0.07904596, 0.01403227, 0.02165728, 0.03648009,\n",
       "         0.05213366, 0.01496382, 0.02369618, 0.04239454, 0.05991187,\n",
       "         0.0162034 , 0.02414918, 0.04164677, 0.06173596, 0.01536841,\n",
       "         0.02513461, 0.04231129, 0.06059628, 0.01485639, 0.02484574,\n",
       "         0.0403718 , 0.05984774, 0.0147943 , 0.02468023, 0.0443172 ,\n",
       "         0.06101637, 0.01502681, 0.02403355, 0.04270196, 0.05708609,\n",
       "         0.01438818, 0.0231297 , 0.04319129, 0.06053324, 0.01443315,\n",
       "         0.02342033, 0.03931427, 0.05586119, 0.01488838, 0.02362108,\n",
       "         0.0398634 , 0.05507712, 0.01540937, 0.0237968 , 0.04242945,\n",
       "         0.06000075, 0.01549559, 0.02441411, 0.04320722, 0.06079788,\n",
       "         0.0155705 , 0.02409496, 0.044981  , 0.05916915, 0.01504135,\n",
       "         0.02371793, 0.04151955, 0.06044059, 0.01497722, 0.02335067,\n",
       "         0.0422565 , 0.05831766, 0.0151422 , 0.02376451, 0.04082007,\n",
       "         0.05902619, 0.01492324, 0.02262392, 0.04600978, 0.05622458,\n",
       "         0.0148294 , 0.02276978, 0.0409914 , 0.05438948, 0.0140172 ,\n",
       "         0.02278605, 0.038977  , 0.05642438, 0.0152174 , 0.02432485,\n",
       "         0.04439139, 0.06022644, 0.01516466, 0.02480178, 0.04233665,\n",
       "         0.06186032, 0.01547456, 0.02415342, 0.04188256, 0.06088467,\n",
       "         0.0149034 , 0.02528358, 0.04133563, 0.05833516, 0.01495037,\n",
       "         0.02359204, 0.04247379, 0.05844741, 0.01482859, 0.02660656,\n",
       "         0.04076767, 0.05912871, 0.01485052, 0.02304516, 0.03972526,\n",
       "         0.05903301, 0.01438174, 0.02287169, 0.03927603, 0.05739884,\n",
       "         0.0146162 , 0.02292686, 0.03751335, 0.05630445, 0.01602201,\n",
       "         0.023769  , 0.04210796, 0.06425676, 0.01538663, 0.02525101,\n",
       "         0.04448009, 0.06105299, 0.01554208, 0.02443924, 0.04397931,\n",
       "         0.05965357, 0.01596222, 0.02356   , 0.04055181, 0.06057687,\n",
       "         0.01490688, 0.02428522, 0.04145651, 0.05990615, 0.01586103,\n",
       "         0.02611313, 0.04194999, 0.05798235, 0.01470728, 0.02269316,\n",
       "         0.04044962, 0.05891662, 0.01653581, 0.02375035, 0.03968015,\n",
       "         0.05769358, 0.0166996 , 0.02354636, 0.04231029, 0.05680737,\n",
       "         0.01367364, 0.02286062, 0.03810935, 0.05191898, 0.0136436 ,\n",
       "         0.02308588, 0.0369328 , 0.05392442, 0.01591063, 0.0221416 ,\n",
       "         0.03679199, 0.05278206, 0.01460414, 0.02387686, 0.03649597,\n",
       "         0.05179753, 0.01464586, 0.02155647, 0.04154377, 0.05022621,\n",
       "         0.01441741, 0.02118974, 0.03591051, 0.0510921 , 0.01373916,\n",
       "         0.02134342, 0.03607664, 0.05091906, 0.01337953, 0.02118464,\n",
       "         0.03576126, 0.05228343, 0.01405697, 0.02079105, 0.03559694,\n",
       "         0.04993386, 0.01458931, 0.02292371, 0.04101214, 0.05695982,\n",
       "         0.01486678, 0.02393417, 0.0430943 , 0.05773978, 0.01493979,\n",
       "         0.02322698, 0.03924174, 0.05540252, 0.01466417, 0.02305741,\n",
       "         0.03966537, 0.05598044, 0.01553378, 0.02253237, 0.03856554,\n",
       "         0.0585752 , 0.01434445, 0.02330251, 0.0390059 , 0.05616398,\n",
       "         0.01419563, 0.02252665, 0.03959765, 0.05596356, 0.01443944,\n",
       "         0.02216682, 0.03856459, 0.05431967, 0.01665206, 0.0222651 ,\n",
       "         0.03780065, 0.05430245, 0.01478624, 0.02343125, 0.04104571,\n",
       "         0.05749402, 0.01489139, 0.0248261 , 0.04053617, 0.06380138,\n",
       "         0.0156858 , 0.02377777, 0.04030733, 0.06034384, 0.01620173,\n",
       "         0.02367568, 0.03954759, 0.05643473, 0.01474209, 0.02297845,\n",
       "         0.04001155, 0.05812488, 0.01451135, 0.02283387, 0.04044838,\n",
       "         0.05650454, 0.01437316, 0.02240624, 0.03844514, 0.05787864,\n",
       "         0.01432981, 0.0243618 , 0.03871322, 0.05417714, 0.01417112,\n",
       "         0.0220161 , 0.03813343, 0.05813203, 0.01527553, 0.02301159,\n",
       "         0.0412394 , 0.05812349, 0.01478004, 0.02381167, 0.04388309,\n",
       "         0.05904069, 0.01504202, 0.02330217, 0.04140573, 0.05763917,\n",
       "         0.01385875, 0.02313924, 0.04090128, 0.06160898, 0.01482043,\n",
       "         0.02550473, 0.04055443, 0.0571702 , 0.01459408, 0.02282224,\n",
       "         0.03932548, 0.05591373, 0.01469412, 0.02283378, 0.03817525,\n",
       "         0.05782142, 0.01434588, 0.02387056, 0.03822322, 0.05531025,\n",
       "         0.01421509, 0.02212219, 0.03927221, 0.05942554, 0.01473212,\n",
       "         0.02322879, 0.04164443, 0.06033487, 0.0148963 , 0.02547159,\n",
       "         0.04126925, 0.05933452, 0.01493936, 0.02475486, 0.04134183,\n",
       "         0.05864463, 0.0146153 , 0.02310224, 0.03932672, 0.05772219,\n",
       "         0.01542115, 0.02427692, 0.03947859, 0.05601091, 0.01457405,\n",
       "         0.02293749, 0.04124069, 0.06136327, 0.01455288, 0.02263651,\n",
       "         0.03815637, 0.05515895, 0.01476369, 0.02360816, 0.03825459,\n",
       "         0.0550817 , 0.01431341, 0.02222981, 0.03857603, 0.04583397]),\n",
       "  'std_score_time': array([3.13831723e-03, 4.60186281e-03, 1.91437237e-02, 1.42870159e-02,\n",
       "         8.93093140e-04, 8.11850406e-03, 3.92637369e-03, 1.92639835e-03,\n",
       "         1.24492548e-04, 2.10037363e-03, 4.18330720e-03, 2.58101576e-02,\n",
       "         5.20965456e-03, 1.38892474e-04, 7.57773064e-04, 2.14306468e-03,\n",
       "         2.50422709e-04, 2.54114436e-04, 3.21490719e-03, 2.65840434e-03,\n",
       "         1.16137098e-03, 1.95538256e-02, 5.37270921e-03, 1.45809912e-03,\n",
       "         2.16317165e-04, 4.45369815e-03, 2.19629535e-03, 2.04220793e-03,\n",
       "         1.93317182e-04, 2.45895675e-03, 3.25342759e-03, 8.08011102e-04,\n",
       "         1.44453408e-03, 4.88581435e-03, 1.13789827e-02, 4.78316697e-03,\n",
       "         2.01113351e-04, 2.42500664e-04, 2.16231304e-03, 3.30281382e-03,\n",
       "         7.98193992e-04, 1.45762334e-03, 1.25336016e-03, 3.08596397e-03,\n",
       "         5.77763911e-03, 1.37336920e-03, 1.64423962e-03, 1.28379162e-03,\n",
       "         1.11803370e-03, 3.23285943e-03, 4.08466784e-03, 3.51595791e-03,\n",
       "         1.70824220e-03, 6.40847888e-04, 1.44501413e-03, 2.60434870e-03,\n",
       "         2.09364128e-04, 1.43687450e-03, 1.14547764e-03, 2.19381239e-03,\n",
       "         8.88062663e-04, 6.08486870e-04, 6.75040212e-04, 3.02656759e-03,\n",
       "         5.00657821e-04, 2.98906239e-04, 3.26291168e-03, 1.52678677e-03,\n",
       "         2.13839643e-04, 1.69904649e-03, 6.43216712e-04, 1.03059540e-02,\n",
       "         8.28341682e-03, 7.15422625e-03, 1.12723672e-03, 1.16315976e-02,\n",
       "         6.65782642e-04, 5.37205504e-04, 3.13153268e-03, 5.73966912e-03,\n",
       "         7.46039400e-04, 6.46871995e-04, 1.95400877e-03, 5.74297216e-03,\n",
       "         5.61342266e-04, 2.75659440e-03, 2.98063072e-03, 9.26650246e-03,\n",
       "         4.64809263e-03, 1.26644692e-03, 4.67807066e-03, 6.39332346e-03,\n",
       "         2.00542594e-03, 1.20458173e-03, 4.93007614e-03, 1.50461698e-03,\n",
       "         1.39219711e-03, 9.62172973e-04, 1.24441973e-03, 2.48522181e-03,\n",
       "         7.23605715e-04, 2.08573049e-03, 5.81257525e-04, 1.72969230e-03,\n",
       "         1.58044320e-03, 7.05203006e-04, 4.48336349e-04, 4.36813545e-03,\n",
       "         4.84059490e-03, 4.36348329e-04, 1.52276883e-03, 3.25051607e-03,\n",
       "         5.07703738e-04, 1.69098667e-02, 1.08202820e-03, 4.90246019e-03,\n",
       "         4.28820682e-04, 2.71795198e-04, 1.36081971e-03, 3.79700587e-03,\n",
       "         4.22710980e-04, 2.20574855e-03, 2.25269320e-03, 2.74671182e-03,\n",
       "         5.20173449e-04, 2.47844543e-04, 1.44650838e-03, 4.88889523e-04,\n",
       "         7.30959449e-04, 6.37914639e-04, 1.90340255e-03, 3.00502023e-03,\n",
       "         2.81176201e-03, 5.31774669e-04, 1.52939526e-03, 5.18849490e-03,\n",
       "         9.50147198e-04, 8.78498728e-04, 2.91992688e-03, 2.01270092e-03,\n",
       "         2.08528570e-03, 1.30837855e-03, 8.57830008e-04, 3.87773136e-03,\n",
       "         4.87307373e-04, 4.14526211e-04, 2.27226063e-03, 1.79561426e-03,\n",
       "         4.86258498e-04, 5.49180905e-04, 2.02401218e-03, 1.05061474e-03,\n",
       "         8.48030486e-04, 6.36290225e-04, 1.46556024e-03, 1.67296055e-03,\n",
       "         3.01689734e-04, 6.93234798e-04, 1.84480898e-03, 2.89390877e-03,\n",
       "         8.70405597e-05, 2.50200733e-04, 1.03884214e-03, 1.52936880e-03,\n",
       "         6.51595396e-04, 2.67405673e-03, 3.37076011e-03, 1.32220358e-03,\n",
       "         1.67927450e-03, 6.21860477e-04, 1.55946989e-03, 1.26241219e-03,\n",
       "         9.38093462e-05, 3.48683937e-04, 1.70611817e-03, 9.35111714e-04,\n",
       "         5.61970060e-04, 1.38806578e-03, 2.48359728e-03, 3.49843560e-03,\n",
       "         4.57507534e-04, 3.73749848e-03, 1.99573845e-04, 1.62278537e-03,\n",
       "         4.10522300e-04, 6.57958938e-04, 2.26537816e-03, 1.70108196e-03,\n",
       "         1.47734226e-03, 1.56341694e-03, 3.34171185e-03, 2.24686464e-03,\n",
       "         7.60982423e-04, 4.28453845e-04, 2.17758269e-03, 8.21056353e-04,\n",
       "         1.11077852e-03, 9.45550908e-04, 6.80226589e-04, 8.99002295e-04,\n",
       "         5.20228828e-04, 2.76004641e-03, 2.78103028e-03, 2.52773353e-03,\n",
       "         5.10442839e-04, 8.76191282e-04, 9.84129476e-04, 3.59903921e-03,\n",
       "         3.90126925e-04, 1.07569918e-04, 1.01693041e-03, 1.33977625e-03,\n",
       "         3.92864841e-04, 1.46111604e-04, 6.00054551e-04, 2.00761381e-03,\n",
       "         7.53825989e-04, 5.06327712e-03, 9.01765012e-04, 2.22464328e-03,\n",
       "         1.58295530e-04, 2.19776000e-04, 6.03196939e-04, 4.05529784e-03,\n",
       "         4.63374874e-04, 7.37054703e-04, 2.30694320e-03, 1.06862810e-03,\n",
       "         1.08506044e-03, 5.17617649e-04, 3.87209007e-03, 4.17889608e-03,\n",
       "         2.52089307e-04, 4.06770979e-04, 1.96266073e-03, 4.90247455e-03,\n",
       "         3.86262245e-04, 1.83760836e-03, 3.12870901e-04, 8.82350525e-04,\n",
       "         5.70053089e-04, 4.67491904e-04, 7.80590162e-04, 2.83510060e-03,\n",
       "         3.48703473e-04, 1.39666645e-03, 6.72799174e-04, 4.83492630e-03,\n",
       "         1.35267950e-03, 7.24636557e-04, 9.23841622e-04, 1.90439781e-03,\n",
       "         1.93240081e-04, 1.36712750e-03, 7.86045172e-04, 8.00695514e-04,\n",
       "         2.57082706e-03, 4.60256939e-04, 1.90846269e-03, 3.53254951e-03,\n",
       "         5.00129657e-04, 2.78526115e-03, 2.73661537e-03, 8.02351381e-04,\n",
       "         2.36191677e-03, 1.50608884e-03, 1.18376483e-03, 4.19629085e-03,\n",
       "         5.40906102e-04, 6.33136884e-04, 5.53597693e-04, 6.52410290e-04,\n",
       "         1.92781260e-03, 5.96505686e-04, 1.50284052e-03, 1.97403766e-03,\n",
       "         1.13266390e-03, 5.04607357e-04, 3.64424388e-04, 7.66448653e-03,\n",
       "         4.84608396e-04, 3.41776458e-04, 9.44135073e-04, 3.55874623e-03,\n",
       "         2.01785835e-04, 4.51018422e-04, 1.25377014e-03, 3.24502565e-03,\n",
       "         3.59341724e-04, 3.05880738e-04, 2.75587683e-03, 1.06117692e-02,\n",
       "         2.60586189e-03, 1.36494847e-03, 8.21112387e-04, 2.20012606e-03,\n",
       "         1.58274414e-04, 1.63699646e-03, 2.35559808e-03, 1.36339468e-03,\n",
       "         4.25896989e-04, 2.54742455e-03, 1.48117512e-03, 1.86449288e-03,\n",
       "         4.92930153e-04, 4.67563998e-04, 6.11406882e-04, 2.24614722e-03,\n",
       "         2.28931471e-04, 8.07715187e-04, 2.52693832e-03, 5.27259429e-03,\n",
       "         2.82760358e-04, 8.73463981e-04, 8.80614320e-04, 2.78961800e-03,\n",
       "         1.18726611e-04, 5.37805168e-04, 1.54755771e-03, 1.27461145e-03,\n",
       "         1.38194185e-03, 8.27765885e-04, 2.12770738e-03, 6.38455476e-03,\n",
       "         5.43427785e-04, 3.39134572e-04, 1.44308956e-03, 1.42098528e-03,\n",
       "         3.71874951e-04, 3.47460038e-04, 1.61229706e-03, 2.64971655e-03,\n",
       "         7.89211978e-04, 1.51419360e-03, 1.58440255e-03, 9.15573339e-03,\n",
       "         1.53540822e-03, 4.21513894e-03, 8.98045266e-04, 3.12064257e-03,\n",
       "         2.21807272e-03, 2.04918895e-03, 2.40236934e-03, 1.86700701e-03,\n",
       "         1.44646538e-04, 2.81688419e-03, 2.38283049e-03, 2.26919504e-03,\n",
       "         2.96856393e-03, 3.65944754e-03, 1.05941648e-03, 1.33449305e-03,\n",
       "         1.86180981e-04, 5.76820255e-04, 6.98511597e-04, 1.12399302e-03,\n",
       "         4.49178715e-04, 6.90401026e-04, 8.02105562e-04, 7.38539007e-03,\n",
       "         2.89969681e-03, 2.03301612e-04, 1.45003235e-03, 8.58032726e-04,\n",
       "         2.11935981e-04, 1.73948245e-03, 2.03269030e-03, 8.42039076e-04,\n",
       "         1.48941708e-03, 1.86542199e-03, 1.40212314e-03, 6.57199390e-03,\n",
       "         7.92965464e-04, 3.35283612e-04, 8.08228048e-04, 3.98636032e-03,\n",
       "         5.60269632e-04, 1.70794613e-03, 1.97593005e-03, 2.07340608e-03,\n",
       "         4.00939603e-04, 1.14774686e-03, 2.36917409e-03, 3.81972886e-03,\n",
       "         2.69716792e-04, 2.54643391e-03, 1.95853824e-03, 1.50761576e-03,\n",
       "         5.09980014e-03, 3.75321475e-04, 1.43801117e-03, 3.27259407e-02,\n",
       "         2.59636961e-04, 6.97463036e-04, 5.28026906e-04, 1.35684452e-03,\n",
       "         1.54458692e-04, 2.76863407e-03, 3.02246235e-03, 4.00690233e-03,\n",
       "         1.47222982e-03, 6.50261016e-04, 1.17887948e-03, 1.59598944e-03,\n",
       "         4.81163270e-04, 2.19004802e-03, 2.44302970e-03, 5.35944502e-03,\n",
       "         1.00561599e-04, 3.08515504e-03, 8.60403898e-04, 3.29729334e-03,\n",
       "         3.28354838e-04, 1.07612684e-03, 5.19185904e-03, 5.43924948e-03,\n",
       "         4.01042162e-04, 8.54546322e-04, 2.16926067e-03, 8.45740913e-04,\n",
       "         4.04770675e-04, 4.57621965e-04, 3.93979879e-03, 6.10378852e-03,\n",
       "         2.21038583e-04, 2.23494315e-03, 1.10860004e-03, 2.11604092e-03,\n",
       "         9.35096142e-04, 2.46047767e-03, 3.44284168e-03, 4.70192567e-04,\n",
       "         2.69716674e-04, 5.61467260e-04, 1.05807042e-03, 5.89534793e-04,\n",
       "         4.69011667e-04, 4.89427931e-04, 1.55458387e-03, 3.17306004e-03,\n",
       "         5.41437971e-04, 4.74263940e-04, 5.13487299e-03, 1.11789056e-03,\n",
       "         3.62175134e-04, 4.10730639e-04, 1.53613754e-03, 2.99946538e-03,\n",
       "         1.11794469e-04, 2.65453255e-04, 2.17241092e-03, 1.46214018e-03,\n",
       "         2.26765575e-04, 6.18125511e-04, 3.79816705e-03, 2.20958183e-03,\n",
       "         2.43299897e-04, 1.05548217e-03, 1.05046168e-02, 2.61586167e-03,\n",
       "         4.08272085e-04, 1.98684580e-04, 2.42947420e-03, 2.15966405e-03,\n",
       "         1.17167965e-03, 2.09009459e-04, 6.13719999e-04, 1.25587592e-03,\n",
       "         2.28620996e-04, 5.67549474e-04, 4.26298169e-03, 1.26423386e-03,\n",
       "         2.41503988e-04, 1.32797757e-03, 6.46188200e-04, 3.35963356e-03,\n",
       "         3.31698703e-04, 8.65032435e-04, 5.03460140e-04, 1.60264703e-03,\n",
       "         2.24801924e-04, 1.29059291e-03, 2.14824737e-03, 1.22056834e-03,\n",
       "         9.03676994e-05, 1.40701904e-04, 2.59056012e-03, 1.69361814e-03,\n",
       "         1.75104746e-04, 3.92605019e-03, 5.49195507e-04, 2.46405755e-03,\n",
       "         1.21534988e-04, 6.46947391e-04, 8.38714615e-04, 1.44819655e-03,\n",
       "         5.64769533e-04, 3.24462246e-04, 3.75747275e-04, 8.21498322e-04,\n",
       "         4.22926695e-04, 3.56952806e-04, 2.78002179e-03, 1.53482173e-03,\n",
       "         1.96926735e-03, 4.34959125e-04, 5.30383435e-04, 3.64336412e-03,\n",
       "         1.47120793e-04, 1.30699635e-03, 2.96444124e-03, 1.89525750e-03,\n",
       "         5.18839857e-04, 1.42098951e-03, 2.09073013e-03, 6.58823305e-04,\n",
       "         2.13881675e-03, 4.29077974e-04, 8.08689484e-04, 1.66711070e-03,\n",
       "         1.82246139e-04, 1.14859616e-03, 2.00222438e-03, 4.40605456e-03,\n",
       "         1.66981727e-03, 4.99688751e-03, 3.45537825e-03, 1.93091021e-03,\n",
       "         5.29552673e-04, 2.65306599e-04, 1.69734275e-03, 3.05606948e-03,\n",
       "         2.29731071e-03, 1.69027302e-03, 2.45901896e-03, 4.22049671e-03,\n",
       "         4.45420369e-03, 1.53668698e-03, 2.65773274e-03, 1.60226476e-03,\n",
       "         4.49093139e-04, 2.71998407e-03, 6.21729720e-03, 4.76562104e-03,\n",
       "         2.14691375e-04, 3.24562817e-03, 2.36400089e-03, 3.50076226e-03,\n",
       "         4.44045846e-03, 1.76910595e-03, 1.52665500e-03, 2.71508694e-03,\n",
       "         2.03319497e-03, 5.32839976e-03, 1.72113797e-03, 2.58556123e-03,\n",
       "         1.16436436e-03, 9.63488678e-04, 6.59797434e-03, 5.87891080e-04,\n",
       "         1.33271995e-03, 4.36441510e-04, 1.04491607e-03, 8.74723623e-04,\n",
       "         2.69959848e-04, 7.78485189e-04, 1.81948986e-03, 1.17548657e-03,\n",
       "         1.24044345e-04, 7.12353292e-04, 8.61357349e-04, 5.12580508e-03,\n",
       "         9.63911689e-04, 5.31868728e-04, 5.47279752e-04, 4.30577416e-04,\n",
       "         1.42632747e-04, 4.62596854e-04, 3.32524112e-03, 7.53151595e-04,\n",
       "         6.70700498e-04, 1.35874419e-03, 5.07787519e-03, 5.34586972e-04,\n",
       "         7.52582753e-04, 3.89202919e-04, 2.47301303e-04, 1.92745641e-03,\n",
       "         2.79932248e-04, 8.02046300e-04, 1.58658102e-03, 1.08524130e-03,\n",
       "         2.07596889e-03, 3.40364901e-04, 6.50377507e-04, 4.71826942e-03,\n",
       "         7.58503895e-05, 9.06110020e-04, 7.20063969e-04, 1.87697487e-03,\n",
       "         1.70466410e-04, 5.65298437e-04, 3.52190568e-03, 3.10442273e-03,\n",
       "         5.77817854e-04, 6.72004843e-04, 1.20513462e-03, 1.18138085e-03,\n",
       "         5.06656336e-03, 4.24863289e-04, 7.64768206e-04, 6.87580714e-04,\n",
       "         1.02348628e-04, 5.32748316e-04, 9.68185065e-04, 2.21363798e-03,\n",
       "         1.38079148e-04, 1.34028840e-03, 4.22741622e-04, 6.32782643e-03,\n",
       "         1.62371137e-03, 5.26523784e-04, 9.74695852e-04, 3.54360336e-03,\n",
       "         2.81213659e-03, 1.23096529e-03, 1.41064011e-03, 5.46398576e-04,\n",
       "         2.66208555e-04, 6.79562759e-04, 2.58221147e-03, 3.46786610e-03,\n",
       "         1.61680822e-03, 2.66805087e-04, 3.26832418e-03, 1.50632683e-03,\n",
       "         3.31901530e-04, 3.19455758e-04, 2.79242927e-03, 3.23782802e-03,\n",
       "         2.56181605e-04, 4.10125313e-03, 2.38716838e-03, 2.81664872e-04,\n",
       "         2.94708240e-04, 6.26943592e-04, 4.15036674e-04, 4.82086524e-03,\n",
       "         3.88952869e-04, 5.82223493e-04, 1.95128790e-03, 4.62655602e-04,\n",
       "         2.64926880e-04, 4.90677776e-04, 4.95696202e-03, 8.38541436e-04,\n",
       "         4.22899222e-04, 1.98010762e-04, 1.37653504e-03, 4.76521325e-04,\n",
       "         1.03654694e-03, 6.84637654e-04, 3.75955189e-03, 7.55669080e-03,\n",
       "         3.60488280e-04, 4.90321914e-03, 1.54953584e-03, 1.43521041e-03,\n",
       "         1.26554325e-04, 3.37314943e-04, 4.37502965e-04, 5.53552972e-04,\n",
       "         4.26553549e-04, 8.04919801e-04, 1.64543823e-03, 4.04353062e-03,\n",
       "         1.17847388e-04, 3.59238264e-03, 2.42147534e-04, 2.56110638e-03,\n",
       "         2.07516913e-04, 2.94211363e-04, 1.64147445e-03, 6.28837666e-03,\n",
       "         2.49854663e-04, 1.96583867e-04, 1.04037282e-03, 3.07956804e-03,\n",
       "         2.83700021e-04, 1.90223405e-03, 5.16183115e-04, 2.37827657e-03,\n",
       "         1.24894603e-04, 2.26195763e-03, 1.82198650e-03, 1.28990396e-03,\n",
       "         1.52067773e-04, 1.18610921e-04, 4.34985518e-04, 2.95961568e-03,\n",
       "         1.09478237e-03, 1.69393631e-03, 4.73824555e-04, 3.64131886e-03,\n",
       "         1.12997227e-04, 6.71816605e-04, 2.78789286e-03, 5.87592997e-03,\n",
       "         2.98566910e-04, 4.39903370e-04, 2.95057357e-03, 5.71713149e-04,\n",
       "         6.27225200e-04, 1.97938334e-03, 5.86518109e-04, 1.00440188e-03,\n",
       "         6.77044311e-04, 2.32386705e-04, 6.81655731e-04, 1.34931017e-02]),\n",
       "  'param_model__bootstrap': masked_array(data=[True, True, True, True, True, True, True, True, True,\n",
       "                     True, True, True, True, True, True, True, True, True,\n",
       "                     True, True, True, True, True, True, True, True, True,\n",
       "                     True, True, True, True, True, True, True, True, True,\n",
       "                     True, True, True, True, True, True, True, True, True,\n",
       "                     True, True, True, True, True, True, True, True, True,\n",
       "                     True, True, True, True, True, True, True, True, True,\n",
       "                     True, True, True, True, True, True, True, True, True,\n",
       "                     True, True, True, True, True, True, True, True, True,\n",
       "                     True, True, True, True, True, True, True, True, True,\n",
       "                     True, True, True, True, True, True, True, True, True,\n",
       "                     True, True, True, True, True, True, True, True, True,\n",
       "                     True, True, True, True, True, True, True, True, True,\n",
       "                     True, True, True, True, True, True, True, True, True,\n",
       "                     True, True, True, True, True, True, True, True, True,\n",
       "                     True, True, True, True, True, True, True, True, True,\n",
       "                     True, True, True, True, True, True, True, True, True,\n",
       "                     True, True, True, True, True, True, True, True, True,\n",
       "                     True, True, True, True, True, True, True, True, True,\n",
       "                     True, True, True, True, True, True, True, True, True,\n",
       "                     True, True, True, True, True, True, True, True, True,\n",
       "                     True, True, True, True, True, True, True, True, True,\n",
       "                     True, True, True, True, True, True, True, True, True,\n",
       "                     True, True, True, True, True, True, True, True, True,\n",
       "                     True, True, True, True, True, True, True, True, True,\n",
       "                     True, True, True, True, True, True, True, True, True,\n",
       "                     True, True, True, True, True, True, True, True, True,\n",
       "                     True, True, True, True, True, True, True, True, True,\n",
       "                     True, True, True, True, True, True, True, True, True,\n",
       "                     True, True, True, True, True, True, True, True, True,\n",
       "                     True, True, True, True, True, True, True, True, True,\n",
       "                     True, True, True, True, True, True, True, True, True,\n",
       "                     True, True, True, True, True, True, True, True, True,\n",
       "                     True, True, True, True, True, True, True, True, True,\n",
       "                     True, True, True, True, True, True, True, True, True,\n",
       "                     True, True, True, True, True, True, True, True, True,\n",
       "                     True, True, True, True, True, True, True, True, True,\n",
       "                     True, True, True, True, True, True, True, True, True,\n",
       "                     True, True, True, True, True, True, True, True, True,\n",
       "                     True, True, True, True, True, True, True, True, True,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy'],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__max_depth': masked_array(data=[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                     5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                     10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                     10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                     10, 10, 10, 10, 10, 10, 10, 10, 50, 50, 50, 50, 50, 50,\n",
       "                     50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                     50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                     50, 50, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                     100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                     100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                     100, 100, 100, 100, 100, None, None, None, None, None,\n",
       "                     None, None, None, None, None, None, None, None, None,\n",
       "                     None, None, None, None, None, None, None, None, None,\n",
       "                     None, None, None, None, None, None, None, None, None,\n",
       "                     None, None, None, None, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                     5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                     5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                     10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                     10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                     50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                     50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                     50, 50, 50, 50, 50, 50, 50, 50, 100, 100, 100, 100,\n",
       "                     100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                     100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                     100, 100, 100, 100, 100, 100, 100, 100, 100, 100, None,\n",
       "                     None, None, None, None, None, None, None, None, None,\n",
       "                     None, None, None, None, None, None, None, None, None,\n",
       "                     None, None, None, None, None, None, None, None, None,\n",
       "                     None, None, None, None, None, None, None, None, 5, 5,\n",
       "                     5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                     5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10,\n",
       "                     10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                     10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                     10, 10, 10, 10, 10, 10, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                     50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                     50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                     100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                     100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                     100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                     100, 100, 100, None, None, None, None, None, None,\n",
       "                     None, None, None, None, None, None, None, None, None,\n",
       "                     None, None, None, None, None, None, None, None, None,\n",
       "                     None, None, None, None, None, None, None, None, None,\n",
       "                     None, None, None, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                     5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                     5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                     10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                     10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 50,\n",
       "                     50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                     50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                     50, 50, 50, 50, 50, 50, 50, 100, 100, 100, 100, 100,\n",
       "                     100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                     100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                     100, 100, 100, 100, 100, 100, 100, 100, 100, None,\n",
       "                     None, None, None, None, None, None, None, None, None,\n",
       "                     None, None, None, None, None, None, None, None, None,\n",
       "                     None, None, None, None, None, None, None, None, None,\n",
       "                     None, None, None, None, None, None, None, None],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__max_features': masked_array(data=[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10,\n",
       "                     10, 10, 10, 10, 10, 10, 10, 25, 25, 25, 25, 25, 25, 25,\n",
       "                     25, 25, 25, 25, 25, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                     10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 25, 25,\n",
       "                     25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 5, 5, 5, 5, 5,\n",
       "                     5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                     10, 10, 10, 10, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "                     25, 25, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10,\n",
       "                     10, 10, 10, 10, 10, 10, 10, 10, 10, 25, 25, 25, 25, 25,\n",
       "                     25, 25, 25, 25, 25, 25, 25, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                     5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                     10, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 5,\n",
       "                     5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10,\n",
       "                     10, 10, 10, 10, 10, 10, 10, 25, 25, 25, 25, 25, 25, 25,\n",
       "                     25, 25, 25, 25, 25, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                     10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 25, 25,\n",
       "                     25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 5, 5, 5, 5, 5,\n",
       "                     5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                     10, 10, 10, 10, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "                     25, 25, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10,\n",
       "                     10, 10, 10, 10, 10, 10, 10, 10, 10, 25, 25, 25, 25, 25,\n",
       "                     25, 25, 25, 25, 25, 25, 25, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                     5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                     10, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 5,\n",
       "                     5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10,\n",
       "                     10, 10, 10, 10, 10, 10, 10, 25, 25, 25, 25, 25, 25, 25,\n",
       "                     25, 25, 25, 25, 25, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                     10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 25, 25,\n",
       "                     25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 5, 5, 5, 5, 5,\n",
       "                     5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                     10, 10, 10, 10, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "                     25, 25, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10,\n",
       "                     10, 10, 10, 10, 10, 10, 10, 10, 10, 25, 25, 25, 25, 25,\n",
       "                     25, 25, 25, 25, 25, 25, 25, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                     5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                     10, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 5,\n",
       "                     5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10,\n",
       "                     10, 10, 10, 10, 10, 10, 10, 25, 25, 25, 25, 25, 25, 25,\n",
       "                     25, 25, 25, 25, 25, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                     10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 25, 25,\n",
       "                     25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 5, 5, 5, 5, 5,\n",
       "                     5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                     10, 10, 10, 10, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "                     25, 25, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10,\n",
       "                     10, 10, 10, 10, 10, 10, 10, 10, 10, 25, 25, 25, 25, 25,\n",
       "                     25, 25, 25, 25, 25, 25, 25, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                     5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                     10, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__min_samples_split': masked_array(data=[2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 2, 2, 2, 2, 5,\n",
       "                     5, 5, 5, 10, 10, 10, 10, 2, 2, 2, 2, 5, 5, 5, 5, 10,\n",
       "                     10, 10, 10, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 2,\n",
       "                     2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 2, 2, 2, 2, 5, 5,\n",
       "                     5, 5, 10, 10, 10, 10, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10,\n",
       "                     10, 10, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 2, 2,\n",
       "                     2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 2, 2, 2, 2, 5, 5, 5,\n",
       "                     5, 10, 10, 10, 10, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10,\n",
       "                     10, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 2, 2, 2, 2,\n",
       "                     5, 5, 5, 5, 10, 10, 10, 10, 2, 2, 2, 2, 5, 5, 5, 5, 10,\n",
       "                     10, 10, 10, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 2,\n",
       "                     2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 2, 2, 2, 2, 5, 5,\n",
       "                     5, 5, 10, 10, 10, 10, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10,\n",
       "                     10, 10, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 2, 2,\n",
       "                     2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 2, 2, 2, 2, 5, 5, 5,\n",
       "                     5, 10, 10, 10, 10, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10,\n",
       "                     10, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 2, 2, 2, 2,\n",
       "                     5, 5, 5, 5, 10, 10, 10, 10, 2, 2, 2, 2, 5, 5, 5, 5, 10,\n",
       "                     10, 10, 10, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 2,\n",
       "                     2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 2, 2, 2, 2, 5, 5,\n",
       "                     5, 5, 10, 10, 10, 10, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10,\n",
       "                     10, 10, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 2, 2,\n",
       "                     2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 2, 2, 2, 2, 5, 5, 5,\n",
       "                     5, 10, 10, 10, 10, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10,\n",
       "                     10, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 2, 2, 2, 2,\n",
       "                     5, 5, 5, 5, 10, 10, 10, 10, 2, 2, 2, 2, 5, 5, 5, 5, 10,\n",
       "                     10, 10, 10, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 2,\n",
       "                     2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 2, 2, 2, 2, 5, 5,\n",
       "                     5, 5, 10, 10, 10, 10, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10,\n",
       "                     10, 10, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 2, 2,\n",
       "                     2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 2, 2, 2, 2, 5, 5, 5,\n",
       "                     5, 10, 10, 10, 10, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10,\n",
       "                     10, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 2, 2, 2, 2,\n",
       "                     5, 5, 5, 5, 10, 10, 10, 10, 2, 2, 2, 2, 5, 5, 5, 5, 10,\n",
       "                     10, 10, 10, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 2,\n",
       "                     2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 2, 2, 2, 2, 5, 5,\n",
       "                     5, 5, 10, 10, 10, 10, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10,\n",
       "                     10, 10, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 2, 2,\n",
       "                     2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 2, 2, 2, 2, 5, 5, 5,\n",
       "                     5, 10, 10, 10, 10, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10,\n",
       "                     10, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 2, 2, 2, 2,\n",
       "                     5, 5, 5, 5, 10, 10, 10, 10, 2, 2, 2, 2, 5, 5, 5, 5, 10,\n",
       "                     10, 10, 10, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 2,\n",
       "                     2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__n_estimators': masked_array(data=[50, 100, 200, 300, 50, 100, 200, 300, 50, 100, 200,\n",
       "                     300, 50, 100, 200, 300, 50, 100, 200, 300, 50, 100,\n",
       "                     200, 300, 50, 100, 200, 300, 50, 100, 200, 300, 50,\n",
       "                     100, 200, 300, 50, 100, 200, 300, 50, 100, 200, 300,\n",
       "                     50, 100, 200, 300, 50, 100, 200, 300, 50, 100, 200,\n",
       "                     300, 50, 100, 200, 300, 50, 100, 200, 300, 50, 100,\n",
       "                     200, 300, 50, 100, 200, 300, 50, 100, 200, 300, 50,\n",
       "                     100, 200, 300, 50, 100, 200, 300, 50, 100, 200, 300,\n",
       "                     50, 100, 200, 300, 50, 100, 200, 300, 50, 100, 200,\n",
       "                     300, 50, 100, 200, 300, 50, 100, 200, 300, 50, 100,\n",
       "                     200, 300, 50, 100, 200, 300, 50, 100, 200, 300, 50,\n",
       "                     100, 200, 300, 50, 100, 200, 300, 50, 100, 200, 300,\n",
       "                     50, 100, 200, 300, 50, 100, 200, 300, 50, 100, 200,\n",
       "                     300, 50, 100, 200, 300, 50, 100, 200, 300, 50, 100,\n",
       "                     200, 300, 50, 100, 200, 300, 50, 100, 200, 300, 50,\n",
       "                     100, 200, 300, 50, 100, 200, 300, 50, 100, 200, 300,\n",
       "                     50, 100, 200, 300, 50, 100, 200, 300, 50, 100, 200,\n",
       "                     300, 50, 100, 200, 300, 50, 100, 200, 300, 50, 100,\n",
       "                     200, 300, 50, 100, 200, 300, 50, 100, 200, 300, 50,\n",
       "                     100, 200, 300, 50, 100, 200, 300, 50, 100, 200, 300,\n",
       "                     50, 100, 200, 300, 50, 100, 200, 300, 50, 100, 200,\n",
       "                     300, 50, 100, 200, 300, 50, 100, 200, 300, 50, 100,\n",
       "                     200, 300, 50, 100, 200, 300, 50, 100, 200, 300, 50,\n",
       "                     100, 200, 300, 50, 100, 200, 300, 50, 100, 200, 300,\n",
       "                     50, 100, 200, 300, 50, 100, 200, 300, 50, 100, 200,\n",
       "                     300, 50, 100, 200, 300, 50, 100, 200, 300, 50, 100,\n",
       "                     200, 300, 50, 100, 200, 300, 50, 100, 200, 300, 50,\n",
       "                     100, 200, 300, 50, 100, 200, 300, 50, 100, 200, 300,\n",
       "                     50, 100, 200, 300, 50, 100, 200, 300, 50, 100, 200,\n",
       "                     300, 50, 100, 200, 300, 50, 100, 200, 300, 50, 100,\n",
       "                     200, 300, 50, 100, 200, 300, 50, 100, 200, 300, 50,\n",
       "                     100, 200, 300, 50, 100, 200, 300, 50, 100, 200, 300,\n",
       "                     50, 100, 200, 300, 50, 100, 200, 300, 50, 100, 200,\n",
       "                     300, 50, 100, 200, 300, 50, 100, 200, 300, 50, 100,\n",
       "                     200, 300, 50, 100, 200, 300, 50, 100, 200, 300, 50,\n",
       "                     100, 200, 300, 50, 100, 200, 300, 50, 100, 200, 300,\n",
       "                     50, 100, 200, 300, 50, 100, 200, 300, 50, 100, 200,\n",
       "                     300, 50, 100, 200, 300, 50, 100, 200, 300, 50, 100,\n",
       "                     200, 300, 50, 100, 200, 300, 50, 100, 200, 300, 50,\n",
       "                     100, 200, 300, 50, 100, 200, 300, 50, 100, 200, 300,\n",
       "                     50, 100, 200, 300, 50, 100, 200, 300, 50, 100, 200,\n",
       "                     300, 50, 100, 200, 300, 50, 100, 200, 300, 50, 100,\n",
       "                     200, 300, 50, 100, 200, 300, 50, 100, 200, 300, 50,\n",
       "                     100, 200, 300, 50, 100, 200, 300, 50, 100, 200, 300,\n",
       "                     50, 100, 200, 300, 50, 100, 200, 300, 50, 100, 200,\n",
       "                     300, 50, 100, 200, 300, 50, 100, 200, 300, 50, 100,\n",
       "                     200, 300, 50, 100, 200, 300, 50, 100, 200, 300, 50,\n",
       "                     100, 200, 300, 50, 100, 200, 300, 50, 100, 200, 300,\n",
       "                     50, 100, 200, 300, 50, 100, 200, 300, 50, 100, 200,\n",
       "                     300, 50, 100, 200, 300, 50, 100, 200, 300, 50, 100,\n",
       "                     200, 300, 50, 100, 200, 300, 50, 100, 200, 300, 50,\n",
       "                     100, 200, 300, 50, 100, 200, 300, 50, 100, 200, 300,\n",
       "                     50, 100, 200, 300, 50, 100, 200, 300, 50, 100, 200,\n",
       "                     300, 50, 100, 200, 300, 50, 100, 200, 300, 50, 100,\n",
       "                     200, 300, 50, 100, 200, 300, 50, 100, 200, 300, 50,\n",
       "                     100, 200, 300, 50, 100, 200, 300, 50, 100, 200, 300,\n",
       "                     50, 100, 200, 300, 50, 100, 200, 300, 50, 100, 200,\n",
       "                     300, 50, 100, 200, 300, 50, 100, 200, 300, 50, 100,\n",
       "                     200, 300, 50, 100, 200, 300, 50, 100, 200, 300, 50,\n",
       "                     100, 200, 300, 50, 100, 200, 300, 50, 100, 200, 300,\n",
       "                     50, 100, 200, 300, 50, 100, 200, 300, 50, 100, 200,\n",
       "                     300, 50, 100, 200, 300, 50, 100, 200, 300, 50, 100,\n",
       "                     200, 300, 50, 100, 200, 300, 50, 100, 200, 300, 50,\n",
       "                     100, 200, 300, 50, 100, 200, 300, 50, 100, 200, 300,\n",
       "                     50, 100, 200, 300, 50, 100, 200, 300, 50, 100, 200,\n",
       "                     300, 50, 100, 200, 300],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__bootstrap': False,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300}],\n",
       "  'split0_test_score': array([0.88888889, 0.88194444, 0.88541667, 0.89236111, 0.88541667,\n",
       "         0.88541667, 0.88541667, 0.89583333, 0.88888889, 0.88194444,\n",
       "         0.88541667, 0.89583333, 0.89930556, 0.89583333, 0.88194444,\n",
       "         0.88541667, 0.89236111, 0.89930556, 0.88888889, 0.88541667,\n",
       "         0.88888889, 0.88888889, 0.89236111, 0.88888889, 0.89583333,\n",
       "         0.88888889, 0.88888889, 0.88888889, 0.89583333, 0.88541667,\n",
       "         0.88888889, 0.89583333, 0.88888889, 0.89236111, 0.89236111,\n",
       "         0.89583333, 0.87847222, 0.86805556, 0.87847222, 0.87152778,\n",
       "         0.88194444, 0.86805556, 0.87847222, 0.88194444, 0.875     ,\n",
       "         0.87847222, 0.875     , 0.88194444, 0.88888889, 0.875     ,\n",
       "         0.88194444, 0.88541667, 0.86805556, 0.86805556, 0.87847222,\n",
       "         0.88194444, 0.88194444, 0.87847222, 0.88888889, 0.88541667,\n",
       "         0.88888889, 0.88541667, 0.88194444, 0.88194444, 0.88194444,\n",
       "         0.88541667, 0.88541667, 0.88541667, 0.89583333, 0.89930556,\n",
       "         0.88541667, 0.88541667, 0.87152778, 0.86805556, 0.87152778,\n",
       "         0.875     , 0.87152778, 0.85763889, 0.86458333, 0.86458333,\n",
       "         0.86805556, 0.86805556, 0.875     , 0.87152778, 0.86458333,\n",
       "         0.86805556, 0.87152778, 0.875     , 0.86111111, 0.86458333,\n",
       "         0.87152778, 0.875     , 0.86805556, 0.87847222, 0.87847222,\n",
       "         0.87847222, 0.87152778, 0.87152778, 0.87847222, 0.87847222,\n",
       "         0.875     , 0.88194444, 0.87847222, 0.875     , 0.88194444,\n",
       "         0.875     , 0.86805556, 0.87847222, 0.87152778, 0.86805556,\n",
       "         0.87152778, 0.875     , 0.87152778, 0.85763889, 0.86458333,\n",
       "         0.86458333, 0.86805556, 0.86805556, 0.875     , 0.87152778,\n",
       "         0.86458333, 0.86805556, 0.87152778, 0.875     , 0.86111111,\n",
       "         0.86458333, 0.87152778, 0.875     , 0.86805556, 0.87847222,\n",
       "         0.87847222, 0.87847222, 0.87152778, 0.87152778, 0.87847222,\n",
       "         0.87847222, 0.875     , 0.88194444, 0.87847222, 0.875     ,\n",
       "         0.88194444, 0.875     , 0.86805556, 0.87847222, 0.87152778,\n",
       "         0.86805556, 0.87152778, 0.875     , 0.87152778, 0.85763889,\n",
       "         0.86458333, 0.86458333, 0.86805556, 0.86805556, 0.875     ,\n",
       "         0.87152778, 0.86458333, 0.86805556, 0.87152778, 0.875     ,\n",
       "         0.86111111, 0.86458333, 0.87152778, 0.875     , 0.86805556,\n",
       "         0.87847222, 0.87847222, 0.87847222, 0.87152778, 0.87152778,\n",
       "         0.87847222, 0.87847222, 0.875     , 0.88194444, 0.87847222,\n",
       "         0.875     , 0.88194444, 0.875     , 0.86805556, 0.87847222,\n",
       "         0.88888889, 0.87847222, 0.88541667, 0.89236111, 0.88888889,\n",
       "         0.88194444, 0.88541667, 0.88888889, 0.87152778, 0.88194444,\n",
       "         0.88194444, 0.88541667, 0.89583333, 0.88888889, 0.90277778,\n",
       "         0.89583333, 0.88888889, 0.88888889, 0.89583333, 0.88888889,\n",
       "         0.89583333, 0.90277778, 0.89583333, 0.89236111, 0.89930556,\n",
       "         0.90277778, 0.89930556, 0.89583333, 0.89930556, 0.90625   ,\n",
       "         0.89583333, 0.89930556, 0.90277778, 0.90625   , 0.89930556,\n",
       "         0.89930556, 0.87152778, 0.88888889, 0.88541667, 0.88194444,\n",
       "         0.87152778, 0.87847222, 0.87847222, 0.88194444, 0.87152778,\n",
       "         0.875     , 0.87152778, 0.875     , 0.88888889, 0.89236111,\n",
       "         0.88888889, 0.88888889, 0.89930556, 0.88888889, 0.89236111,\n",
       "         0.88888889, 0.88541667, 0.88541667, 0.87847222, 0.87847222,\n",
       "         0.88541667, 0.89236111, 0.89236111, 0.88541667, 0.88541667,\n",
       "         0.87847222, 0.88194444, 0.87847222, 0.89583333, 0.88541667,\n",
       "         0.88541667, 0.88541667, 0.87152778, 0.86805556, 0.86458333,\n",
       "         0.86458333, 0.86458333, 0.86458333, 0.86805556, 0.86805556,\n",
       "         0.87152778, 0.87847222, 0.875     , 0.875     , 0.87847222,\n",
       "         0.88888889, 0.88194444, 0.88194444, 0.87847222, 0.87847222,\n",
       "         0.875     , 0.875     , 0.87847222, 0.88541667, 0.87847222,\n",
       "         0.875     , 0.88541667, 0.89236111, 0.89236111, 0.89236111,\n",
       "         0.88194444, 0.88194444, 0.88541667, 0.875     , 0.88194444,\n",
       "         0.87847222, 0.88541667, 0.88541667, 0.87152778, 0.86805556,\n",
       "         0.86458333, 0.86458333, 0.86458333, 0.86458333, 0.86805556,\n",
       "         0.86805556, 0.87152778, 0.87847222, 0.875     , 0.875     ,\n",
       "         0.87847222, 0.88888889, 0.88194444, 0.88194444, 0.87847222,\n",
       "         0.87847222, 0.875     , 0.875     , 0.87847222, 0.88541667,\n",
       "         0.87847222, 0.875     , 0.88541667, 0.89236111, 0.89236111,\n",
       "         0.89236111, 0.88194444, 0.88194444, 0.88541667, 0.875     ,\n",
       "         0.88194444, 0.87847222, 0.88541667, 0.88541667, 0.87152778,\n",
       "         0.86805556, 0.86458333, 0.86458333, 0.86458333, 0.86458333,\n",
       "         0.86805556, 0.86805556, 0.87152778, 0.87847222, 0.875     ,\n",
       "         0.875     , 0.87847222, 0.88888889, 0.88194444, 0.88194444,\n",
       "         0.87847222, 0.87847222, 0.875     , 0.875     , 0.87847222,\n",
       "         0.88541667, 0.87847222, 0.875     , 0.88541667, 0.89236111,\n",
       "         0.89236111, 0.89236111, 0.88194444, 0.88194444, 0.88541667,\n",
       "         0.875     , 0.88194444, 0.87847222, 0.88541667, 0.88541667,\n",
       "         0.88541667, 0.88541667, 0.88194444, 0.87847222, 0.88888889,\n",
       "         0.88888889, 0.88194444, 0.87847222, 0.87152778, 0.89236111,\n",
       "         0.88194444, 0.88541667, 0.89583333, 0.90625   , 0.89236111,\n",
       "         0.90277778, 0.89236111, 0.90277778, 0.89583333, 0.89583333,\n",
       "         0.88888889, 0.88541667, 0.89236111, 0.89236111, 0.90625   ,\n",
       "         0.90625   , 0.90625   , 0.89583333, 0.90625   , 0.90625   ,\n",
       "         0.90625   , 0.89930556, 0.90625   , 0.90625   , 0.90625   ,\n",
       "         0.89930556, 0.88541667, 0.87847222, 0.88194444, 0.88194444,\n",
       "         0.86805556, 0.86805556, 0.87152778, 0.86805556, 0.87152778,\n",
       "         0.87152778, 0.875     , 0.87847222, 0.875     , 0.875     ,\n",
       "         0.875     , 0.875     , 0.88194444, 0.87847222, 0.86805556,\n",
       "         0.875     , 0.87847222, 0.875     , 0.87847222, 0.875     ,\n",
       "         0.875     , 0.87847222, 0.87847222, 0.875     , 0.875     ,\n",
       "         0.88194444, 0.87152778, 0.87152778, 0.88194444, 0.86458333,\n",
       "         0.86805556, 0.87847222, 0.85763889, 0.86805556, 0.86805556,\n",
       "         0.86458333, 0.86458333, 0.86805556, 0.86458333, 0.86111111,\n",
       "         0.86111111, 0.86111111, 0.86458333, 0.86458333, 0.87152778,\n",
       "         0.875     , 0.86805556, 0.86805556, 0.86458333, 0.86805556,\n",
       "         0.86458333, 0.86458333, 0.86805556, 0.86805556, 0.86805556,\n",
       "         0.86805556, 0.87847222, 0.875     , 0.87152778, 0.87152778,\n",
       "         0.87152778, 0.875     , 0.87152778, 0.86458333, 0.87847222,\n",
       "         0.86805556, 0.86458333, 0.86111111, 0.85763889, 0.86805556,\n",
       "         0.86805556, 0.86458333, 0.86458333, 0.86805556, 0.86458333,\n",
       "         0.86111111, 0.86111111, 0.86111111, 0.86458333, 0.86458333,\n",
       "         0.87152778, 0.875     , 0.86805556, 0.86805556, 0.86458333,\n",
       "         0.86805556, 0.86458333, 0.86458333, 0.86805556, 0.86805556,\n",
       "         0.86805556, 0.86805556, 0.87847222, 0.875     , 0.87152778,\n",
       "         0.87152778, 0.87152778, 0.875     , 0.87152778, 0.86458333,\n",
       "         0.87847222, 0.86805556, 0.86458333, 0.86111111, 0.85763889,\n",
       "         0.86805556, 0.86805556, 0.86458333, 0.86458333, 0.86805556,\n",
       "         0.86458333, 0.86111111, 0.86111111, 0.86111111, 0.86458333,\n",
       "         0.86458333, 0.87152778, 0.875     , 0.86805556, 0.86805556,\n",
       "         0.86458333, 0.86805556, 0.86458333, 0.86458333, 0.86805556,\n",
       "         0.86805556, 0.86805556, 0.86805556, 0.87847222, 0.875     ,\n",
       "         0.87152778, 0.87152778, 0.87152778, 0.875     , 0.87152778,\n",
       "         0.86458333, 0.87847222, 0.86805556, 0.86458333, 0.86111111,\n",
       "         0.89236111, 0.89583333, 0.88194444, 0.88888889, 0.89236111,\n",
       "         0.89583333, 0.88194444, 0.88888889, 0.88541667, 0.89236111,\n",
       "         0.88194444, 0.88888889, 0.88888889, 0.89583333, 0.88888889,\n",
       "         0.89236111, 0.89236111, 0.89583333, 0.88888889, 0.88888889,\n",
       "         0.89583333, 0.90277778, 0.88888889, 0.89236111, 0.90625   ,\n",
       "         0.91319444, 0.90625   , 0.89583333, 0.90972222, 0.90972222,\n",
       "         0.90277778, 0.89930556, 0.90625   , 0.89583333, 0.89930556,\n",
       "         0.90277778, 0.875     , 0.86805556, 0.87847222, 0.88194444,\n",
       "         0.87847222, 0.86805556, 0.87152778, 0.875     , 0.87847222,\n",
       "         0.87847222, 0.88194444, 0.875     , 0.875     , 0.87847222,\n",
       "         0.875     , 0.875     , 0.88888889, 0.88194444, 0.875     ,\n",
       "         0.87847222, 0.89583333, 0.87847222, 0.88541667, 0.87847222,\n",
       "         0.875     , 0.88194444, 0.87847222, 0.87847222, 0.87847222,\n",
       "         0.88194444, 0.87847222, 0.875     , 0.88194444, 0.88541667,\n",
       "         0.88194444, 0.87847222, 0.86805556, 0.86805556, 0.86805556,\n",
       "         0.86805556, 0.86805556, 0.86458333, 0.86458333, 0.86805556,\n",
       "         0.86458333, 0.86805556, 0.86458333, 0.86458333, 0.87152778,\n",
       "         0.87152778, 0.875     , 0.875     , 0.87847222, 0.87152778,\n",
       "         0.875     , 0.86805556, 0.86805556, 0.87152778, 0.875     ,\n",
       "         0.875     , 0.875     , 0.87152778, 0.87847222, 0.875     ,\n",
       "         0.875     , 0.87847222, 0.875     , 0.875     , 0.87847222,\n",
       "         0.87847222, 0.87847222, 0.87847222, 0.86805556, 0.86805556,\n",
       "         0.86805556, 0.86805556, 0.86805556, 0.86458333, 0.86458333,\n",
       "         0.86805556, 0.86458333, 0.86805556, 0.86458333, 0.86458333,\n",
       "         0.87152778, 0.87152778, 0.875     , 0.875     , 0.87847222,\n",
       "         0.87152778, 0.875     , 0.86805556, 0.86805556, 0.87152778,\n",
       "         0.875     , 0.875     , 0.875     , 0.87152778, 0.87847222,\n",
       "         0.875     , 0.875     , 0.87847222, 0.875     , 0.875     ,\n",
       "         0.87847222, 0.87847222, 0.87847222, 0.87847222, 0.86805556,\n",
       "         0.86805556, 0.86805556, 0.86805556, 0.86805556, 0.86458333,\n",
       "         0.86458333, 0.86805556, 0.86458333, 0.86805556, 0.86458333,\n",
       "         0.86458333, 0.87152778, 0.87152778, 0.875     , 0.875     ,\n",
       "         0.87847222, 0.87152778, 0.875     , 0.86805556, 0.86805556,\n",
       "         0.87152778, 0.875     , 0.875     , 0.875     , 0.87152778,\n",
       "         0.87847222, 0.875     , 0.875     , 0.87847222, 0.875     ,\n",
       "         0.875     , 0.87847222, 0.87847222, 0.87847222, 0.87847222]),\n",
       "  'split1_test_score': array([0.91986063, 0.91289199, 0.92334495, 0.92682927, 0.91637631,\n",
       "         0.92334495, 0.92682927, 0.91986063, 0.91986063, 0.91986063,\n",
       "         0.92682927, 0.93031359, 0.91637631, 0.91637631, 0.91986063,\n",
       "         0.92682927, 0.91637631, 0.91637631, 0.93031359, 0.92334495,\n",
       "         0.91637631, 0.92334495, 0.92334495, 0.92682927, 0.91986063,\n",
       "         0.92682927, 0.92682927, 0.94076655, 0.91986063, 0.92334495,\n",
       "         0.92334495, 0.93031359, 0.92682927, 0.92682927, 0.92682927,\n",
       "         0.93379791, 0.91986063, 0.92334495, 0.92334495, 0.91986063,\n",
       "         0.92334495, 0.93379791, 0.93031359, 0.92682927, 0.92334495,\n",
       "         0.91637631, 0.91986063, 0.92334495, 0.92334495, 0.93031359,\n",
       "         0.93379791, 0.93379791, 0.92682927, 0.93031359, 0.92334495,\n",
       "         0.92334495, 0.91986063, 0.92334495, 0.91637631, 0.91986063,\n",
       "         0.92682927, 0.93031359, 0.92682927, 0.93031359, 0.93728223,\n",
       "         0.93031359, 0.93379791, 0.92682927, 0.93728223, 0.93031359,\n",
       "         0.94076655, 0.94076655, 0.90592334, 0.90940767, 0.91289199,\n",
       "         0.90940767, 0.91289199, 0.91986063, 0.91986063, 0.91986063,\n",
       "         0.89547038, 0.90592334, 0.91289199, 0.91637631, 0.90940767,\n",
       "         0.90940767, 0.90592334, 0.91637631, 0.91637631, 0.91986063,\n",
       "         0.91986063, 0.91637631, 0.91986063, 0.91986063, 0.91289199,\n",
       "         0.91289199, 0.91637631, 0.91289199, 0.91637631, 0.91637631,\n",
       "         0.91637631, 0.91637631, 0.91637631, 0.91986063, 0.92682927,\n",
       "         0.91289199, 0.93031359, 0.92334495, 0.90592334, 0.90940767,\n",
       "         0.91289199, 0.90940767, 0.91289199, 0.91986063, 0.91986063,\n",
       "         0.91986063, 0.89547038, 0.90592334, 0.91289199, 0.91637631,\n",
       "         0.90940767, 0.90940767, 0.90592334, 0.91637631, 0.91637631,\n",
       "         0.91986063, 0.91986063, 0.91637631, 0.91986063, 0.91986063,\n",
       "         0.91289199, 0.91289199, 0.91637631, 0.91289199, 0.91637631,\n",
       "         0.91637631, 0.91637631, 0.91637631, 0.91637631, 0.91986063,\n",
       "         0.92682927, 0.91289199, 0.93031359, 0.92334495, 0.90592334,\n",
       "         0.90940767, 0.91289199, 0.90940767, 0.91289199, 0.91986063,\n",
       "         0.91986063, 0.91986063, 0.89547038, 0.90592334, 0.91289199,\n",
       "         0.91637631, 0.90940767, 0.90940767, 0.90592334, 0.91637631,\n",
       "         0.91637631, 0.91986063, 0.91986063, 0.91637631, 0.91986063,\n",
       "         0.91986063, 0.91289199, 0.91289199, 0.91637631, 0.91289199,\n",
       "         0.91637631, 0.91637631, 0.91637631, 0.91637631, 0.91637631,\n",
       "         0.91986063, 0.92682927, 0.91289199, 0.93031359, 0.92334495,\n",
       "         0.90592334, 0.91637631, 0.90940767, 0.91289199, 0.91986063,\n",
       "         0.91289199, 0.90940767, 0.91637631, 0.91637631, 0.91986063,\n",
       "         0.91637631, 0.91986063, 0.91986063, 0.91637631, 0.92334495,\n",
       "         0.91637631, 0.91637631, 0.91986063, 0.92682927, 0.91637631,\n",
       "         0.91637631, 0.91637631, 0.93031359, 0.91637631, 0.90940767,\n",
       "         0.91289199, 0.91289199, 0.90940767, 0.90940767, 0.90940767,\n",
       "         0.91289199, 0.90592334, 0.91637631, 0.92334495, 0.91986063,\n",
       "         0.92682927, 0.91986063, 0.92334495, 0.91986063, 0.91986063,\n",
       "         0.91986063, 0.92682927, 0.91637631, 0.91637631, 0.93031359,\n",
       "         0.93379791, 0.92682927, 0.93031359, 0.92334495, 0.93728223,\n",
       "         0.93031359, 0.93031359, 0.92682927, 0.93728223, 0.94076655,\n",
       "         0.94076655, 0.93728223, 0.93379791, 0.93379791, 0.93379791,\n",
       "         0.94425087, 0.93031359, 0.93379791, 0.93031359, 0.92334495,\n",
       "         0.92334495, 0.93031359, 0.93031359, 0.93379791, 0.93728223,\n",
       "         0.93379791, 0.93728223, 0.91986063, 0.91986063, 0.90243902,\n",
       "         0.90243902, 0.90592334, 0.91289199, 0.91289199, 0.90940767,\n",
       "         0.91637631, 0.91986063, 0.92334495, 0.91637631, 0.91637631,\n",
       "         0.93031359, 0.91637631, 0.92682927, 0.92682927, 0.92682927,\n",
       "         0.92682927, 0.92334495, 0.93031359, 0.92334495, 0.91986063,\n",
       "         0.92334495, 0.93379791, 0.93031359, 0.92682927, 0.93379791,\n",
       "         0.92334495, 0.92682927, 0.93379791, 0.92682927, 0.93379791,\n",
       "         0.93728223, 0.93031359, 0.93379791, 0.91986063, 0.91986063,\n",
       "         0.90243902, 0.90243902, 0.90592334, 0.91289199, 0.91289199,\n",
       "         0.90940767, 0.91637631, 0.91986063, 0.92334495, 0.91637631,\n",
       "         0.91637631, 0.93031359, 0.91637631, 0.92682927, 0.92682927,\n",
       "         0.92682927, 0.92682927, 0.92334495, 0.93031359, 0.92334495,\n",
       "         0.91986063, 0.92334495, 0.93379791, 0.93031359, 0.92682927,\n",
       "         0.93379791, 0.92334495, 0.92682927, 0.93379791, 0.92682927,\n",
       "         0.93379791, 0.93728223, 0.93031359, 0.93379791, 0.91986063,\n",
       "         0.91986063, 0.90243902, 0.90243902, 0.90592334, 0.91289199,\n",
       "         0.91289199, 0.90940767, 0.91637631, 0.91986063, 0.92334495,\n",
       "         0.91637631, 0.91637631, 0.93031359, 0.91637631, 0.92682927,\n",
       "         0.92682927, 0.92682927, 0.92682927, 0.92334495, 0.93031359,\n",
       "         0.92334495, 0.91986063, 0.92334495, 0.93379791, 0.93031359,\n",
       "         0.92682927, 0.93379791, 0.92334495, 0.92682927, 0.93379791,\n",
       "         0.92682927, 0.93379791, 0.93728223, 0.93031359, 0.93379791,\n",
       "         0.92334495, 0.91637631, 0.91637631, 0.91986063, 0.91986063,\n",
       "         0.91637631, 0.91289199, 0.91637631, 0.92682927, 0.91289199,\n",
       "         0.91986063, 0.91986063, 0.92682927, 0.92682927, 0.92682927,\n",
       "         0.92334495, 0.92682927, 0.92682927, 0.92334495, 0.92334495,\n",
       "         0.92682927, 0.93031359, 0.92334495, 0.92334495, 0.92682927,\n",
       "         0.92682927, 0.93031359, 0.93728223, 0.93379791, 0.92682927,\n",
       "         0.93379791, 0.93728223, 0.93379791, 0.92682927, 0.93379791,\n",
       "         0.94076655, 0.92334495, 0.91289199, 0.91637631, 0.91986063,\n",
       "         0.92334495, 0.91986063, 0.91986063, 0.92334495, 0.93031359,\n",
       "         0.92334495, 0.91986063, 0.92334495, 0.91986063, 0.91289199,\n",
       "         0.92682927, 0.92682927, 0.91637631, 0.91986063, 0.92334495,\n",
       "         0.92682927, 0.93031359, 0.91637631, 0.91986063, 0.92682927,\n",
       "         0.92682927, 0.92334495, 0.92682927, 0.93031359, 0.92334495,\n",
       "         0.92682927, 0.93031359, 0.92682927, 0.93379791, 0.91986063,\n",
       "         0.92682927, 0.93031359, 0.89198606, 0.89198606, 0.89547038,\n",
       "         0.89198606, 0.89198606, 0.89198606, 0.89547038, 0.89198606,\n",
       "         0.89547038, 0.89547038, 0.90243902, 0.8989547 , 0.90243902,\n",
       "         0.90243902, 0.90592334, 0.90243902, 0.90940767, 0.90592334,\n",
       "         0.90592334, 0.90243902, 0.92334495, 0.91986063, 0.91637631,\n",
       "         0.91289199, 0.90592334, 0.91289199, 0.90592334, 0.91289199,\n",
       "         0.91986063, 0.91986063, 0.91637631, 0.91637631, 0.90940767,\n",
       "         0.91289199, 0.91637631, 0.91289199, 0.89198606, 0.89198606,\n",
       "         0.89547038, 0.89198606, 0.89198606, 0.89198606, 0.89547038,\n",
       "         0.89198606, 0.89547038, 0.89547038, 0.90243902, 0.8989547 ,\n",
       "         0.90243902, 0.90243902, 0.90592334, 0.90243902, 0.90940767,\n",
       "         0.90592334, 0.90592334, 0.90243902, 0.92334495, 0.91986063,\n",
       "         0.91637631, 0.91289199, 0.90592334, 0.91289199, 0.90592334,\n",
       "         0.91289199, 0.91986063, 0.91986063, 0.91637631, 0.91637631,\n",
       "         0.90940767, 0.91289199, 0.91637631, 0.91289199, 0.89198606,\n",
       "         0.89198606, 0.89547038, 0.89198606, 0.89198606, 0.89198606,\n",
       "         0.89547038, 0.89198606, 0.89547038, 0.89547038, 0.90243902,\n",
       "         0.8989547 , 0.90243902, 0.90243902, 0.90592334, 0.90243902,\n",
       "         0.90940767, 0.90592334, 0.90592334, 0.90243902, 0.92334495,\n",
       "         0.91986063, 0.91637631, 0.91289199, 0.90592334, 0.91289199,\n",
       "         0.90592334, 0.91289199, 0.91986063, 0.91986063, 0.91637631,\n",
       "         0.91637631, 0.90940767, 0.91289199, 0.91637631, 0.91289199,\n",
       "         0.91637631, 0.91986063, 0.91289199, 0.90592334, 0.91637631,\n",
       "         0.91637631, 0.91289199, 0.91289199, 0.90940767, 0.91986063,\n",
       "         0.90940767, 0.90592334, 0.92682927, 0.91986063, 0.92334495,\n",
       "         0.91986063, 0.92682927, 0.91637631, 0.92334495, 0.91986063,\n",
       "         0.93379791, 0.91986063, 0.93031359, 0.93031359, 0.93031359,\n",
       "         0.93379791, 0.93728223, 0.93728223, 0.93031359, 0.93379791,\n",
       "         0.93728223, 0.93031359, 0.93031359, 0.93379791, 0.93379791,\n",
       "         0.93379791, 0.91637631, 0.91637631, 0.91986063, 0.91986063,\n",
       "         0.91289199, 0.91289199, 0.91637631, 0.91986063, 0.92334495,\n",
       "         0.91986063, 0.91986063, 0.92334495, 0.91637631, 0.92682927,\n",
       "         0.92682927, 0.92682927, 0.93379791, 0.91986063, 0.92682927,\n",
       "         0.92682927, 0.93031359, 0.93031359, 0.91637631, 0.91637631,\n",
       "         0.93379791, 0.94076655, 0.93031359, 0.93031359, 0.93728223,\n",
       "         0.93379791, 0.92682927, 0.92682927, 0.93031359, 0.92334495,\n",
       "         0.92334495, 0.92334495, 0.88501742, 0.89198606, 0.89198606,\n",
       "         0.88850174, 0.88501742, 0.89547038, 0.89547038, 0.89547038,\n",
       "         0.89198606, 0.89547038, 0.89547038, 0.8989547 , 0.90940767,\n",
       "         0.91289199, 0.90592334, 0.90592334, 0.90592334, 0.90940767,\n",
       "         0.90940767, 0.90940767, 0.91289199, 0.91637631, 0.90940767,\n",
       "         0.90940767, 0.92334495, 0.91986063, 0.91986063, 0.91986063,\n",
       "         0.91289199, 0.91637631, 0.91637631, 0.91986063, 0.91637631,\n",
       "         0.91289199, 0.91637631, 0.91289199, 0.88501742, 0.89198606,\n",
       "         0.89198606, 0.88850174, 0.88501742, 0.89547038, 0.89547038,\n",
       "         0.89547038, 0.89198606, 0.89547038, 0.89547038, 0.8989547 ,\n",
       "         0.90940767, 0.91289199, 0.90592334, 0.90592334, 0.90592334,\n",
       "         0.90940767, 0.90940767, 0.90940767, 0.91289199, 0.91637631,\n",
       "         0.90940767, 0.90940767, 0.92334495, 0.91986063, 0.91986063,\n",
       "         0.91986063, 0.91289199, 0.91637631, 0.91637631, 0.91986063,\n",
       "         0.91637631, 0.91289199, 0.91637631, 0.91289199, 0.88501742,\n",
       "         0.89198606, 0.89198606, 0.88850174, 0.88501742, 0.89547038,\n",
       "         0.89547038, 0.89547038, 0.89198606, 0.89547038, 0.89547038,\n",
       "         0.8989547 , 0.90940767, 0.91289199, 0.90592334, 0.90592334,\n",
       "         0.90592334, 0.90940767, 0.90940767, 0.90940767, 0.91289199,\n",
       "         0.91637631, 0.90940767, 0.90940767, 0.92334495, 0.91986063,\n",
       "         0.91986063, 0.91986063, 0.91289199, 0.91637631, 0.91637631,\n",
       "         0.91986063, 0.91637631, 0.91289199, 0.91637631, 0.91289199]),\n",
       "  'split2_test_score': array([0.91986063, 0.93031359, 0.92682927, 0.93031359, 0.91637631,\n",
       "         0.91637631, 0.91986063, 0.92334495, 0.91637631, 0.91986063,\n",
       "         0.91986063, 0.92682927, 0.93031359, 0.93031359, 0.92682927,\n",
       "         0.91637631, 0.93379791, 0.93031359, 0.92682927, 0.91986063,\n",
       "         0.92334495, 0.92334495, 0.91986063, 0.91637631, 0.91986063,\n",
       "         0.91986063, 0.92334495, 0.93379791, 0.91637631, 0.93031359,\n",
       "         0.92682927, 0.93379791, 0.92334495, 0.93379791, 0.93031359,\n",
       "         0.93728223, 0.90243902, 0.90940767, 0.89547038, 0.90592334,\n",
       "         0.8989547 , 0.90592334, 0.90243902, 0.90243902, 0.90592334,\n",
       "         0.89547038, 0.90243902, 0.90243902, 0.90592334, 0.90243902,\n",
       "         0.90243902, 0.90592334, 0.91289199, 0.90243902, 0.8989547 ,\n",
       "         0.90592334, 0.90940767, 0.90940767, 0.8989547 , 0.90243902,\n",
       "         0.90243902, 0.90940767, 0.90592334, 0.90592334, 0.91289199,\n",
       "         0.8989547 , 0.8989547 , 0.90243902, 0.90592334, 0.8989547 ,\n",
       "         0.90592334, 0.91289199, 0.88501742, 0.89198606, 0.89547038,\n",
       "         0.89198606, 0.90243902, 0.90243902, 0.89547038, 0.8989547 ,\n",
       "         0.8989547 , 0.90243902, 0.90243902, 0.8989547 , 0.90592334,\n",
       "         0.8989547 , 0.89547038, 0.8989547 , 0.91637631, 0.90243902,\n",
       "         0.90243902, 0.90592334, 0.90592334, 0.90243902, 0.90243902,\n",
       "         0.90592334, 0.91289199, 0.91289199, 0.90592334, 0.90243902,\n",
       "         0.90243902, 0.90243902, 0.90243902, 0.90592334, 0.8989547 ,\n",
       "         0.90592334, 0.90940767, 0.90592334, 0.88501742, 0.89198606,\n",
       "         0.89547038, 0.89198606, 0.90243902, 0.90243902, 0.89547038,\n",
       "         0.8989547 , 0.8989547 , 0.90243902, 0.90243902, 0.8989547 ,\n",
       "         0.90592334, 0.8989547 , 0.89547038, 0.8989547 , 0.91637631,\n",
       "         0.90243902, 0.90243902, 0.90592334, 0.90592334, 0.90243902,\n",
       "         0.90243902, 0.90592334, 0.91289199, 0.91289199, 0.90592334,\n",
       "         0.90243902, 0.90243902, 0.90243902, 0.90243902, 0.90592334,\n",
       "         0.8989547 , 0.90592334, 0.90940767, 0.90592334, 0.88501742,\n",
       "         0.89198606, 0.89547038, 0.89198606, 0.90243902, 0.90243902,\n",
       "         0.89547038, 0.8989547 , 0.8989547 , 0.90243902, 0.90243902,\n",
       "         0.8989547 , 0.90592334, 0.8989547 , 0.89547038, 0.8989547 ,\n",
       "         0.91637631, 0.90243902, 0.90243902, 0.90592334, 0.90592334,\n",
       "         0.90243902, 0.90243902, 0.90592334, 0.91289199, 0.91289199,\n",
       "         0.90592334, 0.90243902, 0.90243902, 0.90243902, 0.90243902,\n",
       "         0.90592334, 0.8989547 , 0.90592334, 0.90940767, 0.90592334,\n",
       "         0.91289199, 0.92334495, 0.92334495, 0.91637631, 0.90940767,\n",
       "         0.91637631, 0.91289199, 0.91289199, 0.91289199, 0.91637631,\n",
       "         0.91986063, 0.91986063, 0.91289199, 0.91289199, 0.93031359,\n",
       "         0.93031359, 0.91637631, 0.91289199, 0.93031359, 0.93031359,\n",
       "         0.91986063, 0.91637631, 0.93379791, 0.93728223, 0.90940767,\n",
       "         0.91986063, 0.92682927, 0.92682927, 0.90243902, 0.91986063,\n",
       "         0.93379791, 0.93031359, 0.90940767, 0.91637631, 0.93031359,\n",
       "         0.92682927, 0.8989547 , 0.90592334, 0.90243902, 0.90592334,\n",
       "         0.90592334, 0.91289199, 0.8989547 , 0.90592334, 0.8989547 ,\n",
       "         0.90243902, 0.8989547 , 0.90243902, 0.90592334, 0.8989547 ,\n",
       "         0.90592334, 0.90243902, 0.8989547 , 0.90592334, 0.91289199,\n",
       "         0.91289199, 0.8989547 , 0.90940767, 0.90592334, 0.90592334,\n",
       "         0.91289199, 0.90940767, 0.8989547 , 0.8989547 , 0.90592334,\n",
       "         0.91289199, 0.90243902, 0.90243902, 0.8989547 , 0.91289199,\n",
       "         0.90243902, 0.90243902, 0.8989547 , 0.89547038, 0.89547038,\n",
       "         0.89547038, 0.90592334, 0.91289199, 0.90592334, 0.90592334,\n",
       "         0.8989547 , 0.90592334, 0.90592334, 0.8989547 , 0.89547038,\n",
       "         0.88850174, 0.89547038, 0.90243902, 0.90243902, 0.89547038,\n",
       "         0.8989547 , 0.8989547 , 0.90592334, 0.90243902, 0.90592334,\n",
       "         0.90592334, 0.90592334, 0.90940767, 0.90243902, 0.90243902,\n",
       "         0.91637631, 0.91637631, 0.90592334, 0.90243902, 0.90940767,\n",
       "         0.90592334, 0.90592334, 0.90243902, 0.8989547 , 0.89547038,\n",
       "         0.89547038, 0.89547038, 0.90592334, 0.91289199, 0.90592334,\n",
       "         0.90592334, 0.8989547 , 0.90592334, 0.90592334, 0.8989547 ,\n",
       "         0.89547038, 0.88850174, 0.89547038, 0.90243902, 0.90243902,\n",
       "         0.89547038, 0.8989547 , 0.8989547 , 0.90592334, 0.90243902,\n",
       "         0.90592334, 0.90592334, 0.90592334, 0.90940767, 0.90243902,\n",
       "         0.90243902, 0.91637631, 0.91637631, 0.90592334, 0.90243902,\n",
       "         0.90940767, 0.90592334, 0.90592334, 0.90243902, 0.8989547 ,\n",
       "         0.89547038, 0.89547038, 0.89547038, 0.90592334, 0.91289199,\n",
       "         0.90592334, 0.90592334, 0.8989547 , 0.90592334, 0.90592334,\n",
       "         0.8989547 , 0.89547038, 0.88850174, 0.89547038, 0.90243902,\n",
       "         0.90243902, 0.89547038, 0.8989547 , 0.8989547 , 0.90592334,\n",
       "         0.90243902, 0.90592334, 0.90592334, 0.90592334, 0.90940767,\n",
       "         0.90243902, 0.90243902, 0.91637631, 0.91637631, 0.90592334,\n",
       "         0.90243902, 0.90940767, 0.90592334, 0.90592334, 0.90243902,\n",
       "         0.91637631, 0.91289199, 0.91637631, 0.90940767, 0.91289199,\n",
       "         0.91289199, 0.91986063, 0.91986063, 0.91289199, 0.91637631,\n",
       "         0.91637631, 0.91637631, 0.92334495, 0.92682927, 0.93379791,\n",
       "         0.92334495, 0.91986063, 0.91637631, 0.92682927, 0.91986063,\n",
       "         0.91637631, 0.91986063, 0.91986063, 0.91986063, 0.90940767,\n",
       "         0.91289199, 0.92334495, 0.93379791, 0.91289199, 0.90940767,\n",
       "         0.91986063, 0.92682927, 0.90592334, 0.90940767, 0.92682927,\n",
       "         0.92682927, 0.90243902, 0.90243902, 0.8989547 , 0.90592334,\n",
       "         0.90940767, 0.90243902, 0.90243902, 0.8989547 , 0.8989547 ,\n",
       "         0.8989547 , 0.90243902, 0.90243902, 0.89547038, 0.88850174,\n",
       "         0.8989547 , 0.89547038, 0.8989547 , 0.90243902, 0.8989547 ,\n",
       "         0.89547038, 0.89198606, 0.89198606, 0.89198606, 0.89547038,\n",
       "         0.90243902, 0.8989547 , 0.8989547 , 0.8989547 , 0.89547038,\n",
       "         0.90243902, 0.90243902, 0.90243902, 0.8989547 , 0.8989547 ,\n",
       "         0.8989547 , 0.8989547 , 0.88501742, 0.88850174, 0.88501742,\n",
       "         0.87804878, 0.87108014, 0.88501742, 0.8815331 , 0.88501742,\n",
       "         0.88501742, 0.88501742, 0.88501742, 0.88501742, 0.8815331 ,\n",
       "         0.88850174, 0.8989547 , 0.89547038, 0.88501742, 0.87456446,\n",
       "         0.88501742, 0.88850174, 0.88850174, 0.89547038, 0.89198606,\n",
       "         0.89547038, 0.8989547 , 0.89198606, 0.8989547 , 0.8989547 ,\n",
       "         0.89198606, 0.90592334, 0.90243902, 0.8989547 , 0.89547038,\n",
       "         0.89547038, 0.8989547 , 0.90243902, 0.88501742, 0.88850174,\n",
       "         0.88501742, 0.87804878, 0.87108014, 0.88501742, 0.8815331 ,\n",
       "         0.88501742, 0.88501742, 0.88501742, 0.88501742, 0.88501742,\n",
       "         0.8815331 , 0.88850174, 0.8989547 , 0.89547038, 0.88501742,\n",
       "         0.87456446, 0.88501742, 0.88850174, 0.88850174, 0.89547038,\n",
       "         0.89198606, 0.89547038, 0.8989547 , 0.89198606, 0.8989547 ,\n",
       "         0.8989547 , 0.89198606, 0.90592334, 0.90243902, 0.8989547 ,\n",
       "         0.89547038, 0.89547038, 0.8989547 , 0.90243902, 0.88501742,\n",
       "         0.88850174, 0.88501742, 0.87804878, 0.87108014, 0.88501742,\n",
       "         0.8815331 , 0.88501742, 0.88501742, 0.88501742, 0.88501742,\n",
       "         0.88501742, 0.8815331 , 0.88850174, 0.8989547 , 0.89547038,\n",
       "         0.88501742, 0.87456446, 0.88501742, 0.88850174, 0.88850174,\n",
       "         0.89547038, 0.89198606, 0.89547038, 0.8989547 , 0.89198606,\n",
       "         0.8989547 , 0.8989547 , 0.89198606, 0.90592334, 0.90243902,\n",
       "         0.8989547 , 0.89547038, 0.89547038, 0.8989547 , 0.90243902,\n",
       "         0.91637631, 0.91289199, 0.91637631, 0.91986063, 0.91986063,\n",
       "         0.90940767, 0.91637631, 0.91637631, 0.90940767, 0.91637631,\n",
       "         0.91289199, 0.92334495, 0.91289199, 0.91986063, 0.91986063,\n",
       "         0.92334495, 0.92334495, 0.92334495, 0.91637631, 0.91986063,\n",
       "         0.92682927, 0.92334495, 0.91986063, 0.92682927, 0.89547038,\n",
       "         0.8989547 , 0.91986063, 0.91986063, 0.90243902, 0.91289199,\n",
       "         0.91986063, 0.92334495, 0.90940767, 0.90592334, 0.91986063,\n",
       "         0.92334495, 0.8989547 , 0.90243902, 0.90243902, 0.90243902,\n",
       "         0.90243902, 0.90243902, 0.90243902, 0.90243902, 0.90592334,\n",
       "         0.90592334, 0.90243902, 0.90243902, 0.8989547 , 0.89547038,\n",
       "         0.90243902, 0.90592334, 0.89547038, 0.89547038, 0.90243902,\n",
       "         0.90243902, 0.90243902, 0.90592334, 0.90243902, 0.8989547 ,\n",
       "         0.8989547 , 0.90592334, 0.90592334, 0.90592334, 0.90592334,\n",
       "         0.90592334, 0.90940767, 0.90940767, 0.8989547 , 0.90243902,\n",
       "         0.90940767, 0.90243902, 0.88850174, 0.88850174, 0.88501742,\n",
       "         0.88501742, 0.88501742, 0.88501742, 0.88501742, 0.89198606,\n",
       "         0.88501742, 0.88850174, 0.89547038, 0.8989547 , 0.89198606,\n",
       "         0.8989547 , 0.90243902, 0.89547038, 0.8815331 , 0.88501742,\n",
       "         0.89198606, 0.88501742, 0.89547038, 0.89198606, 0.89547038,\n",
       "         0.89198606, 0.89198606, 0.89547038, 0.8989547 , 0.89547038,\n",
       "         0.88501742, 0.88850174, 0.89547038, 0.8989547 , 0.89198606,\n",
       "         0.90940767, 0.90592334, 0.90243902, 0.88850174, 0.88850174,\n",
       "         0.88501742, 0.88501742, 0.88501742, 0.88501742, 0.88501742,\n",
       "         0.89198606, 0.88501742, 0.88850174, 0.89547038, 0.8989547 ,\n",
       "         0.89198606, 0.8989547 , 0.90243902, 0.89547038, 0.8815331 ,\n",
       "         0.88501742, 0.89198606, 0.88501742, 0.89547038, 0.89198606,\n",
       "         0.89547038, 0.89198606, 0.89198606, 0.89547038, 0.8989547 ,\n",
       "         0.89547038, 0.88501742, 0.88850174, 0.89547038, 0.8989547 ,\n",
       "         0.89198606, 0.90940767, 0.90592334, 0.90243902, 0.88850174,\n",
       "         0.88850174, 0.88501742, 0.88501742, 0.88501742, 0.88501742,\n",
       "         0.88501742, 0.89198606, 0.88501742, 0.88850174, 0.89547038,\n",
       "         0.8989547 , 0.89198606, 0.8989547 , 0.90243902, 0.89547038,\n",
       "         0.8815331 , 0.88501742, 0.89198606, 0.88501742, 0.89547038,\n",
       "         0.89198606, 0.89547038, 0.89198606, 0.89198606, 0.89547038,\n",
       "         0.8989547 , 0.89547038, 0.88501742, 0.88850174, 0.89547038,\n",
       "         0.8989547 , 0.89198606, 0.90940767, 0.90592334, 0.90243902]),\n",
       "  'split3_test_score': array([0.87804878, 0.8815331 , 0.87108014, 0.87456446, 0.88501742,\n",
       "         0.8815331 , 0.86759582, 0.86759582, 0.88501742, 0.8815331 ,\n",
       "         0.87456446, 0.87108014, 0.87108014, 0.87456446, 0.87804878,\n",
       "         0.8815331 , 0.87456446, 0.87804878, 0.8815331 , 0.89198606,\n",
       "         0.87804878, 0.87456446, 0.87456446, 0.8815331 , 0.87804878,\n",
       "         0.8815331 , 0.8815331 , 0.8815331 , 0.87456446, 0.88850174,\n",
       "         0.87804878, 0.87804878, 0.87108014, 0.87804878, 0.8815331 ,\n",
       "         0.8815331 , 0.90592334, 0.90592334, 0.91289199, 0.91289199,\n",
       "         0.89547038, 0.90592334, 0.91289199, 0.90592334, 0.8989547 ,\n",
       "         0.90940767, 0.90243902, 0.90940767, 0.90592334, 0.92334495,\n",
       "         0.90592334, 0.91289199, 0.90940767, 0.91289199, 0.90940767,\n",
       "         0.91289199, 0.90592334, 0.90940767, 0.91289199, 0.91637631,\n",
       "         0.8989547 , 0.90592334, 0.90243902, 0.90243902, 0.90940767,\n",
       "         0.90940767, 0.91289199, 0.90592334, 0.92334495, 0.92334495,\n",
       "         0.91986063, 0.90592334, 0.89547038, 0.8989547 , 0.90243902,\n",
       "         0.8989547 , 0.90592334, 0.8989547 , 0.8989547 , 0.8989547 ,\n",
       "         0.8989547 , 0.90592334, 0.90243902, 0.90592334, 0.90592334,\n",
       "         0.90243902, 0.90940767, 0.90592334, 0.91289199, 0.90592334,\n",
       "         0.90940767, 0.91289199, 0.90243902, 0.91637631, 0.90592334,\n",
       "         0.90243902, 0.90592334, 0.8989547 , 0.90592334, 0.8989547 ,\n",
       "         0.90243902, 0.8989547 , 0.90592334, 0.90243902, 0.90940767,\n",
       "         0.91289199, 0.90940767, 0.8989547 , 0.89547038, 0.8989547 ,\n",
       "         0.90243902, 0.8989547 , 0.90592334, 0.8989547 , 0.8989547 ,\n",
       "         0.8989547 , 0.8989547 , 0.90592334, 0.90243902, 0.90592334,\n",
       "         0.90592334, 0.90243902, 0.90940767, 0.90592334, 0.91289199,\n",
       "         0.90592334, 0.90940767, 0.91289199, 0.90243902, 0.91637631,\n",
       "         0.90592334, 0.90243902, 0.90592334, 0.8989547 , 0.90592334,\n",
       "         0.8989547 , 0.90243902, 0.8989547 , 0.90592334, 0.90243902,\n",
       "         0.90940767, 0.91289199, 0.90940767, 0.8989547 , 0.89547038,\n",
       "         0.8989547 , 0.90243902, 0.8989547 , 0.90592334, 0.8989547 ,\n",
       "         0.8989547 , 0.8989547 , 0.8989547 , 0.90592334, 0.90243902,\n",
       "         0.90592334, 0.90592334, 0.90243902, 0.90940767, 0.90592334,\n",
       "         0.91289199, 0.90592334, 0.90940767, 0.91289199, 0.90243902,\n",
       "         0.91637631, 0.90592334, 0.90243902, 0.90592334, 0.8989547 ,\n",
       "         0.90592334, 0.8989547 , 0.90243902, 0.8989547 , 0.90592334,\n",
       "         0.90243902, 0.90940767, 0.91289199, 0.90940767, 0.8989547 ,\n",
       "         0.8641115 , 0.87804878, 0.87108014, 0.86759582, 0.85365854,\n",
       "         0.87456446, 0.86759582, 0.8641115 , 0.8641115 , 0.87456446,\n",
       "         0.86759582, 0.86759582, 0.86062718, 0.85017422, 0.85714286,\n",
       "         0.86759582, 0.86759582, 0.85714286, 0.85365854, 0.86062718,\n",
       "         0.87108014, 0.8641115 , 0.86759582, 0.8641115 , 0.86062718,\n",
       "         0.86759582, 0.87108014, 0.86759582, 0.85714286, 0.8641115 ,\n",
       "         0.87456446, 0.87108014, 0.8641115 , 0.87456446, 0.87456446,\n",
       "         0.87108014, 0.90592334, 0.91637631, 0.91986063, 0.91986063,\n",
       "         0.88501742, 0.90243902, 0.91986063, 0.91289199, 0.90940767,\n",
       "         0.90592334, 0.91637631, 0.91637631, 0.90243902, 0.90243902,\n",
       "         0.90592334, 0.90592334, 0.90592334, 0.90243902, 0.90592334,\n",
       "         0.90243902, 0.90243902, 0.8989547 , 0.90592334, 0.91289199,\n",
       "         0.91289199, 0.90243902, 0.90243902, 0.90940767, 0.91986063,\n",
       "         0.90940767, 0.90940767, 0.90940767, 0.91637631, 0.91289199,\n",
       "         0.91637631, 0.90940767, 0.8989547 , 0.8989547 , 0.8989547 ,\n",
       "         0.90592334, 0.8989547 , 0.8989547 , 0.8989547 , 0.8989547 ,\n",
       "         0.90592334, 0.8989547 , 0.8989547 , 0.90243902, 0.90592334,\n",
       "         0.90940767, 0.90243902, 0.90592334, 0.91289199, 0.90592334,\n",
       "         0.90243902, 0.90592334, 0.90940767, 0.90592334, 0.90243902,\n",
       "         0.90592334, 0.91637631, 0.90592334, 0.90243902, 0.90592334,\n",
       "         0.91637631, 0.91289199, 0.90592334, 0.90243902, 0.91986063,\n",
       "         0.90940767, 0.91637631, 0.90940767, 0.8989547 , 0.8989547 ,\n",
       "         0.8989547 , 0.90592334, 0.8989547 , 0.8989547 , 0.8989547 ,\n",
       "         0.8989547 , 0.90592334, 0.8989547 , 0.8989547 , 0.90243902,\n",
       "         0.90592334, 0.90940767, 0.90243902, 0.90592334, 0.91289199,\n",
       "         0.90592334, 0.90243902, 0.90592334, 0.90940767, 0.90592334,\n",
       "         0.90243902, 0.90592334, 0.91637631, 0.90592334, 0.90243902,\n",
       "         0.90592334, 0.91637631, 0.91289199, 0.90592334, 0.90243902,\n",
       "         0.91986063, 0.90940767, 0.91637631, 0.90940767, 0.8989547 ,\n",
       "         0.8989547 , 0.8989547 , 0.90592334, 0.8989547 , 0.8989547 ,\n",
       "         0.8989547 , 0.8989547 , 0.90592334, 0.8989547 , 0.8989547 ,\n",
       "         0.90243902, 0.90592334, 0.90940767, 0.90243902, 0.90592334,\n",
       "         0.91289199, 0.90592334, 0.90243902, 0.90592334, 0.90940767,\n",
       "         0.90592334, 0.90243902, 0.90592334, 0.91637631, 0.90592334,\n",
       "         0.90243902, 0.90592334, 0.91637631, 0.91289199, 0.90592334,\n",
       "         0.90243902, 0.91986063, 0.90940767, 0.91637631, 0.90940767,\n",
       "         0.88850174, 0.87804878, 0.8815331 , 0.88501742, 0.88850174,\n",
       "         0.87804878, 0.8815331 , 0.87804878, 0.88850174, 0.8815331 ,\n",
       "         0.88501742, 0.89198606, 0.8815331 , 0.87804878, 0.87804878,\n",
       "         0.87804878, 0.87804878, 0.87804878, 0.87456446, 0.8815331 ,\n",
       "         0.87804878, 0.8815331 , 0.87108014, 0.87804878, 0.88850174,\n",
       "         0.87456446, 0.89198606, 0.89198606, 0.89547038, 0.87804878,\n",
       "         0.88501742, 0.88850174, 0.8815331 , 0.87804878, 0.88850174,\n",
       "         0.88501742, 0.8989547 , 0.8989547 , 0.8989547 , 0.90243902,\n",
       "         0.89547038, 0.90243902, 0.90243902, 0.90940767, 0.90592334,\n",
       "         0.90940767, 0.90592334, 0.90243902, 0.90592334, 0.90592334,\n",
       "         0.90940767, 0.91289199, 0.90940767, 0.91289199, 0.90592334,\n",
       "         0.90940767, 0.90592334, 0.90940767, 0.91289199, 0.91289199,\n",
       "         0.90243902, 0.90243902, 0.90243902, 0.90592334, 0.89547038,\n",
       "         0.90243902, 0.90592334, 0.90243902, 0.89547038, 0.8989547 ,\n",
       "         0.90243902, 0.89547038, 0.89198606, 0.89547038, 0.89547038,\n",
       "         0.8989547 , 0.88850174, 0.88850174, 0.89198606, 0.89547038,\n",
       "         0.90243902, 0.89547038, 0.89547038, 0.8989547 , 0.90940767,\n",
       "         0.90940767, 0.90940767, 0.90592334, 0.8989547 , 0.90592334,\n",
       "         0.90940767, 0.90592334, 0.90940767, 0.91289199, 0.90940767,\n",
       "         0.90940767, 0.89547038, 0.90243902, 0.91289199, 0.91289199,\n",
       "         0.90592334, 0.90592334, 0.91289199, 0.91637631, 0.91289199,\n",
       "         0.91637631, 0.90243902, 0.91289199, 0.89198606, 0.89547038,\n",
       "         0.89547038, 0.8989547 , 0.88850174, 0.88850174, 0.89198606,\n",
       "         0.89547038, 0.90243902, 0.89547038, 0.89547038, 0.8989547 ,\n",
       "         0.90940767, 0.90940767, 0.90940767, 0.90592334, 0.8989547 ,\n",
       "         0.90592334, 0.90940767, 0.90592334, 0.90940767, 0.91289199,\n",
       "         0.90940767, 0.90940767, 0.89547038, 0.90243902, 0.91289199,\n",
       "         0.91289199, 0.90592334, 0.90592334, 0.91289199, 0.91637631,\n",
       "         0.91289199, 0.91637631, 0.90243902, 0.91289199, 0.89198606,\n",
       "         0.89547038, 0.89547038, 0.8989547 , 0.88850174, 0.88850174,\n",
       "         0.89198606, 0.89547038, 0.90243902, 0.89547038, 0.89547038,\n",
       "         0.8989547 , 0.90940767, 0.90940767, 0.90940767, 0.90592334,\n",
       "         0.8989547 , 0.90592334, 0.90940767, 0.90592334, 0.90940767,\n",
       "         0.91289199, 0.90940767, 0.90940767, 0.89547038, 0.90243902,\n",
       "         0.91289199, 0.91289199, 0.90592334, 0.90592334, 0.91289199,\n",
       "         0.91637631, 0.91289199, 0.91637631, 0.90243902, 0.91289199,\n",
       "         0.87804878, 0.87456446, 0.87804878, 0.87456446, 0.87804878,\n",
       "         0.87456446, 0.8815331 , 0.87456446, 0.88850174, 0.87804878,\n",
       "         0.87804878, 0.87804878, 0.86759582, 0.87456446, 0.86759582,\n",
       "         0.8641115 , 0.87108014, 0.87108014, 0.86759582, 0.86759582,\n",
       "         0.87456446, 0.87804878, 0.87108014, 0.87108014, 0.88501742,\n",
       "         0.87804878, 0.87804878, 0.88850174, 0.88501742, 0.87804878,\n",
       "         0.87804878, 0.88850174, 0.89198606, 0.8815331 , 0.87108014,\n",
       "         0.8815331 , 0.8815331 , 0.89198606, 0.90592334, 0.90940767,\n",
       "         0.88850174, 0.8989547 , 0.90243902, 0.90940767, 0.89547038,\n",
       "         0.88850174, 0.8989547 , 0.90243902, 0.90940767, 0.90592334,\n",
       "         0.8989547 , 0.90243902, 0.90940767, 0.90592334, 0.8989547 ,\n",
       "         0.8989547 , 0.90940767, 0.90592334, 0.90940767, 0.90592334,\n",
       "         0.90243902, 0.90592334, 0.90592334, 0.90592334, 0.90243902,\n",
       "         0.90243902, 0.90592334, 0.90592334, 0.90940767, 0.91289199,\n",
       "         0.90243902, 0.90243902, 0.89198606, 0.8989547 , 0.8989547 ,\n",
       "         0.89547038, 0.88850174, 0.8989547 , 0.8989547 , 0.8989547 ,\n",
       "         0.90243902, 0.90592334, 0.90243902, 0.8989547 , 0.90592334,\n",
       "         0.89547038, 0.90940767, 0.90940767, 0.90592334, 0.90592334,\n",
       "         0.90243902, 0.90243902, 0.8989547 , 0.90940767, 0.90940767,\n",
       "         0.90940767, 0.91289199, 0.91637631, 0.91637631, 0.90592334,\n",
       "         0.90940767, 0.90243902, 0.90243902, 0.90243902, 0.90592334,\n",
       "         0.90940767, 0.90940767, 0.91289199, 0.89198606, 0.8989547 ,\n",
       "         0.8989547 , 0.89547038, 0.88850174, 0.8989547 , 0.8989547 ,\n",
       "         0.8989547 , 0.90243902, 0.90592334, 0.90243902, 0.8989547 ,\n",
       "         0.90592334, 0.89547038, 0.90940767, 0.90940767, 0.90592334,\n",
       "         0.90592334, 0.90243902, 0.90243902, 0.8989547 , 0.90940767,\n",
       "         0.90940767, 0.90940767, 0.91289199, 0.91637631, 0.91637631,\n",
       "         0.90592334, 0.90940767, 0.90243902, 0.90243902, 0.90243902,\n",
       "         0.90592334, 0.90940767, 0.90940767, 0.91289199, 0.89198606,\n",
       "         0.8989547 , 0.8989547 , 0.89547038, 0.88850174, 0.8989547 ,\n",
       "         0.8989547 , 0.8989547 , 0.90243902, 0.90592334, 0.90243902,\n",
       "         0.8989547 , 0.90592334, 0.89547038, 0.90940767, 0.90940767,\n",
       "         0.90592334, 0.90592334, 0.90243902, 0.90243902, 0.8989547 ,\n",
       "         0.90940767, 0.90940767, 0.90940767, 0.91289199, 0.91637631,\n",
       "         0.91637631, 0.90592334, 0.90940767, 0.90243902, 0.90243902,\n",
       "         0.90243902, 0.90592334, 0.90940767, 0.90940767, 0.91289199]),\n",
       "  'split4_test_score': array([0.91637631, 0.91637631, 0.92682927, 0.92334495, 0.92334495,\n",
       "         0.91986063, 0.93031359, 0.92334495, 0.91986063, 0.91986063,\n",
       "         0.92682927, 0.92682927, 0.92334495, 0.93031359, 0.93031359,\n",
       "         0.93728223, 0.91637631, 0.93031359, 0.92334495, 0.92334495,\n",
       "         0.91637631, 0.92334495, 0.93379791, 0.93031359, 0.91289199,\n",
       "         0.91986063, 0.92334495, 0.93031359, 0.90940767, 0.91986063,\n",
       "         0.92682927, 0.93379791, 0.91289199, 0.91986063, 0.92682927,\n",
       "         0.93379791, 0.93728223, 0.93031359, 0.93031359, 0.93031359,\n",
       "         0.93379791, 0.93031359, 0.93031359, 0.93031359, 0.93379791,\n",
       "         0.93379791, 0.93379791, 0.93379791, 0.93728223, 0.93728223,\n",
       "         0.93031359, 0.93379791, 0.93728223, 0.93379791, 0.93728223,\n",
       "         0.93379791, 0.92682927, 0.93031359, 0.94076655, 0.93379791,\n",
       "         0.93379791, 0.94076655, 0.93728223, 0.93379791, 0.93379791,\n",
       "         0.93379791, 0.93031359, 0.94076655, 0.93379791, 0.93379791,\n",
       "         0.93728223, 0.94076655, 0.90940767, 0.90592334, 0.91986063,\n",
       "         0.91986063, 0.91637631, 0.90940767, 0.91637631, 0.92334495,\n",
       "         0.92334495, 0.91289199, 0.91986063, 0.91986063, 0.91637631,\n",
       "         0.91637631, 0.92334495, 0.92334495, 0.93031359, 0.92334495,\n",
       "         0.91986063, 0.91986063, 0.92682927, 0.92334495, 0.92682927,\n",
       "         0.92334495, 0.92682927, 0.93379791, 0.93031359, 0.93031359,\n",
       "         0.92682927, 0.93031359, 0.93031359, 0.92682927, 0.92334495,\n",
       "         0.92682927, 0.92682927, 0.92682927, 0.90940767, 0.90592334,\n",
       "         0.91986063, 0.91986063, 0.91637631, 0.90940767, 0.91637631,\n",
       "         0.92334495, 0.92334495, 0.91289199, 0.91986063, 0.91986063,\n",
       "         0.91637631, 0.91637631, 0.92334495, 0.92334495, 0.93031359,\n",
       "         0.92334495, 0.91986063, 0.91986063, 0.92682927, 0.92334495,\n",
       "         0.92682927, 0.92334495, 0.92682927, 0.93379791, 0.93031359,\n",
       "         0.93031359, 0.92682927, 0.93031359, 0.93031359, 0.92682927,\n",
       "         0.92334495, 0.92682927, 0.92682927, 0.92682927, 0.90940767,\n",
       "         0.90592334, 0.91986063, 0.91986063, 0.91637631, 0.90940767,\n",
       "         0.91637631, 0.92334495, 0.92334495, 0.91289199, 0.91986063,\n",
       "         0.91986063, 0.91637631, 0.91637631, 0.92334495, 0.92334495,\n",
       "         0.93031359, 0.92334495, 0.91986063, 0.91986063, 0.92682927,\n",
       "         0.92334495, 0.92682927, 0.92334495, 0.92682927, 0.93379791,\n",
       "         0.93031359, 0.93031359, 0.92682927, 0.93031359, 0.93031359,\n",
       "         0.92682927, 0.92334495, 0.92682927, 0.92682927, 0.92682927,\n",
       "         0.90243902, 0.91986063, 0.91986063, 0.91986063, 0.90592334,\n",
       "         0.91986063, 0.91637631, 0.91637631, 0.91637631, 0.92682927,\n",
       "         0.91986063, 0.91637631, 0.91986063, 0.92334495, 0.91637631,\n",
       "         0.92682927, 0.92334495, 0.91986063, 0.91637631, 0.92334495,\n",
       "         0.91986063, 0.91986063, 0.91986063, 0.91637631, 0.90592334,\n",
       "         0.92334495, 0.91986063, 0.92334495, 0.91637631, 0.91637631,\n",
       "         0.91986063, 0.92334495, 0.91637631, 0.92334495, 0.92682927,\n",
       "         0.92682927, 0.93379791, 0.93379791, 0.93379791, 0.93031359,\n",
       "         0.93031359, 0.92682927, 0.93031359, 0.93379791, 0.93728223,\n",
       "         0.94076655, 0.93031359, 0.93379791, 0.93728223, 0.94076655,\n",
       "         0.94076655, 0.93728223, 0.93728223, 0.93728223, 0.93031359,\n",
       "         0.93728223, 0.94076655, 0.93379791, 0.93728223, 0.93728223,\n",
       "         0.92682927, 0.93728223, 0.92682927, 0.92682927, 0.93031359,\n",
       "         0.93379791, 0.93379791, 0.93031359, 0.94076655, 0.94773519,\n",
       "         0.94425087, 0.94773519, 0.91637631, 0.92682927, 0.92682927,\n",
       "         0.93031359, 0.92682927, 0.91637631, 0.92334495, 0.92682927,\n",
       "         0.92334495, 0.92682927, 0.92682927, 0.91986063, 0.92334495,\n",
       "         0.93379791, 0.93031359, 0.92682927, 0.93728223, 0.93728223,\n",
       "         0.93031359, 0.93031359, 0.93379791, 0.93728223, 0.93728223,\n",
       "         0.93379791, 0.93379791, 0.93031359, 0.93379791, 0.93728223,\n",
       "         0.93379791, 0.93728223, 0.93379791, 0.92682927, 0.92334495,\n",
       "         0.93031359, 0.93379791, 0.93379791, 0.91637631, 0.92682927,\n",
       "         0.92682927, 0.93031359, 0.92682927, 0.91637631, 0.92334495,\n",
       "         0.92682927, 0.92334495, 0.92682927, 0.92682927, 0.91986063,\n",
       "         0.92334495, 0.93379791, 0.93031359, 0.92682927, 0.93728223,\n",
       "         0.93728223, 0.93031359, 0.93031359, 0.93379791, 0.93728223,\n",
       "         0.93728223, 0.93379791, 0.93379791, 0.93031359, 0.93379791,\n",
       "         0.93728223, 0.93379791, 0.93728223, 0.93379791, 0.92682927,\n",
       "         0.92334495, 0.93031359, 0.93379791, 0.93379791, 0.91637631,\n",
       "         0.92682927, 0.92682927, 0.93031359, 0.92682927, 0.91637631,\n",
       "         0.92334495, 0.92682927, 0.92334495, 0.92682927, 0.92682927,\n",
       "         0.91986063, 0.92334495, 0.93379791, 0.93031359, 0.92682927,\n",
       "         0.93728223, 0.93728223, 0.93031359, 0.93031359, 0.93379791,\n",
       "         0.93728223, 0.93728223, 0.93379791, 0.93379791, 0.93031359,\n",
       "         0.93379791, 0.93728223, 0.93379791, 0.93728223, 0.93379791,\n",
       "         0.92682927, 0.92334495, 0.93031359, 0.93379791, 0.93379791,\n",
       "         0.91637631, 0.92334495, 0.92334495, 0.92334495, 0.91637631,\n",
       "         0.92334495, 0.91637631, 0.91986063, 0.90592334, 0.92334495,\n",
       "         0.91986063, 0.91986063, 0.91289199, 0.92334495, 0.92334495,\n",
       "         0.92334495, 0.90940767, 0.92334495, 0.92334495, 0.91986063,\n",
       "         0.91289199, 0.91986063, 0.92682927, 0.92334495, 0.90940767,\n",
       "         0.91637631, 0.92682927, 0.92334495, 0.90940767, 0.91986063,\n",
       "         0.92682927, 0.92334495, 0.92334495, 0.92334495, 0.91986063,\n",
       "         0.91986063, 0.92682927, 0.91986063, 0.91986063, 0.92334495,\n",
       "         0.92682927, 0.92334495, 0.92682927, 0.91986063, 0.91637631,\n",
       "         0.91986063, 0.91986063, 0.91986063, 0.91986063, 0.92682927,\n",
       "         0.92334495, 0.92334495, 0.91289199, 0.92334495, 0.92334495,\n",
       "         0.92334495, 0.91986063, 0.92682927, 0.92334495, 0.92682927,\n",
       "         0.92682927, 0.92682927, 0.92334495, 0.92334495, 0.93031359,\n",
       "         0.93031359, 0.92682927, 0.92682927, 0.91986063, 0.92334495,\n",
       "         0.92334495, 0.92334495, 0.89547038, 0.89198606, 0.8989547 ,\n",
       "         0.89547038, 0.90243902, 0.8989547 , 0.90243902, 0.8989547 ,\n",
       "         0.90243902, 0.90592334, 0.90592334, 0.90243902, 0.90940767,\n",
       "         0.90940767, 0.91637631, 0.90940767, 0.8989547 , 0.90940767,\n",
       "         0.91289199, 0.90243902, 0.91637631, 0.91289199, 0.90940767,\n",
       "         0.91289199, 0.91637631, 0.91637631, 0.91637631, 0.91637631,\n",
       "         0.92682927, 0.92334495, 0.91637631, 0.91986063, 0.91986063,\n",
       "         0.92334495, 0.91986063, 0.91289199, 0.89547038, 0.89198606,\n",
       "         0.8989547 , 0.89547038, 0.90243902, 0.8989547 , 0.90243902,\n",
       "         0.8989547 , 0.90243902, 0.90592334, 0.90592334, 0.90243902,\n",
       "         0.90940767, 0.90940767, 0.91637631, 0.90940767, 0.8989547 ,\n",
       "         0.90940767, 0.91289199, 0.90243902, 0.91637631, 0.91289199,\n",
       "         0.90940767, 0.91289199, 0.91637631, 0.91637631, 0.91637631,\n",
       "         0.91637631, 0.92682927, 0.92334495, 0.91637631, 0.91986063,\n",
       "         0.91986063, 0.92334495, 0.91986063, 0.91289199, 0.89547038,\n",
       "         0.89198606, 0.8989547 , 0.89547038, 0.90243902, 0.8989547 ,\n",
       "         0.90243902, 0.8989547 , 0.90243902, 0.90592334, 0.90592334,\n",
       "         0.90243902, 0.90940767, 0.90940767, 0.91637631, 0.90940767,\n",
       "         0.8989547 , 0.90940767, 0.91289199, 0.90243902, 0.91637631,\n",
       "         0.91289199, 0.90940767, 0.91289199, 0.91637631, 0.91637631,\n",
       "         0.91637631, 0.91637631, 0.92682927, 0.92334495, 0.91637631,\n",
       "         0.91986063, 0.91986063, 0.92334495, 0.91986063, 0.91289199,\n",
       "         0.90243902, 0.90940767, 0.92334495, 0.92334495, 0.90243902,\n",
       "         0.90940767, 0.92334495, 0.91986063, 0.89547038, 0.90940767,\n",
       "         0.92334495, 0.92334495, 0.90592334, 0.91986063, 0.91637631,\n",
       "         0.92334495, 0.90592334, 0.91986063, 0.91986063, 0.92682927,\n",
       "         0.90592334, 0.92334495, 0.92334495, 0.92334495, 0.92334495,\n",
       "         0.92334495, 0.93031359, 0.93031359, 0.92334495, 0.92682927,\n",
       "         0.93031359, 0.93031359, 0.92682927, 0.93031359, 0.93379791,\n",
       "         0.93031359, 0.92682927, 0.91986063, 0.92334495, 0.92334495,\n",
       "         0.91289199, 0.92334495, 0.91986063, 0.91986063, 0.92334495,\n",
       "         0.93379791, 0.92682927, 0.92682927, 0.91637631, 0.91986063,\n",
       "         0.91986063, 0.91986063, 0.92334495, 0.92334495, 0.92334495,\n",
       "         0.92334495, 0.91637631, 0.92334495, 0.92334495, 0.93031359,\n",
       "         0.92682927, 0.93031359, 0.93031359, 0.93031359, 0.93379791,\n",
       "         0.92682927, 0.92682927, 0.93031359, 0.91637631, 0.92682927,\n",
       "         0.92682927, 0.92682927, 0.89198606, 0.8989547 , 0.8989547 ,\n",
       "         0.8989547 , 0.90243902, 0.90592334, 0.8989547 , 0.90243902,\n",
       "         0.90940767, 0.8989547 , 0.90592334, 0.90940767, 0.90592334,\n",
       "         0.91289199, 0.91637631, 0.91986063, 0.91289199, 0.90940767,\n",
       "         0.91637631, 0.91289199, 0.92334495, 0.92334495, 0.92334495,\n",
       "         0.91637631, 0.91986063, 0.92682927, 0.92682927, 0.92682927,\n",
       "         0.92334495, 0.92334495, 0.92682927, 0.92682927, 0.92334495,\n",
       "         0.91637631, 0.91986063, 0.92334495, 0.89198606, 0.8989547 ,\n",
       "         0.8989547 , 0.8989547 , 0.90243902, 0.90592334, 0.8989547 ,\n",
       "         0.90243902, 0.90940767, 0.8989547 , 0.90592334, 0.90940767,\n",
       "         0.90592334, 0.91289199, 0.91637631, 0.91986063, 0.91289199,\n",
       "         0.90940767, 0.91637631, 0.91289199, 0.92334495, 0.92334495,\n",
       "         0.92334495, 0.91637631, 0.91986063, 0.92682927, 0.92682927,\n",
       "         0.92682927, 0.92334495, 0.92334495, 0.92682927, 0.92682927,\n",
       "         0.92334495, 0.91637631, 0.91986063, 0.92334495, 0.89198606,\n",
       "         0.8989547 , 0.8989547 , 0.8989547 , 0.90243902, 0.90592334,\n",
       "         0.8989547 , 0.90243902, 0.90940767, 0.8989547 , 0.90592334,\n",
       "         0.90940767, 0.90592334, 0.91289199, 0.91637631, 0.91986063,\n",
       "         0.91289199, 0.90940767, 0.91637631, 0.91289199, 0.92334495,\n",
       "         0.92334495, 0.92334495, 0.91637631, 0.91986063, 0.92682927,\n",
       "         0.92682927, 0.92682927, 0.92334495, 0.92334495, 0.92682927,\n",
       "         0.92682927, 0.92334495, 0.91637631, 0.91986063, 0.92334495]),\n",
       "  'mean_test_score': array([0.9045961 , 0.9045961 , 0.90668524, 0.90947075, 0.90529248,\n",
       "         0.90529248, 0.90598886, 0.90598886, 0.90598886, 0.9045961 ,\n",
       "         0.90668524, 0.91016713, 0.90807799, 0.90947075, 0.90738162,\n",
       "         0.90947075, 0.90668524, 0.91086351, 0.91016713, 0.90877437,\n",
       "         0.9045961 , 0.90668524, 0.90877437, 0.90877437, 0.90529248,\n",
       "         0.90738162, 0.90877437, 0.91504178, 0.90320334, 0.90947075,\n",
       "         0.90877437, 0.9143454 , 0.9045961 , 0.91016713, 0.91155989,\n",
       "         0.91643454, 0.90877437, 0.90738162, 0.90807799, 0.90807799,\n",
       "         0.90668524, 0.90877437, 0.91086351, 0.90947075, 0.90738162,\n",
       "         0.90668524, 0.90668524, 0.91016713, 0.91225627, 0.91364903,\n",
       "         0.91086351, 0.9143454 , 0.91086351, 0.90947075, 0.90947075,\n",
       "         0.91155989, 0.90877437, 0.91016713, 0.91155989, 0.91155989,\n",
       "         0.91016713, 0.9143454 , 0.91086351, 0.91086351, 0.91504178,\n",
       "         0.91155989, 0.91225627, 0.91225627, 0.91922006, 0.91713092,\n",
       "         0.9178273 , 0.91713092, 0.89345404, 0.8948468 , 0.90041783,\n",
       "         0.89902507, 0.90181058, 0.89763231, 0.89902507, 0.90111421,\n",
       "         0.89693593, 0.89902507, 0.90250696, 0.90250696, 0.90041783,\n",
       "         0.89902507, 0.90111421, 0.90389972, 0.90738162, 0.90320334,\n",
       "         0.9045961 , 0.90598886, 0.9045961 , 0.90807799, 0.90529248,\n",
       "         0.9045961 , 0.90668524, 0.90598886, 0.90738162, 0.90529248,\n",
       "         0.9045961 , 0.90598886, 0.90668524, 0.90598886, 0.90807799,\n",
       "         0.90668524, 0.90877437, 0.90668524, 0.89345404, 0.8948468 ,\n",
       "         0.90041783, 0.89902507, 0.90181058, 0.89763231, 0.89902507,\n",
       "         0.90111421, 0.89693593, 0.89902507, 0.90250696, 0.90250696,\n",
       "         0.90041783, 0.89902507, 0.90111421, 0.90389972, 0.90738162,\n",
       "         0.90320334, 0.9045961 , 0.90598886, 0.9045961 , 0.90807799,\n",
       "         0.90529248, 0.9045961 , 0.90668524, 0.90598886, 0.90738162,\n",
       "         0.90529248, 0.9045961 , 0.90598886, 0.90668524, 0.90598886,\n",
       "         0.90807799, 0.90668524, 0.90877437, 0.90668524, 0.89345404,\n",
       "         0.8948468 , 0.90041783, 0.89902507, 0.90181058, 0.89763231,\n",
       "         0.89902507, 0.90111421, 0.89693593, 0.89902507, 0.90250696,\n",
       "         0.90250696, 0.90041783, 0.89902507, 0.90111421, 0.90389972,\n",
       "         0.90738162, 0.90320334, 0.9045961 , 0.90598886, 0.9045961 ,\n",
       "         0.90807799, 0.90529248, 0.9045961 , 0.90668524, 0.90598886,\n",
       "         0.90738162, 0.90529248, 0.9045961 , 0.90598886, 0.90668524,\n",
       "         0.90598886, 0.90807799, 0.90668524, 0.90877437, 0.90668524,\n",
       "         0.8948468 , 0.90320334, 0.90181058, 0.90181058, 0.89554318,\n",
       "         0.90111421, 0.89832869, 0.89972145, 0.89623955, 0.90389972,\n",
       "         0.90111421, 0.90181058, 0.90181058, 0.89832869, 0.90598886,\n",
       "         0.90738162, 0.90250696, 0.89972145, 0.9045961 , 0.90389972,\n",
       "         0.9045961 , 0.90389972, 0.90947075, 0.90529248, 0.89693593,\n",
       "         0.90529248, 0.90598886, 0.9045961 , 0.89693593, 0.90320334,\n",
       "         0.90738162, 0.90598886, 0.90181058, 0.90877437, 0.91016713,\n",
       "         0.91016713, 0.90598886, 0.91364903, 0.91225627, 0.91155989,\n",
       "         0.90250696, 0.90947075, 0.90877437, 0.91016713, 0.90947075,\n",
       "         0.91155989, 0.90877437, 0.91155989, 0.91155989, 0.9143454 ,\n",
       "         0.9143454 , 0.91295265, 0.91364903, 0.9143454 , 0.91643454,\n",
       "         0.91643454, 0.91295265, 0.91225627, 0.91225627, 0.91364903,\n",
       "         0.91643454, 0.9143454 , 0.91086351, 0.91016713, 0.91295265,\n",
       "         0.91155989, 0.91155989, 0.91016713, 0.91713092, 0.91922006,\n",
       "         0.91643454, 0.91643454, 0.90111421, 0.90181058, 0.89763231,\n",
       "         0.89972145, 0.90041783, 0.90111421, 0.90181058, 0.90181058,\n",
       "         0.90320334, 0.90598886, 0.90598886, 0.90250696, 0.90389972,\n",
       "         0.91016713, 0.90529248, 0.90877437, 0.91155989, 0.90877437,\n",
       "         0.90668524, 0.90668524, 0.91155989, 0.91086351, 0.90877437,\n",
       "         0.90877437, 0.91504178, 0.91364903, 0.91155989, 0.9143454 ,\n",
       "         0.9143454 , 0.91504178, 0.91295265, 0.90668524, 0.91364903,\n",
       "         0.91225627, 0.9143454 , 0.91295265, 0.90111421, 0.90181058,\n",
       "         0.89763231, 0.89972145, 0.90041783, 0.90111421, 0.90181058,\n",
       "         0.90181058, 0.90320334, 0.90598886, 0.90598886, 0.90250696,\n",
       "         0.90389972, 0.91016713, 0.90529248, 0.90877437, 0.91155989,\n",
       "         0.90877437, 0.90668524, 0.90668524, 0.91155989, 0.91086351,\n",
       "         0.90877437, 0.90877437, 0.91504178, 0.91364903, 0.91155989,\n",
       "         0.9143454 , 0.9143454 , 0.91504178, 0.91295265, 0.90668524,\n",
       "         0.91364903, 0.91225627, 0.9143454 , 0.91295265, 0.90111421,\n",
       "         0.90181058, 0.89763231, 0.89972145, 0.90041783, 0.90111421,\n",
       "         0.90181058, 0.90181058, 0.90320334, 0.90598886, 0.90598886,\n",
       "         0.90250696, 0.90389972, 0.91016713, 0.90529248, 0.90877437,\n",
       "         0.91155989, 0.90877437, 0.90668524, 0.90668524, 0.91155989,\n",
       "         0.91086351, 0.90877437, 0.90877437, 0.91504178, 0.91364903,\n",
       "         0.91155989, 0.9143454 , 0.9143454 , 0.91504178, 0.91295265,\n",
       "         0.90668524, 0.91364903, 0.91225627, 0.9143454 , 0.91295265,\n",
       "         0.90598886, 0.90320334, 0.90389972, 0.90320334, 0.90529248,\n",
       "         0.90389972, 0.90250696, 0.90250696, 0.90111421, 0.90529248,\n",
       "         0.9045961 , 0.90668524, 0.90807799, 0.91225627, 0.91086351,\n",
       "         0.91016713, 0.90529248, 0.90947075, 0.90877437, 0.90807799,\n",
       "         0.9045961 , 0.90738162, 0.90668524, 0.90738162, 0.90807799,\n",
       "         0.90738162, 0.91573816, 0.91643454, 0.91155989, 0.90807799,\n",
       "         0.9143454 , 0.91504178, 0.91016713, 0.90877437, 0.91504178,\n",
       "         0.9143454 , 0.90738162, 0.90250696, 0.90320334, 0.90668524,\n",
       "         0.9045961 , 0.90320334, 0.9045961 , 0.90389972, 0.9045961 ,\n",
       "         0.9045961 , 0.9045961 , 0.90529248, 0.90320334, 0.90181058,\n",
       "         0.90668524, 0.90668524, 0.90389972, 0.90738162, 0.90389972,\n",
       "         0.90598886, 0.90529248, 0.90389972, 0.90529248, 0.90738162,\n",
       "         0.90668524, 0.90598886, 0.90598886, 0.90668524, 0.90389972,\n",
       "         0.90877437, 0.90738162, 0.90598886, 0.90598886, 0.90111421,\n",
       "         0.90389972, 0.90529248, 0.88440111, 0.88718663, 0.88857939,\n",
       "         0.88579387, 0.88370474, 0.88649025, 0.88718663, 0.88649025,\n",
       "         0.88927577, 0.88857939, 0.89066852, 0.88997214, 0.8948468 ,\n",
       "         0.89693593, 0.89972145, 0.89623955, 0.8913649 , 0.89275766,\n",
       "         0.89554318, 0.89275766, 0.90111421, 0.90181058, 0.89902507,\n",
       "         0.89972145, 0.89902507, 0.89972145, 0.90111421, 0.90250696,\n",
       "         0.90320334, 0.90598886, 0.90389972, 0.90320334, 0.90320334,\n",
       "         0.90320334, 0.90041783, 0.90041783, 0.88440111, 0.88718663,\n",
       "         0.88857939, 0.88579387, 0.88370474, 0.88649025, 0.88718663,\n",
       "         0.88649025, 0.88927577, 0.88857939, 0.89066852, 0.88997214,\n",
       "         0.8948468 , 0.89693593, 0.89972145, 0.89623955, 0.8913649 ,\n",
       "         0.89275766, 0.89554318, 0.89275766, 0.90111421, 0.90181058,\n",
       "         0.89902507, 0.89972145, 0.89902507, 0.89972145, 0.90111421,\n",
       "         0.90250696, 0.90320334, 0.90598886, 0.90389972, 0.90320334,\n",
       "         0.90320334, 0.90320334, 0.90041783, 0.90041783, 0.88440111,\n",
       "         0.88718663, 0.88857939, 0.88579387, 0.88370474, 0.88649025,\n",
       "         0.88718663, 0.88649025, 0.88927577, 0.88857939, 0.89066852,\n",
       "         0.88997214, 0.8948468 , 0.89693593, 0.89972145, 0.89623955,\n",
       "         0.8913649 , 0.89275766, 0.89554318, 0.89275766, 0.90111421,\n",
       "         0.90181058, 0.89902507, 0.89972145, 0.89902507, 0.89972145,\n",
       "         0.90111421, 0.90250696, 0.90320334, 0.90598886, 0.90389972,\n",
       "         0.90320334, 0.90320334, 0.90320334, 0.90041783, 0.90041783,\n",
       "         0.90111421, 0.90250696, 0.90250696, 0.90250696, 0.90181058,\n",
       "         0.90111421, 0.90320334, 0.90250696, 0.89763231, 0.90320334,\n",
       "         0.90111421, 0.90389972, 0.90041783, 0.90598886, 0.90320334,\n",
       "         0.9045961 , 0.90389972, 0.90529248, 0.90320334, 0.9045961 ,\n",
       "         0.90738162, 0.90947075, 0.90668524, 0.90877437, 0.90807799,\n",
       "         0.90947075, 0.9143454 , 0.9143454 , 0.91016713, 0.91225627,\n",
       "         0.91364903, 0.9143454 , 0.91295265, 0.90947075, 0.91155989,\n",
       "         0.9143454 , 0.89972145, 0.89972145, 0.90598886, 0.90738162,\n",
       "         0.89902507, 0.90111421, 0.90250696, 0.90529248, 0.90529248,\n",
       "         0.90529248, 0.90598886, 0.90598886, 0.90320334, 0.90529248,\n",
       "         0.9045961 , 0.90598886, 0.91016713, 0.90529248, 0.90529248,\n",
       "         0.90598886, 0.91086351, 0.90877437, 0.90738162, 0.90598886,\n",
       "         0.90738162, 0.91295265, 0.91016713, 0.91016713, 0.91155989,\n",
       "         0.91016713, 0.90947075, 0.90947075, 0.90738162, 0.91016713,\n",
       "         0.90877437, 0.90668524, 0.88509749, 0.88927577, 0.88857939,\n",
       "         0.88718663, 0.88579387, 0.88997214, 0.88857939, 0.8913649 ,\n",
       "         0.89066852, 0.8913649 , 0.89275766, 0.89415042, 0.89693593,\n",
       "         0.89832869, 0.90181058, 0.90111421, 0.89693593, 0.89623955,\n",
       "         0.89902507, 0.89554318, 0.89972145, 0.90250696, 0.90250696,\n",
       "         0.90041783, 0.9045961 , 0.90598886, 0.90807799, 0.9045961 ,\n",
       "         0.90111421, 0.90181058, 0.90320334, 0.9045961 , 0.90320334,\n",
       "         0.90529248, 0.90598886, 0.90598886, 0.88509749, 0.88927577,\n",
       "         0.88857939, 0.88718663, 0.88579387, 0.88997214, 0.88857939,\n",
       "         0.8913649 , 0.89066852, 0.8913649 , 0.89275766, 0.89415042,\n",
       "         0.89693593, 0.89832869, 0.90181058, 0.90111421, 0.89693593,\n",
       "         0.89623955, 0.89902507, 0.89554318, 0.89972145, 0.90250696,\n",
       "         0.90250696, 0.90041783, 0.9045961 , 0.90598886, 0.90807799,\n",
       "         0.9045961 , 0.90111421, 0.90181058, 0.90320334, 0.9045961 ,\n",
       "         0.90320334, 0.90529248, 0.90598886, 0.90598886, 0.88509749,\n",
       "         0.88927577, 0.88857939, 0.88718663, 0.88579387, 0.88997214,\n",
       "         0.88857939, 0.8913649 , 0.89066852, 0.8913649 , 0.89275766,\n",
       "         0.89415042, 0.89693593, 0.89832869, 0.90181058, 0.90111421,\n",
       "         0.89693593, 0.89623955, 0.89902507, 0.89554318, 0.89972145,\n",
       "         0.90250696, 0.90250696, 0.90041783, 0.9045961 , 0.90598886,\n",
       "         0.90807799, 0.9045961 , 0.90111421, 0.90181058, 0.90320334,\n",
       "         0.9045961 , 0.90320334, 0.90529248, 0.90598886, 0.90598886]),\n",
       "  'std_test_score': array([0.01764107, 0.01956751, 0.02370149, 0.02208504, 0.01660202,\n",
       "         0.01800431, 0.02495991, 0.02177504, 0.01565328, 0.01867934,\n",
       "         0.02222209, 0.02320872, 0.02117011, 0.02154063, 0.02266161,\n",
       "         0.0222795 , 0.02078012, 0.01998234, 0.02063941, 0.01658843,\n",
       "         0.01777808, 0.02088385, 0.02191056, 0.01992596, 0.01620682,\n",
       "         0.01843798, 0.01943278, 0.02471374, 0.01651198, 0.01872944,\n",
       "         0.02099332, 0.02311388, 0.02137269, 0.02134556, 0.02043546,\n",
       "         0.02315051, 0.0195139 , 0.02162052, 0.01890999, 0.02000124,\n",
       "         0.01903236, 0.02352973, 0.0194074 , 0.01764666, 0.02037922,\n",
       "         0.01876017, 0.01975268, 0.01783567, 0.01659185, 0.02259683,\n",
       "         0.01917089, 0.01826729, 0.0236476 , 0.02369229, 0.02019603,\n",
       "         0.01758417, 0.01535542, 0.01781937, 0.01761577, 0.01646041,\n",
       "         0.01717438, 0.01942599, 0.01942238, 0.01917089, 0.01990309,\n",
       "         0.01840881, 0.01838011, 0.0194075 , 0.01600328, 0.01509051,\n",
       "         0.02050944, 0.02130062, 0.01390688, 0.01469209, 0.01672578,\n",
       "         0.01529622, 0.01594757, 0.02126538, 0.01968168, 0.02094081,\n",
       "         0.01757067, 0.01587887, 0.01528047, 0.01720361, 0.01834952,\n",
       "         0.01662536, 0.01729354, 0.01672997, 0.02393521, 0.02091081,\n",
       "         0.01783273, 0.01619089, 0.02035757, 0.01643888, 0.01581826,\n",
       "         0.01490514, 0.01885692, 0.02053467, 0.01702168, 0.01742407,\n",
       "         0.0174374 , 0.01637612, 0.01713797, 0.01789912, 0.01645656,\n",
       "         0.01726166, 0.02214863, 0.01755758, 0.01390688, 0.01469209,\n",
       "         0.01672578, 0.01529622, 0.01594757, 0.02126538, 0.01968168,\n",
       "         0.02094081, 0.01757067, 0.01587887, 0.01528047, 0.01720361,\n",
       "         0.01834952, 0.01662536, 0.01729354, 0.01672997, 0.02393521,\n",
       "         0.02091081, 0.01783273, 0.01619089, 0.02035757, 0.01643888,\n",
       "         0.01581826, 0.01490514, 0.01885692, 0.02053467, 0.01702168,\n",
       "         0.01742407, 0.0174374 , 0.01637612, 0.01713797, 0.01789912,\n",
       "         0.01645656, 0.01726166, 0.02214863, 0.01755758, 0.01390688,\n",
       "         0.01469209, 0.01672578, 0.01529622, 0.01594757, 0.02126538,\n",
       "         0.01968168, 0.02094081, 0.01757067, 0.01587887, 0.01528047,\n",
       "         0.01720361, 0.01834952, 0.01662536, 0.01729354, 0.01672997,\n",
       "         0.02393521, 0.02091081, 0.01783273, 0.01619089, 0.02035757,\n",
       "         0.01643888, 0.01581826, 0.01490514, 0.01885692, 0.02053467,\n",
       "         0.01702168, 0.01742407, 0.0174374 , 0.01637612, 0.01713797,\n",
       "         0.01789912, 0.01645656, 0.01726166, 0.02214863, 0.01755758,\n",
       "         0.01723488, 0.02050231, 0.02029714, 0.01959427, 0.02318704,\n",
       "         0.0189498 , 0.01882087, 0.0205552 , 0.02337259, 0.02134883,\n",
       "         0.0220288 , 0.02145931, 0.02238118, 0.02671855, 0.02605663,\n",
       "         0.02323724, 0.02108211, 0.02413833, 0.02815459, 0.02579837,\n",
       "         0.01899422, 0.02073137, 0.02478782, 0.02502215, 0.01851825,\n",
       "         0.02010895, 0.0196799 , 0.02151021, 0.0207431 , 0.0201274 ,\n",
       "         0.02046091, 0.02075991, 0.01950831, 0.01820961, 0.02079374,\n",
       "         0.02225907, 0.021002  , 0.01537199, 0.01672108, 0.01673578,\n",
       "         0.02169483, 0.01803834, 0.01822811, 0.0168565 , 0.02350002,\n",
       "         0.02367213, 0.02160855, 0.0214117 , 0.01691305, 0.02042719,\n",
       "         0.01867618, 0.01807331, 0.01557859, 0.0195645 , 0.01725237,\n",
       "         0.01997555, 0.02205084, 0.01915582, 0.02151408, 0.02128335,\n",
       "         0.01934453, 0.01691875, 0.01634799, 0.01687323, 0.01591555,\n",
       "         0.01863986, 0.01904164, 0.01938462, 0.01800785, 0.02174602,\n",
       "         0.02114245, 0.0229052 , 0.01715266, 0.02069769, 0.01988292,\n",
       "         0.02115292, 0.02023603, 0.01925041, 0.0187283 , 0.01923956,\n",
       "         0.01794645, 0.01694129, 0.0186948 , 0.01590295, 0.01585475,\n",
       "         0.01942825, 0.01673068, 0.01686171, 0.02038096, 0.02118329,\n",
       "         0.02023807, 0.01950545, 0.01989906, 0.01787622, 0.0195139 ,\n",
       "         0.01999013, 0.01826502, 0.01474508, 0.01589378, 0.01789451,\n",
       "         0.01743595, 0.01864416, 0.01858785, 0.01925505, 0.01768703,\n",
       "         0.02070956, 0.01759061, 0.01871793, 0.01715266, 0.02069769,\n",
       "         0.01988292, 0.02115292, 0.02023603, 0.01925041, 0.0187283 ,\n",
       "         0.01923956, 0.01794645, 0.01694129, 0.0186948 , 0.01590295,\n",
       "         0.01585475, 0.01942825, 0.01673068, 0.01686171, 0.02038096,\n",
       "         0.02118329, 0.02023807, 0.01950545, 0.01989906, 0.01787622,\n",
       "         0.0195139 , 0.01999013, 0.01826502, 0.01474508, 0.01589378,\n",
       "         0.01789451, 0.01743595, 0.01864416, 0.01858785, 0.01925505,\n",
       "         0.01768703, 0.02070956, 0.01759061, 0.01871793, 0.01715266,\n",
       "         0.02069769, 0.01988292, 0.02115292, 0.02023603, 0.01925041,\n",
       "         0.0187283 , 0.01923956, 0.01794645, 0.01694129, 0.0186948 ,\n",
       "         0.01590295, 0.01585475, 0.01942825, 0.01673068, 0.01686171,\n",
       "         0.02038096, 0.02118329, 0.02023807, 0.01950545, 0.01989906,\n",
       "         0.01787622, 0.0195139 , 0.01999013, 0.01826502, 0.01474508,\n",
       "         0.01589378, 0.01789451, 0.01743595, 0.01864416, 0.01858785,\n",
       "         0.01925505, 0.01768703, 0.02070956, 0.01759061, 0.01871793,\n",
       "         0.0157902 , 0.01801206, 0.01828804, 0.01824812, 0.01374133,\n",
       "         0.01736648, 0.0171145 , 0.01985532, 0.01928364, 0.01573495,\n",
       "         0.01733175, 0.0149018 , 0.01709931, 0.01872344, 0.02170426,\n",
       "         0.01792332, 0.01789919, 0.01773524, 0.02043282, 0.01652196,\n",
       "         0.01818292, 0.01994105, 0.021582  , 0.01871352, 0.01217549,\n",
       "         0.01770107, 0.01447128, 0.01900644, 0.01255032, 0.01671133,\n",
       "         0.0172599 , 0.01818921, 0.01780045, 0.01725168, 0.01609344,\n",
       "         0.01984986, 0.01556777, 0.01414642, 0.01371098, 0.01471892,\n",
       "         0.02140341, 0.01960943, 0.01914509, 0.01987744, 0.0196455 ,\n",
       "         0.01863124, 0.01643451, 0.01597092, 0.01684837, 0.01823691,\n",
       "         0.01874422, 0.01925505, 0.01244581, 0.01614375, 0.02035985,\n",
       "         0.0190802 , 0.01863528, 0.01838819, 0.01728426, 0.01989727,\n",
       "         0.01925505, 0.01764288, 0.01764288, 0.01950545, 0.02027111,\n",
       "         0.0178406 , 0.02106691, 0.02041617, 0.01846536, 0.02094081,\n",
       "         0.02106278, 0.01902188, 0.01382764, 0.00983215, 0.0112921 ,\n",
       "         0.01277543, 0.01391526, 0.01031923, 0.01317829, 0.013521  ,\n",
       "         0.01548048, 0.015263  , 0.01488813, 0.01405343, 0.01551623,\n",
       "         0.01337719, 0.01682554, 0.01484949, 0.01549166, 0.0176981 ,\n",
       "         0.01828896, 0.0153274 , 0.02024968, 0.0187283 , 0.01747912,\n",
       "         0.01711153, 0.01252707, 0.01503702, 0.01598096, 0.01662988,\n",
       "         0.01987127, 0.01706639, 0.01699948, 0.02067744, 0.01471484,\n",
       "         0.01985536, 0.01962735, 0.02009922, 0.01382764, 0.00983215,\n",
       "         0.0112921 , 0.01277543, 0.01391526, 0.01031923, 0.01317829,\n",
       "         0.013521  , 0.01548048, 0.015263  , 0.01488813, 0.01405343,\n",
       "         0.01551623, 0.01337719, 0.01682554, 0.01484949, 0.01549166,\n",
       "         0.0176981 , 0.01828896, 0.0153274 , 0.02024968, 0.0187283 ,\n",
       "         0.01747912, 0.01711153, 0.01252707, 0.01503702, 0.01598096,\n",
       "         0.01662988, 0.01987127, 0.01706639, 0.01699948, 0.02067744,\n",
       "         0.01471484, 0.01985536, 0.01962735, 0.02009922, 0.01382764,\n",
       "         0.00983215, 0.0112921 , 0.01277543, 0.01391526, 0.01031923,\n",
       "         0.01317829, 0.013521  , 0.01548048, 0.015263  , 0.01488813,\n",
       "         0.01405343, 0.01551623, 0.01337719, 0.01682554, 0.01484949,\n",
       "         0.01549166, 0.0176981 , 0.01828896, 0.0153274 , 0.02024968,\n",
       "         0.0187283 , 0.01747912, 0.01711153, 0.01252707, 0.01503702,\n",
       "         0.01598096, 0.01662988, 0.01987127, 0.01706639, 0.01699948,\n",
       "         0.02067744, 0.01471484, 0.01985536, 0.01962735, 0.02009922,\n",
       "         0.0146681 , 0.01600751, 0.01873872, 0.018508  , 0.01543863,\n",
       "         0.01484992, 0.01786104, 0.01770393, 0.01014635, 0.01574381,\n",
       "         0.01789615, 0.01818548, 0.02045818, 0.01825981, 0.02158039,\n",
       "         0.02333824, 0.0205778 , 0.01959544, 0.02158039, 0.02269417,\n",
       "         0.02138858, 0.01745947, 0.02277352, 0.02320143, 0.0168559 ,\n",
       "         0.01946702, 0.02094363, 0.01908934, 0.01594415, 0.01924642,\n",
       "         0.02125662, 0.01723254, 0.01407494, 0.02002279, 0.0238549 ,\n",
       "         0.0196161 , 0.01977644, 0.01873602, 0.01590715, 0.01474879,\n",
       "         0.0136398 , 0.01862694, 0.01706199, 0.01654942, 0.0171433 ,\n",
       "         0.02013721, 0.01592541, 0.01856456, 0.01549814, 0.01728426,\n",
       "         0.0181198 , 0.01789912, 0.01674517, 0.01537011, 0.01874909,\n",
       "         0.01764288, 0.01189948, 0.01795991, 0.01302164, 0.01736564,\n",
       "         0.0210815 , 0.02067466, 0.01925905, 0.01925905, 0.02176275,\n",
       "         0.01850338, 0.01776728, 0.01969442, 0.01631119, 0.01504899,\n",
       "         0.01612616, 0.01741883, 0.0089181 , 0.01137299, 0.01150497,\n",
       "         0.01077415, 0.01096289, 0.0143946 , 0.01305902, 0.01218346,\n",
       "         0.01552636, 0.01295562, 0.01468053, 0.01535229, 0.0140622 ,\n",
       "         0.01518374, 0.01419715, 0.01522308, 0.01410527, 0.01535245,\n",
       "         0.01448137, 0.01678553, 0.01873602, 0.01869078, 0.01635428,\n",
       "         0.01506604, 0.01838566, 0.02017707, 0.01744152, 0.01838566,\n",
       "         0.0181328 , 0.01672729, 0.01782799, 0.0181198 , 0.0162805 ,\n",
       "         0.01367957, 0.01463608, 0.01528484, 0.0089181 , 0.01137299,\n",
       "         0.01150497, 0.01077415, 0.01096289, 0.0143946 , 0.01305902,\n",
       "         0.01218346, 0.01552636, 0.01295562, 0.01468053, 0.01535229,\n",
       "         0.0140622 , 0.01518374, 0.01419715, 0.01522308, 0.01410527,\n",
       "         0.01535245, 0.01448137, 0.01678553, 0.01873602, 0.01869078,\n",
       "         0.01635428, 0.01506604, 0.01838566, 0.02017707, 0.01744152,\n",
       "         0.01838566, 0.0181328 , 0.01672729, 0.01782799, 0.0181198 ,\n",
       "         0.0162805 , 0.01367957, 0.01463608, 0.01528484, 0.0089181 ,\n",
       "         0.01137299, 0.01150497, 0.01077415, 0.01096289, 0.0143946 ,\n",
       "         0.01305902, 0.01218346, 0.01552636, 0.01295562, 0.01468053,\n",
       "         0.01535229, 0.0140622 , 0.01518374, 0.01419715, 0.01522308,\n",
       "         0.01410527, 0.01535245, 0.01448137, 0.01678553, 0.01873602,\n",
       "         0.01869078, 0.01635428, 0.01506604, 0.01838566, 0.02017707,\n",
       "         0.01744152, 0.01838566, 0.0181328 , 0.01672729, 0.01782799,\n",
       "         0.0181198 , 0.0162805 , 0.01367957, 0.01463608, 0.01528484]),\n",
       "  'rank_test_score': array([344, 344, 226, 137, 313, 313, 263, 263, 263, 344, 226, 115, 185,\n",
       "         137, 202, 137, 226, 103, 115, 153, 344, 226, 153, 153, 313, 202,\n",
       "         153,  15, 405, 137, 153,  25, 344, 115,  80,   7, 153, 202, 185,\n",
       "         185, 226, 153, 103, 137, 202, 226, 226, 115,  69,  47, 103,  25,\n",
       "         103, 137, 137,  80, 153, 115,  80,  80, 115,  25, 103, 103,  15,\n",
       "          80,  69,  69,   1,   4,   3,   4, 640, 630, 530, 568, 470, 595,\n",
       "         568, 498, 602, 568, 442, 442, 530, 568, 498, 383, 202, 405, 344,\n",
       "         263, 344, 185, 313, 344, 226, 263, 202, 313, 344, 263, 226, 263,\n",
       "         185, 226, 153, 226, 640, 630, 530, 568, 470, 595, 568, 498, 602,\n",
       "         568, 442, 442, 530, 568, 498, 383, 202, 405, 344, 263, 344, 185,\n",
       "         313, 344, 226, 263, 202, 313, 344, 263, 226, 263, 185, 226, 153,\n",
       "         226, 640, 630, 530, 568, 470, 595, 568, 498, 602, 568, 442, 442,\n",
       "         530, 568, 498, 383, 202, 405, 344, 263, 344, 185, 313, 344, 226,\n",
       "         263, 202, 313, 344, 263, 226, 263, 185, 226, 153, 226, 630, 405,\n",
       "         470, 470, 623, 498, 590, 549, 616, 383, 498, 470, 470, 590, 263,\n",
       "         202, 442, 549, 344, 383, 344, 383, 137, 313, 602, 313, 263, 344,\n",
       "         602, 405, 202, 263, 470, 153, 115, 115, 263,  47,  69,  80, 442,\n",
       "         137, 153, 115, 137,  80, 153,  80,  80,  25,  25,  58,  47,  25,\n",
       "           7,   7,  58,  69,  69,  47,   7,  25, 103, 115,  58,  80,  80,\n",
       "         115,   4,   1,   7,   7, 498, 470, 595, 549, 530, 498, 470, 470,\n",
       "         405, 263, 263, 442, 383, 115, 313, 153,  80, 153, 226, 226,  80,\n",
       "         103, 153, 153,  15,  47,  80,  25,  25,  15,  58, 226,  47,  69,\n",
       "          25,  58, 498, 470, 595, 549, 530, 498, 470, 470, 405, 263, 263,\n",
       "         442, 383, 115, 313, 153,  80, 153, 226, 226,  80, 103, 153, 153,\n",
       "          15,  47,  80,  25,  25,  15,  58, 226,  47,  69,  25,  58, 498,\n",
       "         470, 595, 549, 530, 498, 470, 470, 405, 263, 263, 442, 383, 115,\n",
       "         313, 153,  80, 153, 226, 226,  80, 103, 153, 153,  15,  47,  80,\n",
       "          25,  25,  15,  58, 226,  47,  69,  25,  58, 263, 405, 383, 405,\n",
       "         313, 383, 442, 442, 498, 313, 344, 226, 185,  69, 103, 115, 313,\n",
       "         137, 153, 185, 344, 202, 226, 202, 185, 202,  14,   7,  80, 185,\n",
       "          25,  15, 115, 153,  15,  25, 202, 442, 405, 226, 344, 405, 344,\n",
       "         383, 344, 344, 344, 313, 405, 470, 226, 226, 383, 202, 383, 263,\n",
       "         313, 383, 313, 202, 226, 263, 263, 226, 383, 153, 202, 263, 263,\n",
       "         498, 383, 313, 715, 691, 679, 706, 718, 700, 691, 700, 673, 679,\n",
       "         661, 667, 630, 602, 549, 616, 652, 643, 623, 643, 498, 470, 568,\n",
       "         549, 568, 549, 498, 442, 405, 263, 383, 405, 405, 405, 530, 530,\n",
       "         715, 691, 679, 706, 718, 700, 691, 700, 673, 679, 661, 667, 630,\n",
       "         602, 549, 616, 652, 643, 623, 643, 498, 470, 568, 549, 568, 549,\n",
       "         498, 442, 405, 263, 383, 405, 405, 405, 530, 530, 715, 691, 679,\n",
       "         706, 718, 700, 691, 700, 673, 679, 661, 667, 630, 602, 549, 616,\n",
       "         652, 643, 623, 643, 498, 470, 568, 549, 568, 549, 498, 442, 405,\n",
       "         263, 383, 405, 405, 405, 530, 530, 498, 442, 442, 442, 470, 498,\n",
       "         405, 442, 595, 405, 498, 383, 530, 263, 405, 344, 383, 313, 405,\n",
       "         344, 202, 137, 226, 153, 185, 137,  25,  25, 115,  69,  47,  25,\n",
       "          58, 137,  80,  25, 549, 549, 263, 202, 568, 498, 442, 313, 313,\n",
       "         313, 263, 263, 405, 313, 344, 263, 115, 313, 313, 263, 103, 153,\n",
       "         202, 263, 202,  58, 115, 115,  80, 115, 137, 137, 202, 115, 153,\n",
       "         226, 712, 673, 679, 691, 706, 667, 679, 652, 661, 652, 643, 637,\n",
       "         602, 590, 470, 498, 602, 616, 568, 623, 549, 442, 442, 530, 344,\n",
       "         263, 185, 344, 498, 470, 405, 344, 405, 313, 263, 263, 712, 673,\n",
       "         679, 691, 706, 667, 679, 652, 661, 652, 643, 637, 602, 590, 470,\n",
       "         498, 602, 616, 568, 623, 549, 442, 442, 530, 344, 263, 185, 344,\n",
       "         498, 470, 405, 344, 405, 313, 263, 263, 712, 673, 679, 691, 706,\n",
       "         667, 679, 652, 661, 652, 643, 637, 602, 590, 470, 498, 602, 616,\n",
       "         568, 623, 549, 442, 442, 530, 344, 263, 185, 344, 498, 470, 405,\n",
       "         344, 405, 313, 263, 263], dtype=int32)}}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_2_cls_scores_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T23:46:19.179755Z",
     "start_time": "2019-10-21T23:43:08.609009Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RF_2_cls_scores_fewer_params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-b8208b79ada6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Pickle results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/greenapple/project3/models/RF_2_cls_scores_fewer_params.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRF_2_cls_scores_fewer_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# Pickle model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RF_2_cls_scores_fewer_params' is not defined"
     ]
    }
   ],
   "source": [
    "# Train and fit Random Forest over fewer parameters\n",
    "from src.models import model_sel_grid\n",
    "\n",
    "# Function arguments:\n",
    "model = RandomForestClassifier(random_state=3)\n",
    "transformer = RandomOverSampler(random_state=3, sampling_strategy='minority')\n",
    "CV = 5\n",
    "\n",
    "# Function arguments: classifier params\n",
    "n_estimators = [50, 100, 300]\n",
    "criterion = ['gini', 'entropy']\n",
    "max_depth = [5, 50, None]\n",
    "min_samples_split = [2, 10]\n",
    "max_features = [25]\n",
    "bootstrap = [True]\n",
    "\n",
    "                \n",
    "param_grid = dict(model__n_estimators=n_estimators,\n",
    "                  model__criterion=criterion,\n",
    "                  model__max_depth=max_depth,\n",
    "                  model__min_samples_split=min_samples_split,\n",
    "                  model__max_features=max_features,\n",
    "                  model__bootstrap=bootstrap\n",
    "                 )\n",
    "\n",
    "# Call parameter selection function\n",
    "RF_2_cls_scores_params, RF_2_cls_models = model_sel_grid.train_fit_time(model,\n",
    "                                                                        param_grid,\n",
    "                                                                        transformer,\n",
    "                                                                        X_train,\n",
    "                                                                        X_test,\n",
    "                                                                        y_train,\n",
    "                                                                        y_test,\n",
    "                                                                        CV)\n",
    "\n",
    "# Pickle results\n",
    "with open('/Users/greenapple/project3/models/RF_2_cls_scores_fewer_params.pkl', 'wb') as f:\n",
    "    pickle.dump(RF_2_cls_scores_fewer_params, f)\n",
    "    \n",
    "# Pickle model\n",
    "with open('/Users/greenapple/project3/models/RF_2_cls_models_fewer.pkl', 'wb') as f:\n",
    "    pickle.dump(RF_2_cls_models_fewer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T00:20:22.140003Z",
     "start_time": "2019-10-22T00:20:22.035706Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_train_score': 0.9164345403899722,\n",
       " 'best_test_score': 0.9333333333333333,\n",
       " 'time_sec': 173.056771,\n",
       " 'time_best_fit_sec': 2.0784239999999996,\n",
       " 'best_params': {'model__bootstrap': True,\n",
       "  'model__criterion': 'gini',\n",
       "  'model__max_depth': 5,\n",
       "  'model__max_features': 25,\n",
       "  'model__min_samples_split': 10,\n",
       "  'model__n_estimators': 300},\n",
       " 'best_estimator': Pipeline(memory=None,\n",
       "          steps=[('transformer',\n",
       "                  RandomOverSampler(random_state=3, ratio=None,\n",
       "                                    return_indices=False,\n",
       "                                    sampling_strategy='minority')),\n",
       "                 ('model',\n",
       "                  RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                         criterion='gini', max_depth=5,\n",
       "                                         max_features=25, max_leaf_nodes=None,\n",
       "                                         min_impurity_decrease=0.0,\n",
       "                                         min_impurity_split=None,\n",
       "                                         min_samples_leaf=1,\n",
       "                                         min_samples_split=10,\n",
       "                                         min_weight_fraction_leaf=0.0,\n",
       "                                         n_estimators=300, n_jobs=None,\n",
       "                                         oob_score=False, random_state=3,\n",
       "                                         verbose=0, warm_start=False))],\n",
       "          verbose=False),\n",
       " 'best_test_proba': array([[0.49502123, 0.50497877],\n",
       "        [0.92896551, 0.07103449],\n",
       "        [0.69392429, 0.30607571],\n",
       "        [0.73920281, 0.26079719],\n",
       "        [0.90102261, 0.09897739],\n",
       "        [0.89708655, 0.10291345],\n",
       "        [0.79516083, 0.20483917],\n",
       "        [0.94675424, 0.05324576],\n",
       "        [0.74428444, 0.25571556],\n",
       "        [0.10678197, 0.89321803],\n",
       "        [0.65483458, 0.34516542],\n",
       "        [0.44818271, 0.55181729],\n",
       "        [0.84767018, 0.15232982],\n",
       "        [0.96310766, 0.03689234],\n",
       "        [0.73217393, 0.26782607],\n",
       "        [0.58715187, 0.41284813],\n",
       "        [0.28222689, 0.71777311],\n",
       "        [0.80778756, 0.19221244],\n",
       "        [0.43172891, 0.56827109],\n",
       "        [0.78380298, 0.21619702],\n",
       "        [0.96357024, 0.03642976],\n",
       "        [0.29962019, 0.70037981],\n",
       "        [0.70101223, 0.29898777],\n",
       "        [0.93027134, 0.06972866],\n",
       "        [0.76788822, 0.23211178],\n",
       "        [0.86945934, 0.13054066],\n",
       "        [0.84061187, 0.15938813],\n",
       "        [0.65284267, 0.34715733],\n",
       "        [0.65525068, 0.34474932],\n",
       "        [0.61896495, 0.38103505],\n",
       "        [0.50777776, 0.49222224],\n",
       "        [0.79688493, 0.20311507],\n",
       "        [0.7199431 , 0.2800569 ],\n",
       "        [0.92992788, 0.07007212],\n",
       "        [0.16225112, 0.83774888],\n",
       "        [0.62415368, 0.37584632],\n",
       "        [0.85400189, 0.14599811],\n",
       "        [0.92593204, 0.07406796],\n",
       "        [0.84815863, 0.15184137],\n",
       "        [0.47586066, 0.52413934],\n",
       "        [0.94216512, 0.05783488],\n",
       "        [0.72101149, 0.27898851],\n",
       "        [0.86944573, 0.13055427],\n",
       "        [0.80416353, 0.19583647],\n",
       "        [0.23682227, 0.76317773],\n",
       "        [0.36135768, 0.63864232],\n",
       "        [0.89718333, 0.10281667],\n",
       "        [0.54898622, 0.45101378],\n",
       "        [0.83502831, 0.16497169],\n",
       "        [0.9424955 , 0.0575045 ],\n",
       "        [0.27809062, 0.72190938],\n",
       "        [0.58906846, 0.41093154],\n",
       "        [0.73947788, 0.26052212],\n",
       "        [0.65057547, 0.34942453],\n",
       "        [0.83808068, 0.16191932],\n",
       "        [0.62127818, 0.37872182],\n",
       "        [0.89105813, 0.10894187],\n",
       "        [0.6622718 , 0.3377282 ],\n",
       "        [0.87633397, 0.12366603],\n",
       "        [0.85550412, 0.14449588],\n",
       "        [0.82162408, 0.17837592],\n",
       "        [0.89534171, 0.10465829],\n",
       "        [0.13104146, 0.86895854],\n",
       "        [0.77302276, 0.22697724],\n",
       "        [0.35629222, 0.64370778],\n",
       "        [0.60326034, 0.39673966],\n",
       "        [0.81886447, 0.18113553],\n",
       "        [0.86692551, 0.13307449],\n",
       "        [0.89167152, 0.10832848],\n",
       "        [0.45328679, 0.54671321],\n",
       "        [0.682767  , 0.317233  ],\n",
       "        [0.55235886, 0.44764114],\n",
       "        [0.91025607, 0.08974393],\n",
       "        [0.79831505, 0.20168495],\n",
       "        [0.8012494 , 0.1987506 ],\n",
       "        [0.23118404, 0.76881596],\n",
       "        [0.25495382, 0.74504618],\n",
       "        [0.71678721, 0.28321279],\n",
       "        [0.94529476, 0.05470524],\n",
       "        [0.88981168, 0.11018832],\n",
       "        [0.62421739, 0.37578261],\n",
       "        [0.61168507, 0.38831493],\n",
       "        [0.20743923, 0.79256077],\n",
       "        [0.96766711, 0.03233289],\n",
       "        [0.75242586, 0.24757414],\n",
       "        [0.95018903, 0.04981097],\n",
       "        [0.79282738, 0.20717262],\n",
       "        [0.81484374, 0.18515626],\n",
       "        [0.84981922, 0.15018078],\n",
       "        [0.89425384, 0.10574616],\n",
       "        [0.15980912, 0.84019088],\n",
       "        [0.68677937, 0.31322063],\n",
       "        [0.32419593, 0.67580407],\n",
       "        [0.93124382, 0.06875618],\n",
       "        [0.85137077, 0.14862923],\n",
       "        [0.89984738, 0.10015262],\n",
       "        [0.46709908, 0.53290092],\n",
       "        [0.93186259, 0.06813741],\n",
       "        [0.75233112, 0.24766888],\n",
       "        [0.75595053, 0.24404947],\n",
       "        [0.85046658, 0.14953342],\n",
       "        [0.83623845, 0.16376155],\n",
       "        [0.8745743 , 0.1254257 ],\n",
       "        [0.55462603, 0.44537397],\n",
       "        [0.79183252, 0.20816748],\n",
       "        [0.91774258, 0.08225742],\n",
       "        [0.82932833, 0.17067167],\n",
       "        [0.72681662, 0.27318338],\n",
       "        [0.24319431, 0.75680569],\n",
       "        [0.52137644, 0.47862356],\n",
       "        [0.76332905, 0.23667095],\n",
       "        [0.82222371, 0.17777629],\n",
       "        [0.9072269 , 0.0927731 ],\n",
       "        [0.7159952 , 0.2840048 ],\n",
       "        [0.52337348, 0.47662652],\n",
       "        [0.82222175, 0.17777825],\n",
       "        [0.86331034, 0.13668966],\n",
       "        [0.34728622, 0.65271378],\n",
       "        [0.29637931, 0.70362069],\n",
       "        [0.83757957, 0.16242043],\n",
       "        [0.62840026, 0.37159974],\n",
       "        [0.81797685, 0.18202315],\n",
       "        [0.80546549, 0.19453451],\n",
       "        [0.24634689, 0.75365311],\n",
       "        [0.94472594, 0.05527406],\n",
       "        [0.51147026, 0.48852974],\n",
       "        [0.37689099, 0.62310901],\n",
       "        [0.82453743, 0.17546257],\n",
       "        [0.3408911 , 0.6591089 ],\n",
       "        [0.25234936, 0.74765064],\n",
       "        [0.49237824, 0.50762176],\n",
       "        [0.70538587, 0.29461413],\n",
       "        [0.86706405, 0.13293595],\n",
       "        [0.80138376, 0.19861624],\n",
       "        [0.91892922, 0.08107078],\n",
       "        [0.84020373, 0.15979627],\n",
       "        [0.63454806, 0.36545194],\n",
       "        [0.76341492, 0.23658508],\n",
       "        [0.70962995, 0.29037005],\n",
       "        [0.90378874, 0.09621126],\n",
       "        [0.8420128 , 0.1579872 ],\n",
       "        [0.74390137, 0.25609863],\n",
       "        [0.17681054, 0.82318946],\n",
       "        [0.72505352, 0.27494648],\n",
       "        [0.81386805, 0.18613195],\n",
       "        [0.81620781, 0.18379219],\n",
       "        [0.89968724, 0.10031276],\n",
       "        [0.87659773, 0.12340227],\n",
       "        [0.84254145, 0.15745855],\n",
       "        [0.93173593, 0.06826407],\n",
       "        [0.90063789, 0.09936211],\n",
       "        [0.8627592 , 0.1372408 ],\n",
       "        [0.21750411, 0.78249589],\n",
       "        [0.81907468, 0.18092532],\n",
       "        [0.90747417, 0.09252583],\n",
       "        [0.90181324, 0.09818676],\n",
       "        [0.39088322, 0.60911678],\n",
       "        [0.51342147, 0.48657853],\n",
       "        [0.64648844, 0.35351156],\n",
       "        [0.56950976, 0.43049024],\n",
       "        [0.66799114, 0.33200886],\n",
       "        [0.63173696, 0.36826304],\n",
       "        [0.78161749, 0.21838251],\n",
       "        [0.93958132, 0.06041868],\n",
       "        [0.1702922 , 0.8297078 ],\n",
       "        [0.59173569, 0.40826431],\n",
       "        [0.91527257, 0.08472743],\n",
       "        [0.90132079, 0.09867921],\n",
       "        [0.72282083, 0.27717917],\n",
       "        [0.33991444, 0.66008556],\n",
       "        [0.48852545, 0.51147455],\n",
       "        [0.88901532, 0.11098468],\n",
       "        [0.95180966, 0.04819034],\n",
       "        [0.56763102, 0.43236898],\n",
       "        [0.70702455, 0.29297545],\n",
       "        [0.92701659, 0.07298341],\n",
       "        [0.61444832, 0.38555168],\n",
       "        [0.79780147, 0.20219853],\n",
       "        [0.3359588 , 0.6640412 ],\n",
       "        [0.82272585, 0.17727415],\n",
       "        [0.39581543, 0.60418457],\n",
       "        [0.93889789, 0.06110211],\n",
       "        [0.65097368, 0.34902632],\n",
       "        [0.76674899, 0.23325101],\n",
       "        [0.62238177, 0.37761823],\n",
       "        [0.96919163, 0.03080837],\n",
       "        [0.88134518, 0.11865482],\n",
       "        [0.11154658, 0.88845342],\n",
       "        [0.84234561, 0.15765439],\n",
       "        [0.96052486, 0.03947514],\n",
       "        [0.84200602, 0.15799398],\n",
       "        [0.76898418, 0.23101582],\n",
       "        [0.84022219, 0.15977781],\n",
       "        [0.67380753, 0.32619247],\n",
       "        [0.77147184, 0.22852816],\n",
       "        [0.53893076, 0.46106924],\n",
       "        [0.80390397, 0.19609603],\n",
       "        [0.79455654, 0.20544346],\n",
       "        [0.4014522 , 0.5985478 ],\n",
       "        [0.59245443, 0.40754557],\n",
       "        [0.8861228 , 0.1138772 ],\n",
       "        [0.31510249, 0.68489751],\n",
       "        [0.91824243, 0.08175757],\n",
       "        [0.82242078, 0.17757922],\n",
       "        [0.81241406, 0.18758594],\n",
       "        [0.68761734, 0.31238266],\n",
       "        [0.78693518, 0.21306482],\n",
       "        [0.6507231 , 0.3492769 ],\n",
       "        [0.55752469, 0.44247531],\n",
       "        [0.70684069, 0.29315931],\n",
       "        [0.37911687, 0.62088313],\n",
       "        [0.80327413, 0.19672587],\n",
       "        [0.78517031, 0.21482969],\n",
       "        [0.66768885, 0.33231115],\n",
       "        [0.15476917, 0.84523083],\n",
       "        [0.7530261 , 0.2469739 ],\n",
       "        [0.97341281, 0.02658719],\n",
       "        [0.45427874, 0.54572126],\n",
       "        [0.86170847, 0.13829153],\n",
       "        [0.97590758, 0.02409242],\n",
       "        [0.57942662, 0.42057338],\n",
       "        [0.51829878, 0.48170122],\n",
       "        [0.89013732, 0.10986268],\n",
       "        [0.26850331, 0.73149669],\n",
       "        [0.70958927, 0.29041073],\n",
       "        [0.88584009, 0.11415991],\n",
       "        [0.59080344, 0.40919656],\n",
       "        [0.9026934 , 0.0973066 ],\n",
       "        [0.93446919, 0.06553081],\n",
       "        [0.65940752, 0.34059248],\n",
       "        [0.94590187, 0.05409813],\n",
       "        [0.8434513 , 0.1565487 ],\n",
       "        [0.84405672, 0.15594328],\n",
       "        [0.85562908, 0.14437092],\n",
       "        [0.78010882, 0.21989118],\n",
       "        [0.91653148, 0.08346852],\n",
       "        [0.7843198 , 0.2156802 ],\n",
       "        [0.9228925 , 0.0771075 ],\n",
       "        [0.86410817, 0.13589183],\n",
       "        [0.95081388, 0.04918612],\n",
       "        [0.13443138, 0.86556862],\n",
       "        [0.7243946 , 0.2756054 ],\n",
       "        [0.7399291 , 0.2600709 ],\n",
       "        [0.44718571, 0.55281429],\n",
       "        [0.67759952, 0.32240048],\n",
       "        [0.88323531, 0.11676469],\n",
       "        [0.86127235, 0.13872765],\n",
       "        [0.85657867, 0.14342133],\n",
       "        [0.58630944, 0.41369056],\n",
       "        [0.85427784, 0.14572216],\n",
       "        [0.91807465, 0.08192535],\n",
       "        [0.26888113, 0.73111887],\n",
       "        [0.67380695, 0.32619305],\n",
       "        [0.38666205, 0.61333795],\n",
       "        [0.57137996, 0.42862004],\n",
       "        [0.84142635, 0.15857365],\n",
       "        [0.82692156, 0.17307844],\n",
       "        [0.93996626, 0.06003374],\n",
       "        [0.53926185, 0.46073815],\n",
       "        [0.33219613, 0.66780387],\n",
       "        [0.80630009, 0.19369991],\n",
       "        [0.86916939, 0.13083061],\n",
       "        [0.95550896, 0.04449104],\n",
       "        [0.91094179, 0.08905821],\n",
       "        [0.8423553 , 0.1576447 ],\n",
       "        [0.77052551, 0.22947449],\n",
       "        [0.9482181 , 0.0517819 ],\n",
       "        [0.84466858, 0.15533142],\n",
       "        [0.74609989, 0.25390011],\n",
       "        [0.80688975, 0.19311025],\n",
       "        [0.80599077, 0.19400923],\n",
       "        [0.8125708 , 0.1874292 ],\n",
       "        [0.17264647, 0.82735353],\n",
       "        [0.73710452, 0.26289548],\n",
       "        [0.3529724 , 0.6470276 ],\n",
       "        [0.8481899 , 0.1518101 ],\n",
       "        [0.63792925, 0.36207075],\n",
       "        [0.8265669 , 0.1734331 ],\n",
       "        [0.69842168, 0.30157832],\n",
       "        [0.64278575, 0.35721425],\n",
       "        [0.856014  , 0.143986  ],\n",
       "        [0.87225981, 0.12774019],\n",
       "        [0.90333761, 0.09666239],\n",
       "        [0.94734882, 0.05265118],\n",
       "        [0.91023164, 0.08976836],\n",
       "        [0.69527613, 0.30472387],\n",
       "        [0.20529689, 0.79470311],\n",
       "        [0.87399833, 0.12600167],\n",
       "        [0.1526712 , 0.8473288 ],\n",
       "        [0.20369391, 0.79630609],\n",
       "        [0.79953026, 0.20046974],\n",
       "        [0.62353956, 0.37646044],\n",
       "        [0.6688763 , 0.3311237 ],\n",
       "        [0.47706319, 0.52293681],\n",
       "        [0.72789666, 0.27210334],\n",
       "        [0.57826099, 0.42173901],\n",
       "        [0.94114497, 0.05885503],\n",
       "        [0.93048033, 0.06951967],\n",
       "        [0.92002254, 0.07997746],\n",
       "        [0.7610967 , 0.2389033 ],\n",
       "        [0.50128674, 0.49871326],\n",
       "        [0.8710103 , 0.1289897 ],\n",
       "        [0.56141273, 0.43858727],\n",
       "        [0.14861459, 0.85138541],\n",
       "        [0.68668324, 0.31331676],\n",
       "        [0.54320109, 0.45679891],\n",
       "        [0.73324384, 0.26675616],\n",
       "        [0.88097987, 0.11902013],\n",
       "        [0.56908912, 0.43091088],\n",
       "        [0.61504965, 0.38495035],\n",
       "        [0.78933819, 0.21066181],\n",
       "        [0.20305145, 0.79694855],\n",
       "        [0.47410122, 0.52589878],\n",
       "        [0.68728899, 0.31271101],\n",
       "        [0.62190298, 0.37809702],\n",
       "        [0.95531907, 0.04468093],\n",
       "        [0.92006693, 0.07993307],\n",
       "        [0.23265811, 0.76734189],\n",
       "        [0.74108311, 0.25891689],\n",
       "        [0.80393284, 0.19606716],\n",
       "        [0.37063115, 0.62936885],\n",
       "        [0.82265131, 0.17734869],\n",
       "        [0.15140138, 0.84859862],\n",
       "        [0.76497956, 0.23502044],\n",
       "        [0.68487963, 0.31512037],\n",
       "        [0.90426315, 0.09573685],\n",
       "        [0.16048961, 0.83951039],\n",
       "        [0.09777313, 0.90222687],\n",
       "        [0.51882782, 0.48117218],\n",
       "        [0.95783941, 0.04216059],\n",
       "        [0.84839216, 0.15160784],\n",
       "        [0.61098384, 0.38901616],\n",
       "        [0.92018103, 0.07981897],\n",
       "        [0.74660667, 0.25339333],\n",
       "        [0.91917644, 0.08082356],\n",
       "        [0.78243137, 0.21756863],\n",
       "        [0.84235518, 0.15764482],\n",
       "        [0.8402337 , 0.1597663 ],\n",
       "        [0.63003373, 0.36996627],\n",
       "        [0.90443545, 0.09556455],\n",
       "        [0.6865589 , 0.3134411 ],\n",
       "        [0.86172146, 0.13827854],\n",
       "        [0.56883912, 0.43116088],\n",
       "        [0.89916764, 0.10083236],\n",
       "        [0.47664648, 0.52335352],\n",
       "        [0.57945183, 0.42054817],\n",
       "        [0.79468182, 0.20531818],\n",
       "        [0.38526438, 0.61473562],\n",
       "        [0.83256208, 0.16743792],\n",
       "        [0.66965896, 0.33034104],\n",
       "        [0.21498844, 0.78501156],\n",
       "        [0.90848963, 0.09151037],\n",
       "        [0.90640977, 0.09359023],\n",
       "        [0.73731651, 0.26268349],\n",
       "        [0.71287292, 0.28712708],\n",
       "        [0.7829401 , 0.2170599 ],\n",
       "        [0.64840159, 0.35159841],\n",
       "        [0.96519787, 0.03480213],\n",
       "        [0.75343083, 0.24656917],\n",
       "        [0.65105443, 0.34894557]]),\n",
       " 'best_y_hat': array(['purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'purr', 'purr', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps', 'purr',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'purr', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps'], dtype=object),\n",
       " 'all_scores': {'mean_fit_time': array([1.20730124, 1.71856437, 5.14694943, 0.82787828, 1.5440136 ,\n",
       "         5.05938869, 1.60674176, 2.5985415 , 7.32232261, 1.24632449,\n",
       "         2.39283247, 7.21800399, 1.24745836, 2.49464211, 7.44351397,\n",
       "         1.24316192, 2.5337358 , 7.53706627, 0.99942217, 1.91586308,\n",
       "         5.69853644, 0.97456188, 1.95265222, 5.73897219, 1.35754147,\n",
       "         2.70051847, 8.09074445, 1.39067373, 2.71197495, 8.08449473,\n",
       "         1.36369743, 2.71667886, 9.089888  , 1.63900743, 3.13569469,\n",
       "         8.25320172]),\n",
       "  'std_fit_time': array([0.0512917 , 0.17175258, 0.26149715, 0.04558137, 0.02292052,\n",
       "         0.09227434, 0.27826603, 0.06750727, 0.11495119, 0.05811643,\n",
       "         0.02405852, 0.15440013, 0.01970551, 0.03204479, 0.11775079,\n",
       "         0.01281677, 0.03894087, 0.06549883, 0.02051363, 0.00843509,\n",
       "         0.02188103, 0.00686117, 0.02020864, 0.03652668, 0.0228503 ,\n",
       "         0.02274819, 0.10806306, 0.02836684, 0.02889758, 0.12158939,\n",
       "         0.02039877, 0.02100284, 0.22509836, 0.09058111, 0.04285442,\n",
       "         1.38148567]),\n",
       "  'mean_score_time': array([0.0398324 , 0.01948161, 0.05545597, 0.01428246, 0.02185817,\n",
       "         0.04772248, 0.01953306, 0.02348018, 0.05447884, 0.01520653,\n",
       "         0.02105422, 0.0526639 , 0.01403661, 0.02202749, 0.05434399,\n",
       "         0.01427002, 0.02259178, 0.05518003, 0.01364427, 0.02194667,\n",
       "         0.05399432, 0.01380181, 0.02108779, 0.052038  , 0.01584973,\n",
       "         0.02325482, 0.05573764, 0.01570024, 0.02278919, 0.05748801,\n",
       "         0.01639915, 0.02330503, 0.06268058, 0.01910753, 0.025844  ,\n",
       "         0.04619184]),\n",
       "  'std_score_time': array([0.01055518, 0.00031387, 0.00303202, 0.0013354 , 0.00260963,\n",
       "         0.00391814, 0.00819426, 0.00418388, 0.00596952, 0.00296507,\n",
       "         0.0002147 , 0.00080544, 0.000174  , 0.00020311, 0.0007409 ,\n",
       "         0.00019762, 0.00067982, 0.00061919, 0.00044157, 0.00185576,\n",
       "         0.00569446, 0.00044398, 0.0005361 , 0.00220606, 0.00142597,\n",
       "         0.00136261, 0.00111649, 0.00232427, 0.00076815, 0.00404347,\n",
       "         0.00317437, 0.0007275 , 0.00385669, 0.0032793 , 0.00290681,\n",
       "         0.01590037]),\n",
       "  'param_model__bootstrap': masked_array(data=[True, True, True, True, True, True, True, True, True,\n",
       "                     True, True, True, True, True, True, True, True, True,\n",
       "                     True, True, True, True, True, True, True, True, True,\n",
       "                     True, True, True, True, True, True, True, True, True],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                     'gini', 'gini', 'gini', 'gini', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                     'entropy'],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__max_depth': masked_array(data=[5, 5, 5, 5, 5, 5, 50, 50, 50, 50, 50, 50, None, None,\n",
       "                     None, None, None, None, 5, 5, 5, 5, 5, 5, 50, 50, 50,\n",
       "                     50, 50, 50, None, None, None, None, None, None],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__max_features': masked_array(data=[25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "                     25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "                     25, 25, 25, 25, 25, 25, 25, 25],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__min_samples_split': masked_array(data=[2, 2, 2, 10, 10, 10, 2, 2, 2, 10, 10, 10, 2, 2, 2, 10,\n",
       "                     10, 10, 2, 2, 2, 10, 10, 10, 2, 2, 2, 10, 10, 10, 2, 2,\n",
       "                     2, 10, 10, 10],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__n_estimators': masked_array(data=[50, 100, 300, 50, 100, 300, 50, 100, 300, 50, 100, 300,\n",
       "                     50, 100, 300, 50, 100, 300, 50, 100, 300, 50, 100, 300,\n",
       "                     50, 100, 300, 50, 100, 300, 50, 100, 300, 50, 100, 300],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__bootstrap': True,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300}],\n",
       "  'split0_test_score': array([0.89583333, 0.88888889, 0.88888889, 0.88888889, 0.89236111,\n",
       "         0.89583333, 0.87152778, 0.87152778, 0.87847222, 0.88194444,\n",
       "         0.875     , 0.87847222, 0.87152778, 0.87152778, 0.87847222,\n",
       "         0.88194444, 0.875     , 0.87847222, 0.89930556, 0.90277778,\n",
       "         0.89583333, 0.90277778, 0.90625   , 0.89930556, 0.88541667,\n",
       "         0.89236111, 0.89236111, 0.88194444, 0.87847222, 0.88541667,\n",
       "         0.88541667, 0.89236111, 0.89236111, 0.88194444, 0.87847222,\n",
       "         0.88541667]),\n",
       "  'split1_test_score': array([0.91986063, 0.92682927, 0.94076655, 0.92682927, 0.92682927,\n",
       "         0.93379791, 0.91637631, 0.91289199, 0.91637631, 0.92682927,\n",
       "         0.91289199, 0.92334495, 0.91637631, 0.91289199, 0.91637631,\n",
       "         0.92682927, 0.91289199, 0.92334495, 0.90940767, 0.91289199,\n",
       "         0.90940767, 0.91637631, 0.92334495, 0.92682927, 0.93379791,\n",
       "         0.93031359, 0.93379791, 0.93379791, 0.93728223, 0.93379791,\n",
       "         0.93379791, 0.93031359, 0.93379791, 0.93379791, 0.93728223,\n",
       "         0.93379791]),\n",
       "  'split2_test_score': array([0.91986063, 0.91986063, 0.93379791, 0.92334495, 0.93379791,\n",
       "         0.93728223, 0.91289199, 0.91289199, 0.90243902, 0.8989547 ,\n",
       "         0.90592334, 0.90592334, 0.91289199, 0.91289199, 0.90243902,\n",
       "         0.8989547 , 0.90592334, 0.90592334, 0.90940767, 0.91986063,\n",
       "         0.92682927, 0.90940767, 0.91637631, 0.92682927, 0.90592334,\n",
       "         0.90940767, 0.90243902, 0.90940767, 0.90592334, 0.90243902,\n",
       "         0.90592334, 0.90940767, 0.90243902, 0.90940767, 0.90592334,\n",
       "         0.90243902]),\n",
       "  'split3_test_score': array([0.87804878, 0.8815331 , 0.8815331 , 0.87108014, 0.87804878,\n",
       "         0.8815331 , 0.90592334, 0.8989547 , 0.8989547 , 0.90940767,\n",
       "         0.91289199, 0.8989547 , 0.90592334, 0.8989547 , 0.8989547 ,\n",
       "         0.90940767, 0.91289199, 0.8989547 , 0.86062718, 0.86759582,\n",
       "         0.86759582, 0.8641115 , 0.87456446, 0.87108014, 0.91637631,\n",
       "         0.90592334, 0.90592334, 0.91986063, 0.90940767, 0.90940767,\n",
       "         0.91637631, 0.90592334, 0.90592334, 0.91986063, 0.90940767,\n",
       "         0.90940767]),\n",
       "  'split4_test_score': array([0.91289199, 0.91986063, 0.93031359, 0.91289199, 0.91986063,\n",
       "         0.93379791, 0.92682927, 0.93379791, 0.93031359, 0.92334495,\n",
       "         0.92682927, 0.92682927, 0.92682927, 0.93379791, 0.93031359,\n",
       "         0.92334495, 0.92682927, 0.92682927, 0.90592334, 0.92334495,\n",
       "         0.92334495, 0.91637631, 0.92334495, 0.92682927, 0.93379791,\n",
       "         0.93031359, 0.93728223, 0.92334495, 0.93031359, 0.93379791,\n",
       "         0.93379791, 0.93031359, 0.93728223, 0.92334495, 0.93031359,\n",
       "         0.93379791]),\n",
       "  'mean_test_score': array([0.90529248, 0.90738162, 0.91504178, 0.9045961 , 0.91016713,\n",
       "         0.91643454, 0.90668524, 0.90598886, 0.90529248, 0.90807799,\n",
       "         0.90668524, 0.90668524, 0.90668524, 0.90598886, 0.90529248,\n",
       "         0.90807799, 0.90668524, 0.90668524, 0.89693593, 0.90529248,\n",
       "         0.9045961 , 0.90181058, 0.90877437, 0.91016713, 0.91504178,\n",
       "         0.91364903, 0.9143454 , 0.91364903, 0.91225627, 0.91295265,\n",
       "         0.91504178, 0.91364903, 0.9143454 , 0.91364903, 0.91225627,\n",
       "         0.91295265]),\n",
       "  'std_test_score': array([0.01620682, 0.01843798, 0.02471374, 0.02137269, 0.02134556,\n",
       "         0.02315051, 0.01885692, 0.02053467, 0.01742407, 0.01645656,\n",
       "         0.01726166, 0.01755758, 0.01885692, 0.02053467, 0.01742407,\n",
       "         0.01645656, 0.01726166, 0.01755758, 0.01851825, 0.02010895,\n",
       "         0.02151021, 0.01950831, 0.01820961, 0.02225907, 0.01826502,\n",
       "         0.01474508, 0.01789451, 0.01768703, 0.02070956, 0.01871793,\n",
       "         0.01826502, 0.01474508, 0.01789451, 0.01768703, 0.02070956,\n",
       "         0.01871793]),\n",
       "  'rank_test_score': array([29, 20,  2, 33, 15,  1, 21, 27, 29, 18, 21, 21, 21, 27, 29, 18, 21,\n",
       "         21, 36, 29, 33, 35, 17, 15,  2,  7,  5,  7, 13, 11,  2,  7,  5,  7,\n",
       "         13, 11], dtype=int32)}}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_2_cls_scores_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T07:00:45.462798Z",
     "start_time": "2019-10-22T06:52:24.566680Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train and fit Gradient Boosting\n",
    "from src.models import model_sel_grid\n",
    "\n",
    "# Function arguments:\n",
    "model = GradientBoostingClassifier(random_state=3)\n",
    "transformer = RandomOverSampler(random_state=3, sampling_strategy='minority')\n",
    "CV = 5\n",
    "\n",
    "# Function arguments: classifier params\n",
    "n_estimators = [50, 100, 200, 300]\n",
    "max_depth = [5, 10, 50, 100, None]\n",
    "min_samples_split = [2, 5, 10]\n",
    "max_features = [5, 10, 25]\n",
    "\n",
    "                \n",
    "param_grid = dict(model__n_estimators=n_estimators,\n",
    "                  model__max_depth=max_depth,\n",
    "                  model__min_samples_split=min_samples_split,\n",
    "                  model__max_features=max_features,\n",
    "                 )\n",
    "\n",
    "# Call parameter selection function\n",
    "GBM_2_cls_scores_params, GBM_2_cls_models = model_sel_grid.train_fit_time(model,\n",
    "                                                                        param_grid,\n",
    "                                                                        transformer,\n",
    "                                                                        X_train,\n",
    "                                                                        X_test,\n",
    "                                                                        y_train,\n",
    "                                                                        y_test,\n",
    "                                                                        CV)\n",
    "\n",
    "# Pickle results\n",
    "with open('/Users/greenapple/project3/models/GBM_2_cls_scores_params.pkl', 'wb') as f:\n",
    "    pickle.dump(GBM_2_cls_scores_params, f)\n",
    "    \n",
    "# Pickle model\n",
    "with open('/Users/greenapple/project3/models/GBM_2_cls_models.pkl', 'wb') as f:\n",
    "    pickle.dump(GBM_2_cls_models, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T13:09:17.617808Z",
     "start_time": "2019-10-22T13:09:17.000642Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_train_score': 0.9240947075208914,\n",
       " 'best_test_score': 0.9333333333333333,\n",
       " 'time_sec': 494.899637,\n",
       " 'time_best_fit_sec': 0.7078482000000001,\n",
       " 'best_params': {'model__max_depth': 5,\n",
       "  'model__max_features': 5,\n",
       "  'model__min_samples_split': 10,\n",
       "  'model__n_estimators': 300},\n",
       " 'best_estimator': Pipeline(memory=None,\n",
       "          steps=[('transformer',\n",
       "                  RandomOverSampler(random_state=3, ratio=None,\n",
       "                                    return_indices=False,\n",
       "                                    sampling_strategy='minority')),\n",
       "                 ('model',\n",
       "                  GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                                             learning_rate=0.1, loss='deviance',\n",
       "                                             max_depth=5, max_features=5,\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=10,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             n_estimators=300,\n",
       "                                             n_iter_no_change=None,\n",
       "                                             presort='auto', random_state=3,\n",
       "                                             subsample=1.0, tol=0.0001,\n",
       "                                             validation_fraction=0.1, verbose=0,\n",
       "                                             warm_start=False))],\n",
       "          verbose=False),\n",
       " 'best_test_proba': array([[2.26681865e-01, 7.73318135e-01],\n",
       "        [9.99976579e-01, 2.34207561e-05],\n",
       "        [9.97524473e-01, 2.47552745e-03],\n",
       "        [9.99639167e-01, 3.60832926e-04],\n",
       "        [9.99943802e-01, 5.61980114e-05],\n",
       "        [9.99967570e-01, 3.24298111e-05],\n",
       "        [9.99970055e-01, 2.99448570e-05],\n",
       "        [9.99998446e-01, 1.55446570e-06],\n",
       "        [9.98403953e-01, 1.59604740e-03],\n",
       "        [1.47840298e-04, 9.99852160e-01],\n",
       "        [9.97818182e-01, 2.18181835e-03],\n",
       "        [9.80558820e-01, 1.94411805e-02],\n",
       "        [9.99841425e-01, 1.58574682e-04],\n",
       "        [9.99997712e-01, 2.28804836e-06],\n",
       "        [9.98495010e-01, 1.50498995e-03],\n",
       "        [9.94467186e-01, 5.53281387e-03],\n",
       "        [5.08642177e-02, 9.49135782e-01],\n",
       "        [9.99996654e-01, 3.34628875e-06],\n",
       "        [9.54863822e-01, 4.51361782e-02],\n",
       "        [9.92249101e-01, 7.75089916e-03],\n",
       "        [9.99995869e-01, 4.13089328e-06],\n",
       "        [3.30774718e-01, 6.69225282e-01],\n",
       "        [9.99824756e-01, 1.75244316e-04],\n",
       "        [9.99843032e-01, 1.56967737e-04],\n",
       "        [9.99658793e-01, 3.41207246e-04],\n",
       "        [9.99953831e-01, 4.61690752e-05],\n",
       "        [9.99745083e-01, 2.54917007e-04],\n",
       "        [9.93992633e-01, 6.00736718e-03],\n",
       "        [9.99446705e-01, 5.53295394e-04],\n",
       "        [9.74430465e-01, 2.55695354e-02],\n",
       "        [9.15816957e-01, 8.41830427e-02],\n",
       "        [9.99936376e-01, 6.36237217e-05],\n",
       "        [9.99183344e-01, 8.16655977e-04],\n",
       "        [9.99977143e-01, 2.28569003e-05],\n",
       "        [4.43073471e-04, 9.99556927e-01],\n",
       "        [9.99883384e-01, 1.16615793e-04],\n",
       "        [9.99980455e-01, 1.95446261e-05],\n",
       "        [9.99985161e-01, 1.48389780e-05],\n",
       "        [9.99889650e-01, 1.10349879e-04],\n",
       "        [5.61378082e-01, 4.38621918e-01],\n",
       "        [9.99995256e-01, 4.74358323e-06],\n",
       "        [9.99896899e-01, 1.03100834e-04],\n",
       "        [9.99983100e-01, 1.69002565e-05],\n",
       "        [9.99525096e-01, 4.74903627e-04],\n",
       "        [4.93868827e-01, 5.06131173e-01],\n",
       "        [3.20983379e-01, 6.79016621e-01],\n",
       "        [9.99953420e-01, 4.65801084e-05],\n",
       "        [9.41428930e-01, 5.85710701e-02],\n",
       "        [9.99878370e-01, 1.21629826e-04],\n",
       "        [9.99986974e-01, 1.30257031e-05],\n",
       "        [1.41590878e-02, 9.85840912e-01],\n",
       "        [9.87595086e-01, 1.24049144e-02],\n",
       "        [9.97386974e-01, 2.61302632e-03],\n",
       "        [9.98353922e-01, 1.64607797e-03],\n",
       "        [9.99791871e-01, 2.08129243e-04],\n",
       "        [9.95077158e-01, 4.92284223e-03],\n",
       "        [9.99936578e-01, 6.34222971e-05],\n",
       "        [9.99345337e-01, 6.54663258e-04],\n",
       "        [9.99969879e-01, 3.01207490e-05],\n",
       "        [9.99940840e-01, 5.91598749e-05],\n",
       "        [9.99926341e-01, 7.36594396e-05],\n",
       "        [9.99964957e-01, 3.50429571e-05],\n",
       "        [5.63962663e-02, 9.43603734e-01],\n",
       "        [9.99849486e-01, 1.50514419e-04],\n",
       "        [2.14986896e-02, 9.78501310e-01],\n",
       "        [9.83770838e-01, 1.62291623e-02],\n",
       "        [9.98831413e-01, 1.16858737e-03],\n",
       "        [9.99940849e-01, 5.91514900e-05],\n",
       "        [9.99970542e-01, 2.94580067e-05],\n",
       "        [9.74390820e-01, 2.56091798e-02],\n",
       "        [9.99437323e-01, 5.62677464e-04],\n",
       "        [9.96300614e-01, 3.69938591e-03],\n",
       "        [9.99984248e-01, 1.57524797e-05],\n",
       "        [9.99031398e-01, 9.68602113e-04],\n",
       "        [9.99806311e-01, 1.93689319e-04],\n",
       "        [5.32199565e-03, 9.94678004e-01],\n",
       "        [1.46331209e-02, 9.85366879e-01],\n",
       "        [9.96970697e-01, 3.02930287e-03],\n",
       "        [9.99994200e-01, 5.80015270e-06],\n",
       "        [9.99981134e-01, 1.88655527e-05],\n",
       "        [9.98583886e-01, 1.41611401e-03],\n",
       "        [9.99749444e-01, 2.50556349e-04],\n",
       "        [4.58554190e-03, 9.95414458e-01],\n",
       "        [9.99993891e-01, 6.10856802e-06],\n",
       "        [9.99509478e-01, 4.90522088e-04],\n",
       "        [9.99982152e-01, 1.78475857e-05],\n",
       "        [9.99696854e-01, 3.03145512e-04],\n",
       "        [9.99708278e-01, 2.91721651e-04],\n",
       "        [9.99522493e-01, 4.77506529e-04],\n",
       "        [9.99990699e-01, 9.30054898e-06],\n",
       "        [2.31610520e-03, 9.97683895e-01],\n",
       "        [9.98641243e-01, 1.35875732e-03],\n",
       "        [9.30652504e-02, 9.06934750e-01],\n",
       "        [9.99989635e-01, 1.03651527e-05],\n",
       "        [9.99973027e-01, 2.69730350e-05],\n",
       "        [9.99975499e-01, 2.45007127e-05],\n",
       "        [7.56811317e-01, 2.43188683e-01],\n",
       "        [9.99950038e-01, 4.99623633e-05],\n",
       "        [9.99990563e-01, 9.43735769e-06],\n",
       "        [9.99982200e-01, 1.78003907e-05],\n",
       "        [9.99966456e-01, 3.35441955e-05],\n",
       "        [9.99901833e-01, 9.81666724e-05],\n",
       "        [9.99872890e-01, 1.27110090e-04],\n",
       "        [9.20781784e-01, 7.92182157e-02],\n",
       "        [9.99740703e-01, 2.59297249e-04],\n",
       "        [9.99985903e-01, 1.40972715e-05],\n",
       "        [9.99912950e-01, 8.70495587e-05],\n",
       "        [9.99972764e-01, 2.72364461e-05],\n",
       "        [2.35713477e-01, 7.64286523e-01],\n",
       "        [9.95172117e-01, 4.82788336e-03],\n",
       "        [9.99396017e-01, 6.03982986e-04],\n",
       "        [9.98182010e-01, 1.81798986e-03],\n",
       "        [9.99993556e-01, 6.44384922e-06],\n",
       "        [9.99889689e-01, 1.10310758e-04],\n",
       "        [9.15833845e-01, 8.41661547e-02],\n",
       "        [9.99825333e-01, 1.74666914e-04],\n",
       "        [9.99802857e-01, 1.97143402e-04],\n",
       "        [6.03460436e-01, 3.96539564e-01],\n",
       "        [1.83911025e-01, 8.16088975e-01],\n",
       "        [9.99922376e-01, 7.76242764e-05],\n",
       "        [9.98063941e-01, 1.93605855e-03],\n",
       "        [9.99873455e-01, 1.26544660e-04],\n",
       "        [9.98713642e-01, 1.28635753e-03],\n",
       "        [2.46132420e-01, 7.53867580e-01],\n",
       "        [9.99950860e-01, 4.91401702e-05],\n",
       "        [9.53436167e-01, 4.65638328e-02],\n",
       "        [7.05741992e-01, 2.94258008e-01],\n",
       "        [9.99395050e-01, 6.04950151e-04],\n",
       "        [9.25207502e-01, 7.47924983e-02],\n",
       "        [7.57942697e-01, 2.42057303e-01],\n",
       "        [9.26335215e-01, 7.36647851e-02],\n",
       "        [9.98751731e-01, 1.24826909e-03],\n",
       "        [9.99982142e-01, 1.78575574e-05],\n",
       "        [9.99839987e-01, 1.60013345e-04],\n",
       "        [9.99935468e-01, 6.45322624e-05],\n",
       "        [9.99983893e-01, 1.61073781e-05],\n",
       "        [9.88337040e-01, 1.16629595e-02],\n",
       "        [9.99981630e-01, 1.83700684e-05],\n",
       "        [9.99263691e-01, 7.36309447e-04],\n",
       "        [9.99962531e-01, 3.74688528e-05],\n",
       "        [9.99854929e-01, 1.45071313e-04],\n",
       "        [9.99528900e-01, 4.71100444e-04],\n",
       "        [1.57327797e-02, 9.84267220e-01],\n",
       "        [9.99615588e-01, 3.84411570e-04],\n",
       "        [9.99758068e-01, 2.41932343e-04],\n",
       "        [9.98355580e-01, 1.64442040e-03],\n",
       "        [9.99935417e-01, 6.45829844e-05],\n",
       "        [9.99965707e-01, 3.42931172e-05],\n",
       "        [9.99969229e-01, 3.07714184e-05],\n",
       "        [9.99981157e-01, 1.88434250e-05],\n",
       "        [9.99802941e-01, 1.97059284e-04],\n",
       "        [9.99990977e-01, 9.02294382e-06],\n",
       "        [1.68737299e-01, 8.31262701e-01],\n",
       "        [9.99936289e-01, 6.37113429e-05],\n",
       "        [9.99956436e-01, 4.35642839e-05],\n",
       "        [9.99990800e-01, 9.19994265e-06],\n",
       "        [7.88662545e-01, 2.11337455e-01],\n",
       "        [8.54385571e-01, 1.45614429e-01],\n",
       "        [9.99522100e-01, 4.77899521e-04],\n",
       "        [9.88622778e-01, 1.13772215e-02],\n",
       "        [9.98318388e-01, 1.68161243e-03],\n",
       "        [9.99508681e-01, 4.91318678e-04],\n",
       "        [9.99637372e-01, 3.62627951e-04],\n",
       "        [9.99990231e-01, 9.76863166e-06],\n",
       "        [1.31815724e-03, 9.98681843e-01],\n",
       "        [9.99874844e-01, 1.25156083e-04],\n",
       "        [9.99901254e-01, 9.87459270e-05],\n",
       "        [9.99997093e-01, 2.90729967e-06],\n",
       "        [9.99492633e-01, 5.07367069e-04],\n",
       "        [1.96908656e-01, 8.03091344e-01],\n",
       "        [1.27759251e-01, 8.72240749e-01],\n",
       "        [9.99946772e-01, 5.32277923e-05],\n",
       "        [9.99982228e-01, 1.77721613e-05],\n",
       "        [7.53242300e-01, 2.46757700e-01],\n",
       "        [9.85444386e-01, 1.45556137e-02],\n",
       "        [9.99967882e-01, 3.21176821e-05],\n",
       "        [9.94261289e-01, 5.73871104e-03],\n",
       "        [9.99719444e-01, 2.80555691e-04],\n",
       "        [5.99292480e-01, 4.00707520e-01],\n",
       "        [9.99961976e-01, 3.80242511e-05],\n",
       "        [9.11942648e-01, 8.80573520e-02],\n",
       "        [9.99974556e-01, 2.54440435e-05],\n",
       "        [9.95125897e-01, 4.87410308e-03],\n",
       "        [9.99659873e-01, 3.40126959e-04],\n",
       "        [9.99146463e-01, 8.53536993e-04],\n",
       "        [9.99995896e-01, 4.10449230e-06],\n",
       "        [9.99926664e-01, 7.33360934e-05],\n",
       "        [6.38234045e-05, 9.99936177e-01],\n",
       "        [9.99319620e-01, 6.80379674e-04],\n",
       "        [9.99993751e-01, 6.24863865e-06],\n",
       "        [9.99903372e-01, 9.66284357e-05],\n",
       "        [9.99789464e-01, 2.10536082e-04],\n",
       "        [9.99992315e-01, 7.68517091e-06],\n",
       "        [9.94771269e-01, 5.22873091e-03],\n",
       "        [9.99974067e-01, 2.59325400e-05],\n",
       "        [9.75650125e-01, 2.43498752e-02],\n",
       "        [9.99883818e-01, 1.16181736e-04],\n",
       "        [9.99761503e-01, 2.38497429e-04],\n",
       "        [3.85554834e-01, 6.14445166e-01],\n",
       "        [9.89612626e-01, 1.03873740e-02],\n",
       "        [9.99978160e-01, 2.18396023e-05],\n",
       "        [1.95475692e-02, 9.80452431e-01],\n",
       "        [9.99953206e-01, 4.67940520e-05],\n",
       "        [9.99950064e-01, 4.99363150e-05],\n",
       "        [9.99910589e-01, 8.94105071e-05],\n",
       "        [9.97951125e-01, 2.04887538e-03],\n",
       "        [9.99213251e-01, 7.86748736e-04],\n",
       "        [9.66854785e-01, 3.31452155e-02],\n",
       "        [9.91051061e-01, 8.94893928e-03],\n",
       "        [9.99401449e-01, 5.98551328e-04],\n",
       "        [3.76450673e-01, 6.23549327e-01],\n",
       "        [9.99748766e-01, 2.51234106e-04],\n",
       "        [9.99901700e-01, 9.83001391e-05],\n",
       "        [9.93715284e-01, 6.28471650e-03],\n",
       "        [2.36691343e-02, 9.76330866e-01],\n",
       "        [9.99327965e-01, 6.72034501e-04],\n",
       "        [9.99991957e-01, 8.04330372e-06],\n",
       "        [2.44511485e-01, 7.55488515e-01],\n",
       "        [9.99905953e-01, 9.40465432e-05],\n",
       "        [9.99997609e-01, 2.39132924e-06],\n",
       "        [9.97561426e-01, 2.43857388e-03],\n",
       "        [8.10269073e-01, 1.89730927e-01],\n",
       "        [9.99958112e-01, 4.18878339e-05],\n",
       "        [1.38163472e-01, 8.61836528e-01],\n",
       "        [9.99537956e-01, 4.62044270e-04],\n",
       "        [9.99881756e-01, 1.18243776e-04],\n",
       "        [9.94818432e-01, 5.18156782e-03],\n",
       "        [9.99983088e-01, 1.69124530e-05],\n",
       "        [9.99990228e-01, 9.77185725e-06],\n",
       "        [9.99697267e-01, 3.02732730e-04],\n",
       "        [9.99994551e-01, 5.44890708e-06],\n",
       "        [9.99887535e-01, 1.12465396e-04],\n",
       "        [9.99931104e-01, 6.88963794e-05],\n",
       "        [9.99898769e-01, 1.01230679e-04],\n",
       "        [9.99594170e-01, 4.05829691e-04],\n",
       "        [9.99985548e-01, 1.44515630e-05],\n",
       "        [9.99265011e-01, 7.34988553e-04],\n",
       "        [9.99964992e-01, 3.50077008e-05],\n",
       "        [9.99941279e-01, 5.87210091e-05],\n",
       "        [9.99993986e-01, 6.01420109e-06],\n",
       "        [8.07753801e-04, 9.99192246e-01],\n",
       "        [9.99847795e-01, 1.52205165e-04],\n",
       "        [9.98999342e-01, 1.00065817e-03],\n",
       "        [9.87671004e-02, 9.01232900e-01],\n",
       "        [9.93841322e-01, 6.15867783e-03],\n",
       "        [9.99933948e-01, 6.60518999e-05],\n",
       "        [9.99943338e-01, 5.66620412e-05],\n",
       "        [9.99905177e-01, 9.48233399e-05],\n",
       "        [6.89248382e-01, 3.10751618e-01],\n",
       "        [9.99956722e-01, 4.32780041e-05],\n",
       "        [9.99981012e-01, 1.89881230e-05],\n",
       "        [1.05677291e-01, 8.94322709e-01],\n",
       "        [9.99510945e-01, 4.89055108e-04],\n",
       "        [7.75922834e-01, 2.24077166e-01],\n",
       "        [9.82559402e-01, 1.74405976e-02],\n",
       "        [9.99962553e-01, 3.74466730e-05],\n",
       "        [9.99918234e-01, 8.17660111e-05],\n",
       "        [9.99966704e-01, 3.32955763e-05],\n",
       "        [9.96222706e-01, 3.77729443e-03],\n",
       "        [4.57932738e-01, 5.42067262e-01],\n",
       "        [9.99581099e-01, 4.18900820e-04],\n",
       "        [9.99806455e-01, 1.93544885e-04],\n",
       "        [9.99998675e-01, 1.32474700e-06],\n",
       "        [9.99901042e-01, 9.89575701e-05],\n",
       "        [9.99862028e-01, 1.37971560e-04],\n",
       "        [9.98710135e-01, 1.28986542e-03],\n",
       "        [9.99973041e-01, 2.69586179e-05],\n",
       "        [9.94557272e-01, 5.44272797e-03],\n",
       "        [9.99708308e-01, 2.91691708e-04],\n",
       "        [9.99228596e-01, 7.71404076e-04],\n",
       "        [9.99975377e-01, 2.46232308e-05],\n",
       "        [9.99853776e-01, 1.46223635e-04],\n",
       "        [1.60087764e-03, 9.98399122e-01],\n",
       "        [9.98373174e-01, 1.62682607e-03],\n",
       "        [7.62902359e-01, 2.37097641e-01],\n",
       "        [9.99847460e-01, 1.52540283e-04],\n",
       "        [9.80104961e-01, 1.98950388e-02],\n",
       "        [9.95980698e-01, 4.01930209e-03],\n",
       "        [9.99163072e-01, 8.36927672e-04],\n",
       "        [9.90704232e-01, 9.29576798e-03],\n",
       "        [9.99979064e-01, 2.09361034e-05],\n",
       "        [9.99993126e-01, 6.87432771e-06],\n",
       "        [9.99969557e-01, 3.04434962e-05],\n",
       "        [9.99890478e-01, 1.09521796e-04],\n",
       "        [9.99994880e-01, 5.12032571e-06],\n",
       "        [9.98792659e-01, 1.20734095e-03],\n",
       "        [7.51524306e-03, 9.92484757e-01],\n",
       "        [9.99942707e-01, 5.72934804e-05],\n",
       "        [2.62077751e-03, 9.97379222e-01],\n",
       "        [1.53579652e-03, 9.98464203e-01],\n",
       "        [9.99590930e-01, 4.09069634e-04],\n",
       "        [9.98785146e-01, 1.21485415e-03],\n",
       "        [9.98575020e-01, 1.42498036e-03],\n",
       "        [8.99393469e-01, 1.00606531e-01],\n",
       "        [9.98957628e-01, 1.04237248e-03],\n",
       "        [9.99686966e-01, 3.13033511e-04],\n",
       "        [9.99958327e-01, 4.16731543e-05],\n",
       "        [9.99937746e-01, 6.22536997e-05],\n",
       "        [9.99920477e-01, 7.95231871e-05],\n",
       "        [9.97536429e-01, 2.46357058e-03],\n",
       "        [9.85301568e-01, 1.46984325e-02],\n",
       "        [9.99966276e-01, 3.37242987e-05],\n",
       "        [9.92679034e-01, 7.32096582e-03],\n",
       "        [4.16485910e-04, 9.99583514e-01],\n",
       "        [9.99288418e-01, 7.11581978e-04],\n",
       "        [9.61952619e-01, 3.80473811e-02],\n",
       "        [9.99979772e-01, 2.02276334e-05],\n",
       "        [9.99916446e-01, 8.35539309e-05],\n",
       "        [9.76877147e-01, 2.31228527e-02],\n",
       "        [9.88569470e-01, 1.14305298e-02],\n",
       "        [9.97804073e-01, 2.19592715e-03],\n",
       "        [2.09316490e-04, 9.99790684e-01],\n",
       "        [8.81932343e-01, 1.18067657e-01],\n",
       "        [9.98474402e-01, 1.52559834e-03],\n",
       "        [9.98329344e-01, 1.67065617e-03],\n",
       "        [9.99995625e-01, 4.37471169e-06],\n",
       "        [9.99627097e-01, 3.72903311e-04],\n",
       "        [3.09274831e-03, 9.96907252e-01],\n",
       "        [9.99936327e-01, 6.36733650e-05],\n",
       "        [9.99970208e-01, 2.97924097e-05],\n",
       "        [4.17636146e-02, 9.58236385e-01],\n",
       "        [9.99944184e-01, 5.58161116e-05],\n",
       "        [5.15050258e-04, 9.99484950e-01],\n",
       "        [9.98254798e-01, 1.74520206e-03],\n",
       "        [9.99421777e-01, 5.78223244e-04],\n",
       "        [9.99949669e-01, 5.03305005e-05],\n",
       "        [1.15733121e-04, 9.99884267e-01],\n",
       "        [3.99695575e-04, 9.99600304e-01],\n",
       "        [9.52987787e-01, 4.70122128e-02],\n",
       "        [9.99990405e-01, 9.59547644e-06],\n",
       "        [9.99928729e-01, 7.12706950e-05],\n",
       "        [9.92532216e-01, 7.46778380e-03],\n",
       "        [9.99980058e-01, 1.99416689e-05],\n",
       "        [9.99908476e-01, 9.15238486e-05],\n",
       "        [9.99995846e-01, 4.15424645e-06],\n",
       "        [9.99873386e-01, 1.26614053e-04],\n",
       "        [9.99980168e-01, 1.98320314e-05],\n",
       "        [9.99947408e-01, 5.25924999e-05],\n",
       "        [9.97049923e-01, 2.95007664e-03],\n",
       "        [9.99988108e-01, 1.18923651e-05],\n",
       "        [9.99191162e-01, 8.08837741e-04],\n",
       "        [9.99913548e-01, 8.64515738e-05],\n",
       "        [9.97224884e-01, 2.77511568e-03],\n",
       "        [9.99893730e-01, 1.06270202e-04],\n",
       "        [9.79003068e-01, 2.09969321e-02],\n",
       "        [9.99270455e-01, 7.29545377e-04],\n",
       "        [9.90808398e-01, 9.19160227e-03],\n",
       "        [2.43174113e-01, 7.56825887e-01],\n",
       "        [9.99429383e-01, 5.70617085e-04],\n",
       "        [9.80977015e-01, 1.90229854e-02],\n",
       "        [3.85476011e-01, 6.14523989e-01],\n",
       "        [9.99982240e-01, 1.77600065e-05],\n",
       "        [9.99939890e-01, 6.01102053e-05],\n",
       "        [9.99796143e-01, 2.03856731e-04],\n",
       "        [9.99319730e-01, 6.80270187e-04],\n",
       "        [9.99574485e-01, 4.25514802e-04],\n",
       "        [9.98901598e-01, 1.09840192e-03],\n",
       "        [9.99999727e-01, 2.73002927e-07],\n",
       "        [9.97764947e-01, 2.23505337e-03],\n",
       "        [9.94818790e-01, 5.18121046e-03]]),\n",
       " 'best_y_hat': array(['purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'purr', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'purr', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps'], dtype=object),\n",
       " 'all_scores': {'mean_fit_time': array([0.50647612, 0.74733973, 1.32972164, 1.49882946, 0.44123955,\n",
       "         0.76322551, 1.41007643, 1.54608541, 0.43658504, 0.74313431,\n",
       "         1.30399685, 1.47330465, 0.58061461, 1.03043232, 1.86013656,\n",
       "         1.95319238, 0.58971186, 1.02365971, 1.84755321, 1.93126493,\n",
       "         0.60281701, 1.02249947, 1.83189998, 1.90339293, 1.00545602,\n",
       "         1.8911582 , 3.00955925, 3.07369604, 0.9972671 , 1.85513086,\n",
       "         2.98461194, 3.04399862, 1.01318998, 1.84769053, 2.96045079,\n",
       "         2.95977187, 1.75066171, 2.54569626, 2.60737724, 2.69416285,\n",
       "         1.42331009, 2.11434779, 2.2088582 , 2.23285823, 1.12741385,\n",
       "         1.76917315, 1.84604568, 1.89833446, 2.06603165, 2.92015314,\n",
       "         2.99992967, 3.01946559, 1.74380479, 2.49461799, 2.57902246,\n",
       "         2.6148191 , 1.4630187 , 2.19503722, 2.23720617, 2.30953884,\n",
       "         3.01390557, 4.16582751, 4.27138166, 4.31324492, 2.64599667,\n",
       "         3.73256288, 3.78887916, 3.85881991, 2.37933407, 3.51828899,\n",
       "         3.54761014, 3.61367025, 0.97054577, 1.31118441, 1.37958741,\n",
       "         1.42889214, 1.28968182, 1.67472701, 1.72600565, 1.77271276,\n",
       "         1.66380806, 2.1416543 , 2.18318238, 2.24727454, 1.18922243,\n",
       "         1.60444803, 1.6637888 , 1.71553602, 1.46828136, 1.91763635,\n",
       "         1.96418438, 2.04651771, 2.01046996, 2.50301504, 2.61280351,\n",
       "         2.63060808, 1.9286808 , 2.64588332, 2.6904355 , 2.75232754,\n",
       "         2.28566799, 2.98827219, 3.05580978, 3.13946939, 3.13905926,\n",
       "         4.00365562, 4.02578497, 4.09483137, 0.96581984, 1.31039352,\n",
       "         1.37754722, 1.44000497, 1.32284174, 1.67831168, 1.70229721,\n",
       "         1.79850264, 1.65740438, 2.12452741, 2.17668366, 2.21918716,\n",
       "         1.16270757, 1.60220275, 1.67733035, 1.7160418 , 1.49268622,\n",
       "         1.91606231, 2.00877056, 2.01720295, 1.9983294 , 2.51408   ,\n",
       "         2.61922393, 2.65357776, 1.93178453, 2.63076711, 2.68335967,\n",
       "         2.75419664, 2.30078988, 3.00404463, 3.06440978, 3.1088223 ,\n",
       "         3.14189854, 4.03382711, 4.05269332, 4.12916827, 0.98537774,\n",
       "         1.31970348, 1.37740078, 1.43782277, 1.30646262, 1.66970382,\n",
       "         1.76160178, 1.80503702, 1.68182855, 2.13659234, 2.19339461,\n",
       "         2.22791529, 1.16827049, 1.64089351, 1.68817983, 1.73835959,\n",
       "         1.47351584, 1.91510048, 1.98093209, 2.03484626, 1.99612699,\n",
       "         2.54097133, 2.59243679, 2.62836885, 1.93048997, 2.68225641,\n",
       "         2.71040816, 2.79660449, 2.27475905, 3.00303702, 3.09678397,\n",
       "         3.13975768, 3.14400296, 4.042483  , 4.05657501, 3.648666  ]),\n",
       "  'std_fit_time': array([0.02690157, 0.01553948, 0.0193207 , 0.03541278, 0.00273738,\n",
       "         0.04672794, 0.03699132, 0.04332561, 0.01210547, 0.01849843,\n",
       "         0.01635357, 0.02365992, 0.00882787, 0.00616449, 0.02601753,\n",
       "         0.06512188, 0.01356445, 0.00720392, 0.03595994, 0.04401742,\n",
       "         0.02782793, 0.00562107, 0.03311304, 0.03280879, 0.00945653,\n",
       "         0.02626401, 0.056764  , 0.0523125 , 0.00633375, 0.02006588,\n",
       "         0.06584981, 0.06499419, 0.02141323, 0.03384998, 0.06443284,\n",
       "         0.06639964, 0.04899605, 0.04006951, 0.03347726, 0.05244409,\n",
       "         0.01588851, 0.05432678, 0.03817563, 0.02482326, 0.01015824,\n",
       "         0.01672111, 0.01762583, 0.01552818, 0.02241032, 0.05363534,\n",
       "         0.07041961, 0.06053715, 0.03378189, 0.06310829, 0.06934063,\n",
       "         0.06263463, 0.00704007, 0.0237162 , 0.03388052, 0.03223798,\n",
       "         0.08480161, 0.14052036, 0.18641832, 0.13301244, 0.04750345,\n",
       "         0.11437246, 0.09162003, 0.1051054 , 0.02980386, 0.04847826,\n",
       "         0.06140031, 0.06812619, 0.0208502 , 0.03198507, 0.03807636,\n",
       "         0.0229807 , 0.02639611, 0.04437559, 0.01861533, 0.01799486,\n",
       "         0.01787589, 0.02205183, 0.0271062 , 0.04012817, 0.00990873,\n",
       "         0.02458879, 0.01934639, 0.02813956, 0.02680919, 0.04542201,\n",
       "         0.03072094, 0.0219623 , 0.01755903, 0.03455039, 0.01345515,\n",
       "         0.02927626, 0.06659509, 0.05582761, 0.07558852, 0.06732826,\n",
       "         0.0401972 , 0.04250914, 0.06573719, 0.07857987, 0.05719596,\n",
       "         0.0683837 , 0.07372994, 0.08600079, 0.01636011, 0.01316474,\n",
       "         0.03215997, 0.02512906, 0.04521039, 0.02421285, 0.01159787,\n",
       "         0.02395239, 0.02435078, 0.0247986 , 0.02666136, 0.04222166,\n",
       "         0.01381289, 0.03817829, 0.02394533, 0.01341573, 0.03978666,\n",
       "         0.03356845, 0.04063616, 0.0386798 , 0.01820413, 0.02482589,\n",
       "         0.01413705, 0.01494106, 0.05351223, 0.07237748, 0.07418313,\n",
       "         0.07281889, 0.04430167, 0.04664972, 0.05104796, 0.04899552,\n",
       "         0.06805643, 0.09747125, 0.0680817 , 0.05762277, 0.01521746,\n",
       "         0.03681703, 0.02114616, 0.01414836, 0.02144531, 0.02408589,\n",
       "         0.0318943 , 0.02077372, 0.0220018 , 0.02957993, 0.03155163,\n",
       "         0.03821397, 0.01421107, 0.01081721, 0.02157451, 0.04254449,\n",
       "         0.03295172, 0.03710259, 0.02415241, 0.031498  , 0.01377598,\n",
       "         0.03587891, 0.02628315, 0.01693429, 0.055583  , 0.04481909,\n",
       "         0.09974168, 0.05454876, 0.05117137, 0.06467255, 0.05913778,\n",
       "         0.07392794, 0.06978612, 0.07616038, 0.09661674, 0.42641084]),\n",
       "  'mean_score_time': array([0.0074255 , 0.00938907, 0.01085405, 0.01112819, 0.00735235,\n",
       "         0.00913496, 0.01060977, 0.01171813, 0.00744038, 0.00847054,\n",
       "         0.01042643, 0.00997171, 0.00757418, 0.00833974, 0.01073456,\n",
       "         0.01088576, 0.007763  , 0.00841231, 0.0107903 , 0.01012049,\n",
       "         0.00734582, 0.00831814, 0.01116076, 0.01043067, 0.00775023,\n",
       "         0.00872769, 0.00988107, 0.01136274, 0.00809398, 0.00866013,\n",
       "         0.01011963, 0.01001163, 0.00764303, 0.00876803, 0.00979705,\n",
       "         0.0099709 , 0.00918913, 0.01060872, 0.01092253, 0.01264172,\n",
       "         0.00899453, 0.01137981, 0.010466  , 0.01189909, 0.00874004,\n",
       "         0.01210365, 0.01049476, 0.01081901, 0.00923033, 0.01033711,\n",
       "         0.01047382, 0.01094708, 0.00879111, 0.01140418, 0.01026611,\n",
       "         0.01048002, 0.00897632, 0.01060853, 0.01022048, 0.01046705,\n",
       "         0.00884418, 0.00981402, 0.01032324, 0.01034303, 0.00857344,\n",
       "         0.00980611, 0.00987635, 0.01095562, 0.00863562, 0.00982289,\n",
       "         0.00989819, 0.01015687, 0.0087173 , 0.00943584, 0.01079297,\n",
       "         0.00973063, 0.00898161, 0.00977879, 0.01079197, 0.01011205,\n",
       "         0.0093472 , 0.01040797, 0.01054201, 0.01090674, 0.00839162,\n",
       "         0.01076713, 0.00925784, 0.00952926, 0.00870657, 0.00950165,\n",
       "         0.00988784, 0.00990601, 0.00908284, 0.0100873 , 0.01190214,\n",
       "         0.01035337, 0.0083281 , 0.00907235, 0.0092185 , 0.00948949,\n",
       "         0.00839324, 0.00929632, 0.00916181, 0.0095706 , 0.00902486,\n",
       "         0.00994172, 0.00995116, 0.01044989, 0.0081202 , 0.00935421,\n",
       "         0.00948706, 0.00968661, 0.00892057, 0.00997071, 0.00991678,\n",
       "         0.01016231, 0.00937486, 0.0103477 , 0.01070781, 0.01059279,\n",
       "         0.0082808 , 0.00912414, 0.00931668, 0.00965323, 0.00867858,\n",
       "         0.00951838, 0.01153622, 0.01108775, 0.00908031, 0.0100327 ,\n",
       "         0.01026421, 0.01059551, 0.00808382, 0.00887284, 0.00945129,\n",
       "         0.00924931, 0.00848918, 0.00923901, 0.01018524, 0.00958581,\n",
       "         0.00902953, 0.00984173, 0.01006203, 0.00961895, 0.00843267,\n",
       "         0.00935183, 0.0096992 , 0.00994253, 0.00894737, 0.00973821,\n",
       "         0.01025524, 0.01020379, 0.00993142, 0.01143904, 0.01043258,\n",
       "         0.01075807, 0.00836353, 0.00970125, 0.00943503, 0.00950799,\n",
       "         0.00883698, 0.00937381, 0.00964212, 0.01065116, 0.00955186,\n",
       "         0.01060286, 0.01032853, 0.01052718, 0.00960927, 0.00926895,\n",
       "         0.00916028, 0.01018195, 0.00963755, 0.01042762, 0.00943666,\n",
       "         0.00949922, 0.00925198, 0.00960999, 0.01006899, 0.01117363]),\n",
       "  'std_score_time': array([4.30780120e-04, 1.70169581e-03, 1.51595382e-03, 1.29438688e-03,\n",
       "         2.77373474e-04, 2.48507797e-03, 2.48593719e-04, 2.28492749e-03,\n",
       "         3.44343271e-04, 2.33791707e-04, 2.17068279e-04, 6.93889553e-04,\n",
       "         5.21171160e-04, 3.35744852e-04, 2.71100775e-04, 1.61737428e-03,\n",
       "         6.77879469e-04, 1.98468733e-04, 1.99726100e-04, 1.89732936e-04,\n",
       "         1.98674967e-04, 4.69153472e-04, 4.65173249e-04, 2.06925604e-04,\n",
       "         3.40571085e-04, 5.33975867e-05, 4.37475846e-04, 3.24194642e-03,\n",
       "         1.86857911e-04, 2.24499644e-04, 4.94287232e-04, 3.26943821e-04,\n",
       "         1.84188955e-04, 3.62605154e-04, 2.40869485e-04, 3.61604925e-04,\n",
       "         2.90520058e-04, 2.26675536e-04, 8.30604068e-05, 3.59761897e-03,\n",
       "         4.23788991e-04, 2.01568145e-03, 1.24014115e-04, 2.00377053e-03,\n",
       "         1.31720912e-04, 3.88949569e-03, 2.36606982e-04, 4.15526346e-04,\n",
       "         3.00887474e-04, 1.59896447e-04, 1.62153354e-04, 6.67698296e-04,\n",
       "         2.74305713e-04, 2.14368140e-03, 2.84617042e-04, 8.49156613e-05,\n",
       "         4.72649775e-04, 1.03841846e-03, 1.09745851e-04, 2.11818183e-04,\n",
       "         1.58726434e-04, 2.81478554e-04, 5.90509665e-04, 1.07310547e-04,\n",
       "         2.68473066e-04, 2.69076230e-04, 3.44178009e-05, 1.47001923e-03,\n",
       "         2.17389511e-04, 3.40074210e-04, 2.31273592e-04, 1.68350396e-04,\n",
       "         6.75739378e-04, 1.60346263e-04, 2.18935143e-03, 2.01265299e-04,\n",
       "         1.36527364e-04, 2.62677139e-04, 1.39384100e-03, 1.38789760e-04,\n",
       "         3.32382692e-04, 2.95077506e-04, 1.77885481e-04, 2.12992777e-04,\n",
       "         2.59346685e-04, 2.20872341e-03, 1.81488344e-04, 1.46708978e-04,\n",
       "         4.06046650e-04, 9.34130443e-05, 5.55712693e-04, 4.87851847e-04,\n",
       "         2.37444385e-04, 7.13274756e-05, 3.23055061e-03, 1.47761395e-04,\n",
       "         4.20700013e-04, 2.46666272e-04, 3.00547075e-04, 3.09809046e-04,\n",
       "         1.50495231e-04, 2.45742349e-04, 2.25658650e-04, 2.62762067e-04,\n",
       "         2.56922985e-04, 2.85013136e-04, 8.61600543e-05, 3.77783037e-04,\n",
       "         1.14036127e-03, 1.82649833e-04, 1.33423400e-04, 1.64103465e-04,\n",
       "         7.65409940e-05, 2.20367825e-04, 1.77566500e-04, 3.34720917e-04,\n",
       "         3.38605689e-04, 1.24522406e-04, 1.44823334e-04, 8.09079833e-05,\n",
       "         2.23177742e-04, 2.92176598e-04, 1.35179508e-04, 1.42582252e-04,\n",
       "         8.30631442e-05, 3.99847306e-04, 3.77352232e-03, 2.42628311e-03,\n",
       "         2.07382593e-04, 1.70945117e-04, 1.32519592e-04, 1.00297615e-04,\n",
       "         9.84892116e-05, 1.87852938e-04, 3.58030779e-04, 4.51168593e-05,\n",
       "         3.27791972e-04, 1.42457158e-04, 1.59959147e-03, 1.52009628e-04,\n",
       "         9.33791073e-05, 2.60284453e-04, 2.10178893e-04, 1.05313544e-03,\n",
       "         1.24238400e-04, 9.20018466e-05, 2.12290966e-04, 3.09030911e-04,\n",
       "         2.40797430e-04, 1.54601387e-04, 7.52888072e-04, 1.33848912e-04,\n",
       "         9.63028518e-04, 2.02742587e-03, 2.19464871e-04, 2.53198178e-04,\n",
       "         1.28231380e-04, 5.77023382e-04, 2.19224897e-04, 1.59038139e-04,\n",
       "         1.13446365e-04, 9.78639701e-05, 1.82920042e-04, 1.12277495e-03,\n",
       "         3.06563411e-04, 7.60855520e-04, 1.42090752e-04, 1.28124769e-04,\n",
       "         2.13701193e-03, 3.38867922e-04, 2.61549202e-04, 1.40015608e-03,\n",
       "         1.39591414e-03, 1.97654940e-03, 2.42252021e-04, 9.63736853e-05,\n",
       "         3.45723928e-04, 3.68211091e-04, 1.05145740e-04, 7.95095715e-03]),\n",
       "  'param_model__max_depth': masked_array(data=[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                     5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                     10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                     10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                     10, 10, 10, 10, 10, 10, 10, 10, 50, 50, 50, 50, 50, 50,\n",
       "                     50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                     50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                     50, 50, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                     100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                     100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                     100, 100, 100, 100, 100, None, None, None, None, None,\n",
       "                     None, None, None, None, None, None, None, None, None,\n",
       "                     None, None, None, None, None, None, None, None, None,\n",
       "                     None, None, None, None, None, None, None, None, None,\n",
       "                     None, None, None, None],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__max_features': masked_array(data=[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10,\n",
       "                     10, 10, 10, 10, 10, 10, 10, 25, 25, 25, 25, 25, 25, 25,\n",
       "                     25, 25, 25, 25, 25, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                     10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 25, 25,\n",
       "                     25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 5, 5, 5, 5, 5,\n",
       "                     5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                     10, 10, 10, 10, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "                     25, 25, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10,\n",
       "                     10, 10, 10, 10, 10, 10, 10, 10, 10, 25, 25, 25, 25, 25,\n",
       "                     25, 25, 25, 25, 25, 25, 25, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                     5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                     10, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__min_samples_split': masked_array(data=[2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 2, 2, 2, 2, 5,\n",
       "                     5, 5, 5, 10, 10, 10, 10, 2, 2, 2, 2, 5, 5, 5, 5, 10,\n",
       "                     10, 10, 10, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 2,\n",
       "                     2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 2, 2, 2, 2, 5, 5,\n",
       "                     5, 5, 10, 10, 10, 10, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10,\n",
       "                     10, 10, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 2, 2,\n",
       "                     2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 2, 2, 2, 2, 5, 5, 5,\n",
       "                     5, 10, 10, 10, 10, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10,\n",
       "                     10, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 2, 2, 2, 2,\n",
       "                     5, 5, 5, 5, 10, 10, 10, 10, 2, 2, 2, 2, 5, 5, 5, 5, 10,\n",
       "                     10, 10, 10, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__n_estimators': masked_array(data=[50, 100, 200, 300, 50, 100, 200, 300, 50, 100, 200,\n",
       "                     300, 50, 100, 200, 300, 50, 100, 200, 300, 50, 100,\n",
       "                     200, 300, 50, 100, 200, 300, 50, 100, 200, 300, 50,\n",
       "                     100, 200, 300, 50, 100, 200, 300, 50, 100, 200, 300,\n",
       "                     50, 100, 200, 300, 50, 100, 200, 300, 50, 100, 200,\n",
       "                     300, 50, 100, 200, 300, 50, 100, 200, 300, 50, 100,\n",
       "                     200, 300, 50, 100, 200, 300, 50, 100, 200, 300, 50,\n",
       "                     100, 200, 300, 50, 100, 200, 300, 50, 100, 200, 300,\n",
       "                     50, 100, 200, 300, 50, 100, 200, 300, 50, 100, 200,\n",
       "                     300, 50, 100, 200, 300, 50, 100, 200, 300, 50, 100,\n",
       "                     200, 300, 50, 100, 200, 300, 50, 100, 200, 300, 50,\n",
       "                     100, 200, 300, 50, 100, 200, 300, 50, 100, 200, 300,\n",
       "                     50, 100, 200, 300, 50, 100, 200, 300, 50, 100, 200,\n",
       "                     300, 50, 100, 200, 300, 50, 100, 200, 300, 50, 100,\n",
       "                     200, 300, 50, 100, 200, 300, 50, 100, 200, 300, 50,\n",
       "                     100, 200, 300, 50, 100, 200, 300, 50, 100, 200, 300,\n",
       "                     50, 100, 200, 300],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__max_depth': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__max_depth': 5,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__max_depth': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__max_depth': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__max_depth': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__max_depth': 50,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__max_depth': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__max_depth': 100,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__max_depth': 100,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__max_depth': 100,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__max_depth': None,\n",
       "    'model__max_features': 5,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__max_depth': None,\n",
       "    'model__max_features': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 200},\n",
       "   {'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300}],\n",
       "  'split0_test_score': array([0.88194444, 0.89236111, 0.89583333, 0.89583333, 0.89236111,\n",
       "         0.88194444, 0.88194444, 0.88888889, 0.88888889, 0.90625   ,\n",
       "         0.89583333, 0.89583333, 0.89236111, 0.89236111, 0.90972222,\n",
       "         0.90972222, 0.89236111, 0.90277778, 0.89236111, 0.89236111,\n",
       "         0.88541667, 0.89236111, 0.89930556, 0.89930556, 0.89583333,\n",
       "         0.89583333, 0.89583333, 0.89583333, 0.88541667, 0.89930556,\n",
       "         0.90972222, 0.90972222, 0.90625   , 0.91319444, 0.91319444,\n",
       "         0.91319444, 0.86458333, 0.86805556, 0.86805556, 0.86805556,\n",
       "         0.875     , 0.86805556, 0.86805556, 0.86805556, 0.87152778,\n",
       "         0.86805556, 0.86805556, 0.86805556, 0.875     , 0.87152778,\n",
       "         0.87152778, 0.87152778, 0.87152778, 0.87152778, 0.87152778,\n",
       "         0.87152778, 0.875     , 0.86805556, 0.86805556, 0.86805556,\n",
       "         0.87152778, 0.86458333, 0.86458333, 0.86458333, 0.87847222,\n",
       "         0.875     , 0.875     , 0.875     , 0.875     , 0.88194444,\n",
       "         0.88194444, 0.88194444, 0.86458333, 0.86458333, 0.86458333,\n",
       "         0.86458333, 0.85416667, 0.85763889, 0.85763889, 0.85763889,\n",
       "         0.85416667, 0.85416667, 0.85416667, 0.85416667, 0.86458333,\n",
       "         0.86111111, 0.86111111, 0.86111111, 0.86111111, 0.86111111,\n",
       "         0.86111111, 0.86111111, 0.875     , 0.86805556, 0.86805556,\n",
       "         0.86805556, 0.875     , 0.88194444, 0.88194444, 0.88194444,\n",
       "         0.86458333, 0.86458333, 0.86458333, 0.86458333, 0.86458333,\n",
       "         0.875     , 0.875     , 0.875     , 0.86458333, 0.86458333,\n",
       "         0.86458333, 0.86458333, 0.85416667, 0.85763889, 0.85763889,\n",
       "         0.85763889, 0.85416667, 0.85416667, 0.85416667, 0.85416667,\n",
       "         0.86458333, 0.86111111, 0.86111111, 0.86111111, 0.86111111,\n",
       "         0.86111111, 0.86111111, 0.86111111, 0.875     , 0.86805556,\n",
       "         0.86805556, 0.86805556, 0.875     , 0.88194444, 0.88194444,\n",
       "         0.88194444, 0.86458333, 0.86458333, 0.86458333, 0.86458333,\n",
       "         0.86458333, 0.875     , 0.875     , 0.875     , 0.86458333,\n",
       "         0.86458333, 0.86458333, 0.86458333, 0.85416667, 0.85763889,\n",
       "         0.85763889, 0.85763889, 0.85416667, 0.85416667, 0.85416667,\n",
       "         0.85416667, 0.86458333, 0.86111111, 0.86111111, 0.86111111,\n",
       "         0.86111111, 0.86111111, 0.86111111, 0.86111111, 0.875     ,\n",
       "         0.86805556, 0.86805556, 0.86805556, 0.875     , 0.88194444,\n",
       "         0.88194444, 0.88194444, 0.86458333, 0.86458333, 0.86458333,\n",
       "         0.86458333, 0.86458333, 0.875     , 0.875     , 0.875     ]),\n",
       "  'split1_test_score': array([0.94076655, 0.94425087, 0.93728223, 0.94773519, 0.92682927,\n",
       "         0.93379791, 0.93728223, 0.94076655, 0.92682927, 0.93728223,\n",
       "         0.94076655, 0.94076655, 0.93379791, 0.93031359, 0.93031359,\n",
       "         0.93031359, 0.91986063, 0.93379791, 0.93379791, 0.93379791,\n",
       "         0.93379791, 0.94773519, 0.93728223, 0.93728223, 0.94076655,\n",
       "         0.93379791, 0.93379791, 0.93379791, 0.93728223, 0.94076655,\n",
       "         0.94076655, 0.94076655, 0.93379791, 0.92682927, 0.93379791,\n",
       "         0.93379791, 0.92334495, 0.90592334, 0.90592334, 0.90592334,\n",
       "         0.90243902, 0.90243902, 0.90243902, 0.90243902, 0.91986063,\n",
       "         0.91289199, 0.91289199, 0.91289199, 0.91637631, 0.91986063,\n",
       "         0.91986063, 0.91986063, 0.90940767, 0.91289199, 0.91289199,\n",
       "         0.91289199, 0.92682927, 0.91637631, 0.91637631, 0.91637631,\n",
       "         0.91986063, 0.91986063, 0.91986063, 0.91986063, 0.92334495,\n",
       "         0.92334495, 0.92334495, 0.92334495, 0.92682927, 0.92334495,\n",
       "         0.92334495, 0.92334495, 0.88850174, 0.89198606, 0.89198606,\n",
       "         0.89198606, 0.88850174, 0.8989547 , 0.8989547 , 0.8989547 ,\n",
       "         0.8989547 , 0.90940767, 0.90940767, 0.90940767, 0.90940767,\n",
       "         0.90592334, 0.90592334, 0.90592334, 0.89547038, 0.90592334,\n",
       "         0.90592334, 0.90592334, 0.91637631, 0.91289199, 0.91289199,\n",
       "         0.91289199, 0.90940767, 0.90940767, 0.90940767, 0.90940767,\n",
       "         0.90243902, 0.90243902, 0.90243902, 0.90243902, 0.90940767,\n",
       "         0.90940767, 0.90940767, 0.90940767, 0.88850174, 0.89198606,\n",
       "         0.89198606, 0.89198606, 0.88850174, 0.8989547 , 0.8989547 ,\n",
       "         0.8989547 , 0.8989547 , 0.90940767, 0.90940767, 0.90940767,\n",
       "         0.90940767, 0.90592334, 0.90592334, 0.90592334, 0.89547038,\n",
       "         0.90592334, 0.90592334, 0.90592334, 0.91637631, 0.91289199,\n",
       "         0.91289199, 0.91289199, 0.90940767, 0.90940767, 0.90940767,\n",
       "         0.90940767, 0.90243902, 0.90243902, 0.90243902, 0.90243902,\n",
       "         0.90940767, 0.90940767, 0.90940767, 0.90940767, 0.88850174,\n",
       "         0.89198606, 0.89198606, 0.89198606, 0.88850174, 0.8989547 ,\n",
       "         0.8989547 , 0.8989547 , 0.8989547 , 0.90940767, 0.90940767,\n",
       "         0.90940767, 0.90940767, 0.90592334, 0.90592334, 0.90592334,\n",
       "         0.89547038, 0.90592334, 0.90592334, 0.90592334, 0.91637631,\n",
       "         0.91289199, 0.91289199, 0.91289199, 0.90940767, 0.90940767,\n",
       "         0.90940767, 0.90940767, 0.90243902, 0.90243902, 0.90243902,\n",
       "         0.90243902, 0.90940767, 0.90940767, 0.90940767, 0.90940767]),\n",
       "  'split2_test_score': array([0.91289199, 0.91637631, 0.91986063, 0.91637631, 0.90243902,\n",
       "         0.90592334, 0.8989547 , 0.90940767, 0.90940767, 0.91637631,\n",
       "         0.91637631, 0.91986063, 0.91289199, 0.91289199, 0.91637631,\n",
       "         0.91637631, 0.91289199, 0.91637631, 0.92334495, 0.92334495,\n",
       "         0.90940767, 0.91637631, 0.90940767, 0.90940767, 0.92334495,\n",
       "         0.91637631, 0.92682927, 0.92682927, 0.91637631, 0.91986063,\n",
       "         0.91289199, 0.91289199, 0.91637631, 0.91289199, 0.91637631,\n",
       "         0.91637631, 0.90592334, 0.90940767, 0.90940767, 0.90940767,\n",
       "         0.89198606, 0.89547038, 0.89547038, 0.89547038, 0.89198606,\n",
       "         0.89547038, 0.89547038, 0.89547038, 0.8989547 , 0.90243902,\n",
       "         0.90243902, 0.90243902, 0.90940767, 0.90940767, 0.90940767,\n",
       "         0.90940767, 0.89547038, 0.89198606, 0.89198606, 0.89198606,\n",
       "         0.90243902, 0.89547038, 0.89547038, 0.89547038, 0.8989547 ,\n",
       "         0.89547038, 0.89547038, 0.89547038, 0.90940767, 0.90940767,\n",
       "         0.90940767, 0.90940767, 0.88501742, 0.89198606, 0.89198606,\n",
       "         0.89198606, 0.88850174, 0.89547038, 0.89547038, 0.89547038,\n",
       "         0.88501742, 0.88501742, 0.88501742, 0.88501742, 0.89198606,\n",
       "         0.89547038, 0.89547038, 0.89547038, 0.8989547 , 0.8989547 ,\n",
       "         0.8989547 , 0.8989547 , 0.89198606, 0.89547038, 0.89547038,\n",
       "         0.89547038, 0.90592334, 0.90592334, 0.90592334, 0.90592334,\n",
       "         0.89547038, 0.8989547 , 0.8989547 , 0.8989547 , 0.89198606,\n",
       "         0.8989547 , 0.8989547 , 0.8989547 , 0.88501742, 0.89198606,\n",
       "         0.89198606, 0.89198606, 0.88850174, 0.89547038, 0.89547038,\n",
       "         0.89547038, 0.88501742, 0.88501742, 0.88501742, 0.88501742,\n",
       "         0.89198606, 0.89547038, 0.89547038, 0.89547038, 0.8989547 ,\n",
       "         0.8989547 , 0.8989547 , 0.8989547 , 0.89198606, 0.89547038,\n",
       "         0.89547038, 0.89547038, 0.90592334, 0.90592334, 0.90592334,\n",
       "         0.90592334, 0.89547038, 0.8989547 , 0.8989547 , 0.8989547 ,\n",
       "         0.89198606, 0.8989547 , 0.8989547 , 0.8989547 , 0.88501742,\n",
       "         0.89198606, 0.89198606, 0.89198606, 0.88850174, 0.89547038,\n",
       "         0.89547038, 0.89547038, 0.88501742, 0.88501742, 0.88501742,\n",
       "         0.88501742, 0.89198606, 0.89547038, 0.89547038, 0.89547038,\n",
       "         0.8989547 , 0.8989547 , 0.8989547 , 0.8989547 , 0.89198606,\n",
       "         0.89547038, 0.89547038, 0.89547038, 0.90592334, 0.90592334,\n",
       "         0.90592334, 0.90592334, 0.89547038, 0.8989547 , 0.8989547 ,\n",
       "         0.8989547 , 0.89198606, 0.8989547 , 0.8989547 , 0.8989547 ]),\n",
       "  'split3_test_score': array([0.89547038, 0.91986063, 0.91986063, 0.91986063, 0.91637631,\n",
       "         0.92334495, 0.93031359, 0.92682927, 0.90940767, 0.91289199,\n",
       "         0.92334495, 0.92334495, 0.92334495, 0.91986063, 0.91637631,\n",
       "         0.91637631, 0.90592334, 0.90243902, 0.90940767, 0.90940767,\n",
       "         0.8989547 , 0.90940767, 0.90940767, 0.90940767, 0.8989547 ,\n",
       "         0.91289199, 0.90592334, 0.90592334, 0.8989547 , 0.90243902,\n",
       "         0.90592334, 0.90592334, 0.8989547 , 0.90243902, 0.91289199,\n",
       "         0.91289199, 0.90592334, 0.91289199, 0.91289199, 0.91289199,\n",
       "         0.8989547 , 0.90940767, 0.90940767, 0.90940767, 0.90940767,\n",
       "         0.91289199, 0.91289199, 0.91289199, 0.91289199, 0.90940767,\n",
       "         0.90940767, 0.90940767, 0.91637631, 0.91289199, 0.91289199,\n",
       "         0.91289199, 0.91986063, 0.91289199, 0.91289199, 0.91289199,\n",
       "         0.8989547 , 0.90940767, 0.90940767, 0.90940767, 0.90940767,\n",
       "         0.91637631, 0.91637631, 0.91637631, 0.90592334, 0.91637631,\n",
       "         0.91637631, 0.91637631, 0.8989547 , 0.90592334, 0.90592334,\n",
       "         0.90592334, 0.90243902, 0.90243902, 0.90243902, 0.90243902,\n",
       "         0.8989547 , 0.8989547 , 0.8989547 , 0.8989547 , 0.8989547 ,\n",
       "         0.90243902, 0.90243902, 0.90243902, 0.90592334, 0.91289199,\n",
       "         0.91289199, 0.91289199, 0.88850174, 0.8989547 , 0.8989547 ,\n",
       "         0.8989547 , 0.90243902, 0.90940767, 0.90940767, 0.90940767,\n",
       "         0.90940767, 0.8989547 , 0.8989547 , 0.8989547 , 0.91289199,\n",
       "         0.91637631, 0.91637631, 0.91637631, 0.8989547 , 0.90592334,\n",
       "         0.90592334, 0.90592334, 0.90243902, 0.90243902, 0.90243902,\n",
       "         0.90243902, 0.8989547 , 0.8989547 , 0.8989547 , 0.8989547 ,\n",
       "         0.8989547 , 0.90243902, 0.90243902, 0.90243902, 0.90592334,\n",
       "         0.91289199, 0.91289199, 0.91289199, 0.88850174, 0.8989547 ,\n",
       "         0.8989547 , 0.8989547 , 0.90243902, 0.90940767, 0.90940767,\n",
       "         0.90940767, 0.90940767, 0.8989547 , 0.8989547 , 0.8989547 ,\n",
       "         0.91289199, 0.91637631, 0.91637631, 0.91637631, 0.8989547 ,\n",
       "         0.90592334, 0.90592334, 0.90592334, 0.90243902, 0.90243902,\n",
       "         0.90243902, 0.90243902, 0.8989547 , 0.8989547 , 0.8989547 ,\n",
       "         0.8989547 , 0.8989547 , 0.90243902, 0.90243902, 0.90243902,\n",
       "         0.90592334, 0.91289199, 0.91289199, 0.91289199, 0.88850174,\n",
       "         0.8989547 , 0.8989547 , 0.8989547 , 0.90243902, 0.90940767,\n",
       "         0.90940767, 0.90940767, 0.90940767, 0.8989547 , 0.8989547 ,\n",
       "         0.8989547 , 0.91289199, 0.91637631, 0.91637631, 0.91637631]),\n",
       "  'split4_test_score': array([0.94425087, 0.93728223, 0.93728223, 0.93728223, 0.93031359,\n",
       "         0.94773519, 0.93379791, 0.93379791, 0.93379791, 0.93379791,\n",
       "         0.93728223, 0.94076655, 0.92334495, 0.93031359, 0.93379791,\n",
       "         0.93379791, 0.93379791, 0.95121951, 0.94773519, 0.94773519,\n",
       "         0.93728223, 0.95121951, 0.94425087, 0.94076655, 0.94773519,\n",
       "         0.94425087, 0.95470383, 0.95470383, 0.93728223, 0.93728223,\n",
       "         0.94425087, 0.94425087, 0.95121951, 0.94425087, 0.94425087,\n",
       "         0.94425087, 0.90940767, 0.90940767, 0.90940767, 0.90940767,\n",
       "         0.91986063, 0.91637631, 0.91637631, 0.91637631, 0.93031359,\n",
       "         0.92334495, 0.92334495, 0.92334495, 0.92682927, 0.92682927,\n",
       "         0.92682927, 0.92682927, 0.91637631, 0.91986063, 0.91986063,\n",
       "         0.91986063, 0.93031359, 0.92682927, 0.92682927, 0.92682927,\n",
       "         0.93031359, 0.93031359, 0.93031359, 0.93031359, 0.92334495,\n",
       "         0.93728223, 0.93728223, 0.93728223, 0.93031359, 0.93728223,\n",
       "         0.93728223, 0.93728223, 0.8989547 , 0.90592334, 0.90592334,\n",
       "         0.90592334, 0.8989547 , 0.90592334, 0.90592334, 0.90592334,\n",
       "         0.89198606, 0.8989547 , 0.8989547 , 0.8989547 , 0.90243902,\n",
       "         0.90940767, 0.90940767, 0.90940767, 0.91289199, 0.91986063,\n",
       "         0.91986063, 0.91986063, 0.90592334, 0.91637631, 0.91637631,\n",
       "         0.91637631, 0.91637631, 0.92682927, 0.92682927, 0.92682927,\n",
       "         0.92682927, 0.92334495, 0.92334495, 0.92334495, 0.91637631,\n",
       "         0.91986063, 0.91986063, 0.91986063, 0.8989547 , 0.90592334,\n",
       "         0.90592334, 0.90592334, 0.8989547 , 0.90592334, 0.90592334,\n",
       "         0.90592334, 0.89198606, 0.8989547 , 0.8989547 , 0.8989547 ,\n",
       "         0.90243902, 0.90940767, 0.90940767, 0.90940767, 0.91289199,\n",
       "         0.91986063, 0.91986063, 0.91986063, 0.90592334, 0.91637631,\n",
       "         0.91637631, 0.91637631, 0.91637631, 0.92682927, 0.92682927,\n",
       "         0.92682927, 0.92682927, 0.92334495, 0.92334495, 0.92334495,\n",
       "         0.91637631, 0.91986063, 0.91986063, 0.91986063, 0.8989547 ,\n",
       "         0.90592334, 0.90592334, 0.90592334, 0.8989547 , 0.90592334,\n",
       "         0.90592334, 0.90592334, 0.89198606, 0.8989547 , 0.8989547 ,\n",
       "         0.8989547 , 0.90243902, 0.90940767, 0.90940767, 0.90940767,\n",
       "         0.91289199, 0.91986063, 0.91986063, 0.91986063, 0.90592334,\n",
       "         0.91637631, 0.91637631, 0.91637631, 0.91637631, 0.92682927,\n",
       "         0.92682927, 0.92682927, 0.92682927, 0.92334495, 0.92334495,\n",
       "         0.92334495, 0.91637631, 0.91986063, 0.91986063, 0.91986063]),\n",
       "  'mean_test_score': array([0.91504178, 0.92200557, 0.92200557, 0.92339833, 0.91364903,\n",
       "         0.91852368, 0.91643454, 0.91991643, 0.91364903, 0.92130919,\n",
       "         0.92270195, 0.92409471, 0.91713092, 0.91713092, 0.92130919,\n",
       "         0.92130919, 0.91295265, 0.92130919, 0.92130919, 0.92130919,\n",
       "         0.91295265, 0.92339833, 0.91991643, 0.91922006, 0.92130919,\n",
       "         0.92061281, 0.92339833, 0.92339833, 0.91504178, 0.91991643,\n",
       "         0.92270195, 0.92270195, 0.92130919, 0.91991643, 0.92409471,\n",
       "         0.92409471, 0.90181058, 0.90111421, 0.90111421, 0.90111421,\n",
       "         0.89763231, 0.89832869, 0.89832869, 0.89832869, 0.9045961 ,\n",
       "         0.90250696, 0.90250696, 0.90250696, 0.90598886, 0.90598886,\n",
       "         0.90598886, 0.90598886, 0.9045961 , 0.90529248, 0.90529248,\n",
       "         0.90529248, 0.90947075, 0.90320334, 0.90320334, 0.90320334,\n",
       "         0.9045961 , 0.90389972, 0.90389972, 0.90389972, 0.90668524,\n",
       "         0.90947075, 0.90947075, 0.90947075, 0.90947075, 0.91364903,\n",
       "         0.91364903, 0.91364903, 0.88718663, 0.89206128, 0.89206128,\n",
       "         0.89206128, 0.88649025, 0.89206128, 0.89206128, 0.89206128,\n",
       "         0.88579387, 0.88927577, 0.88927577, 0.88927577, 0.89345404,\n",
       "         0.8948468 , 0.8948468 , 0.8948468 , 0.8948468 , 0.89972145,\n",
       "         0.89972145, 0.89972145, 0.89554318, 0.89832869, 0.89832869,\n",
       "         0.89832869, 0.90181058, 0.90668524, 0.90668524, 0.90668524,\n",
       "         0.89972145, 0.89763231, 0.89763231, 0.89763231, 0.89902507,\n",
       "         0.90389972, 0.90389972, 0.90389972, 0.88718663, 0.89206128,\n",
       "         0.89206128, 0.89206128, 0.88649025, 0.89206128, 0.89206128,\n",
       "         0.89206128, 0.88579387, 0.88927577, 0.88927577, 0.88927577,\n",
       "         0.89345404, 0.8948468 , 0.8948468 , 0.8948468 , 0.8948468 ,\n",
       "         0.89972145, 0.89972145, 0.89972145, 0.89554318, 0.89832869,\n",
       "         0.89832869, 0.89832869, 0.90181058, 0.90668524, 0.90668524,\n",
       "         0.90668524, 0.89972145, 0.89763231, 0.89763231, 0.89763231,\n",
       "         0.89902507, 0.90389972, 0.90389972, 0.90389972, 0.88718663,\n",
       "         0.89206128, 0.89206128, 0.89206128, 0.88649025, 0.89206128,\n",
       "         0.89206128, 0.89206128, 0.88579387, 0.88927577, 0.88927577,\n",
       "         0.88927577, 0.89345404, 0.8948468 , 0.8948468 , 0.8948468 ,\n",
       "         0.8948468 , 0.89972145, 0.89972145, 0.89972145, 0.89554318,\n",
       "         0.89832869, 0.89832869, 0.89832869, 0.90181058, 0.90668524,\n",
       "         0.90668524, 0.90668524, 0.89972145, 0.89763231, 0.89763231,\n",
       "         0.89763231, 0.89902507, 0.90389972, 0.90389972, 0.90389972]),\n",
       "  'std_test_score': array([0.0244939 , 0.01813962, 0.01524806, 0.01793447, 0.01441221,\n",
       "         0.02284518, 0.02202865, 0.01871089, 0.0156845 , 0.01211072,\n",
       "         0.01614231, 0.01658264, 0.01405687, 0.01405687, 0.00916675,\n",
       "         0.00916675, 0.013831  , 0.01883818, 0.01918187, 0.01918187,\n",
       "         0.01997221, 0.02269898, 0.0175489 , 0.01661365, 0.02112116,\n",
       "         0.01688391, 0.02081489, 0.02081489, 0.02063527, 0.01712908,\n",
       "         0.01634975, 0.01634975, 0.01897876, 0.01441786, 0.01268201,\n",
       "         0.01268201, 0.01972114, 0.01670399, 0.01670399, 0.01670399,\n",
       "         0.01458832, 0.01668659, 0.01668659, 0.01668659, 0.02084404,\n",
       "         0.01943785, 0.01943785, 0.01943785, 0.01789912, 0.01919093,\n",
       "         0.01919093, 0.01919093, 0.01685339, 0.01724912, 0.01724912,\n",
       "         0.01724912, 0.02112118, 0.02092632, 0.02092632, 0.02092632,\n",
       "         0.02013348, 0.02281747, 0.02281747, 0.02281747, 0.01685243,\n",
       "         0.02191059, 0.02191059, 0.02191059, 0.01969442, 0.01836015,\n",
       "         0.01836015, 0.01836015, 0.01261384, 0.0151076 , 0.0151076 ,\n",
       "         0.0151076 , 0.01711871, 0.01758947, 0.01758947, 0.01758947,\n",
       "         0.01666229, 0.01921691, 0.01921691, 0.01921691, 0.01551286,\n",
       "         0.01751418, 0.01751418, 0.01751418, 0.01792498, 0.0205552 ,\n",
       "         0.0205552 , 0.0205552 , 0.01433024, 0.01711726, 0.01711726,\n",
       "         0.01711726, 0.01419715, 0.01438544, 0.01438544, 0.01438544,\n",
       "         0.02045309, 0.01888142, 0.01888142, 0.01888142, 0.01918222,\n",
       "         0.01613941, 0.01613941, 0.01613941, 0.01261384, 0.0151076 ,\n",
       "         0.0151076 , 0.0151076 , 0.01711871, 0.01758947, 0.01758947,\n",
       "         0.01758947, 0.01666229, 0.01921691, 0.01921691, 0.01921691,\n",
       "         0.01551286, 0.01751418, 0.01751418, 0.01751418, 0.01792498,\n",
       "         0.0205552 , 0.0205552 , 0.0205552 , 0.01433024, 0.01711726,\n",
       "         0.01711726, 0.01711726, 0.01419715, 0.01438544, 0.01438544,\n",
       "         0.01438544, 0.02045309, 0.01888142, 0.01888142, 0.01888142,\n",
       "         0.01918222, 0.01613941, 0.01613941, 0.01613941, 0.01261384,\n",
       "         0.0151076 , 0.0151076 , 0.0151076 , 0.01711871, 0.01758947,\n",
       "         0.01758947, 0.01758947, 0.01666229, 0.01921691, 0.01921691,\n",
       "         0.01921691, 0.01551286, 0.01751418, 0.01751418, 0.01751418,\n",
       "         0.01792498, 0.0205552 , 0.0205552 , 0.0205552 , 0.01433024,\n",
       "         0.01711726, 0.01711726, 0.01711726, 0.01419715, 0.01438544,\n",
       "         0.01438544, 0.01438544, 0.02045309, 0.01888142, 0.01888142,\n",
       "         0.01888142, 0.01918222, 0.01613941, 0.01613941, 0.01613941]),\n",
       "  'rank_test_score': array([ 31,  11,  11,   4,  33,  27,  30,  22,  33,  13,   8,   1,  28,\n",
       "          28,  13,  13,  38,  13,  13,  13,  38,   4,  22,  26,  13,  21,\n",
       "           4,   4,  31,  22,   8,   8,  13,  22,   1,   1,  83,  87,  87,\n",
       "          87, 117, 105, 105, 105,  62,  80,  80,  80,  55,  55,  55,  55,\n",
       "          62,  59,  59,  59,  40,  77,  77,  77,  62,  65,  65,  65,  45,\n",
       "          40,  40,  40,  40,  33,  33,  33, 172, 145, 145, 145, 175, 145,\n",
       "         145, 145, 178, 163, 163, 163, 142, 130, 130, 130, 130,  90,  90,\n",
       "          90, 127, 105, 105, 105,  83,  45,  45,  45,  90, 117, 117, 117,\n",
       "         102,  65,  65,  65, 172, 145, 145, 145, 175, 145, 145, 145, 178,\n",
       "         163, 163, 163, 142, 130, 130, 130, 130,  90,  90,  90, 127, 105,\n",
       "         105, 105,  83,  45,  45,  45,  90, 117, 117, 117, 102,  65,  65,\n",
       "          65, 172, 145, 145, 145, 175, 145, 145, 145, 178, 163, 163, 163,\n",
       "         142, 130, 130, 130, 130,  90,  90,  90, 127, 105, 105, 105,  83,\n",
       "          45,  45,  45,  90, 117, 117, 117, 102,  65,  65,  65], dtype=int32)}}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBM_2_cls_scores_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [50, 100, 300]\n",
    "criterion = ['gini', 'entropy']\n",
    "max_depth = [5, 50, None]\n",
    "min_samples_split = [2, 10]\n",
    "max_features = [25]\n",
    "bootstrap = [True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T00:03:47.213352Z",
     "start_time": "2019-10-22T00:02:21.825388Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train and fit Gradient Boosting over fewer parameters\n",
    "from src.models import model_sel_grid\n",
    "\n",
    "# Function arguments:\n",
    "model = GradientBoostingClassifier(random_state=3)\n",
    "transformer = RandomOverSampler(random_state=3, sampling_strategy='minority')\n",
    "CV = 5\n",
    "\n",
    "# Function arguments: classifier params\n",
    "n_estimators = [50, 100, 300]\n",
    "max_depth = [5, 50, None]\n",
    "min_samples_split = [2, 10]\n",
    "max_features = [25]\n",
    "\n",
    "                \n",
    "param_grid = dict(model__n_estimators=n_estimators,\n",
    "                  model__max_depth=max_depth,\n",
    "                  model__min_samples_split=min_samples_split,\n",
    "                  model__max_features=max_features,\n",
    "                 )\n",
    "\n",
    "# Call parameter selection function\n",
    "GBM_2_cls_scores_fewer_params, GBM_2_cls_model_fewer = model_sel_grid.train_fit_time(model,\n",
    "                                                                        param_grid,\n",
    "                                                                        transformer,\n",
    "                                                                        X_train,\n",
    "                                                                        X_test,\n",
    "                                                                        y_train,\n",
    "                                                                        y_test,\n",
    "                                                                        CV)\n",
    "\n",
    "# Pickle results\n",
    "with open('/Users/greenapple/project3/models/GBM_2_cls_scores_fewer_params.pkl', 'wb') as f:\n",
    "    pickle.dump(GBM_2_cls_scores_fewer_params, f)\n",
    "    \n",
    "# Pickle model\n",
    "with open('/Users/greenapple/project3/models/GBM_2_cls_model_fewer.pkl', 'wb') as f:\n",
    "    pickle.dump(GBM_2_cls_model_fewer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T00:05:19.328389Z",
     "start_time": "2019-10-22T00:05:19.227233Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_train_score': 0.9240947075208914,\n",
       " 'best_test_score': 0.9277777777777778,\n",
       " 'time_sec': 73.11709,\n",
       " 'time_best_fit_sec': 1.6232022000000002,\n",
       " 'best_params': {'model__max_depth': 5,\n",
       "  'model__max_features': 25,\n",
       "  'model__min_samples_split': 10,\n",
       "  'model__n_estimators': 300},\n",
       " 'best_estimator': Pipeline(memory=None,\n",
       "          steps=[('transformer',\n",
       "                  RandomOverSampler(random_state=3, ratio=None,\n",
       "                                    return_indices=False,\n",
       "                                    sampling_strategy='minority')),\n",
       "                 ('model',\n",
       "                  GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                                             learning_rate=0.1, loss='deviance',\n",
       "                                             max_depth=5, max_features=25,\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=10,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             n_estimators=300,\n",
       "                                             n_iter_no_change=None,\n",
       "                                             presort='auto', random_state=3,\n",
       "                                             subsample=1.0, tol=0.0001,\n",
       "                                             validation_fraction=0.1, verbose=0,\n",
       "                                             warm_start=False))],\n",
       "          verbose=False),\n",
       " 'best_test_proba': array([[2.14675659e-01, 7.85324341e-01],\n",
       "        [9.99969409e-01, 3.05910501e-05],\n",
       "        [9.98675939e-01, 1.32406089e-03],\n",
       "        [9.96604807e-01, 3.39519265e-03],\n",
       "        [9.99820058e-01, 1.79941943e-04],\n",
       "        [9.99969862e-01, 3.01377805e-05],\n",
       "        [9.99895403e-01, 1.04596842e-04],\n",
       "        [9.99995376e-01, 4.62434987e-06],\n",
       "        [9.98501514e-01, 1.49848570e-03],\n",
       "        [2.38321827e-05, 9.99976168e-01],\n",
       "        [9.83803540e-01, 1.61964604e-02],\n",
       "        [9.34857861e-01, 6.51421391e-02],\n",
       "        [9.99785242e-01, 2.14758372e-04],\n",
       "        [9.99989147e-01, 1.08530982e-05],\n",
       "        [9.99510132e-01, 4.89868053e-04],\n",
       "        [9.95478257e-01, 4.52174294e-03],\n",
       "        [5.42783157e-02, 9.45721684e-01],\n",
       "        [9.99991989e-01, 8.01110804e-06],\n",
       "        [6.49709056e-01, 3.50290944e-01],\n",
       "        [9.98099425e-01, 1.90057467e-03],\n",
       "        [9.99988828e-01, 1.11720338e-05],\n",
       "        [2.73801070e-01, 7.26198930e-01],\n",
       "        [9.99655912e-01, 3.44087836e-04],\n",
       "        [9.99926315e-01, 7.36851567e-05],\n",
       "        [9.99363461e-01, 6.36539106e-04],\n",
       "        [9.99630673e-01, 3.69326950e-04],\n",
       "        [9.99816253e-01, 1.83746866e-04],\n",
       "        [9.95705329e-01, 4.29467095e-03],\n",
       "        [9.99604504e-01, 3.95496030e-04],\n",
       "        [9.93698096e-01, 6.30190426e-03],\n",
       "        [9.34298893e-01, 6.57011068e-02],\n",
       "        [9.99542623e-01, 4.57377095e-04],\n",
       "        [9.99936687e-01, 6.33126005e-05],\n",
       "        [9.99939399e-01, 6.06013959e-05],\n",
       "        [4.87574106e-04, 9.99512426e-01],\n",
       "        [9.99853110e-01, 1.46890489e-04],\n",
       "        [9.99955463e-01, 4.45368793e-05],\n",
       "        [9.99974329e-01, 2.56709343e-05],\n",
       "        [9.99862856e-01, 1.37143665e-04],\n",
       "        [4.57279588e-01, 5.42720412e-01],\n",
       "        [9.99971772e-01, 2.82279868e-05],\n",
       "        [9.99819651e-01, 1.80348869e-04],\n",
       "        [9.99972315e-01, 2.76845354e-05],\n",
       "        [9.99101572e-01, 8.98428099e-04],\n",
       "        [8.46917253e-01, 1.53082747e-01],\n",
       "        [8.92894934e-02, 9.10710507e-01],\n",
       "        [9.99987104e-01, 1.28957608e-05],\n",
       "        [9.91457749e-01, 8.54225142e-03],\n",
       "        [9.99922055e-01, 7.79449691e-05],\n",
       "        [9.99928924e-01, 7.10756707e-05],\n",
       "        [2.48876085e-02, 9.75112391e-01],\n",
       "        [9.98816445e-01, 1.18355536e-03],\n",
       "        [9.93754664e-01, 6.24533599e-03],\n",
       "        [9.99401341e-01, 5.98658607e-04],\n",
       "        [9.99938123e-01, 6.18765684e-05],\n",
       "        [9.88711278e-01, 1.12887219e-02],\n",
       "        [9.99959009e-01, 4.09905832e-05],\n",
       "        [9.99756558e-01, 2.43441666e-04],\n",
       "        [9.99978577e-01, 2.14226468e-05],\n",
       "        [9.99920030e-01, 7.99700835e-05],\n",
       "        [9.99931384e-01, 6.86159643e-05],\n",
       "        [9.99970492e-01, 2.95075039e-05],\n",
       "        [6.91936570e-03, 9.93080634e-01],\n",
       "        [9.99363866e-01, 6.36134399e-04],\n",
       "        [7.50518677e-03, 9.92494813e-01],\n",
       "        [9.75432678e-01, 2.45673216e-02],\n",
       "        [9.99700328e-01, 2.99671704e-04],\n",
       "        [9.99931686e-01, 6.83142704e-05],\n",
       "        [9.99948965e-01, 5.10348229e-05],\n",
       "        [9.74157811e-01, 2.58421892e-02],\n",
       "        [9.99130116e-01, 8.69884177e-04],\n",
       "        [9.80786398e-01, 1.92136025e-02],\n",
       "        [9.99897631e-01, 1.02368888e-04],\n",
       "        [9.99875238e-01, 1.24761662e-04],\n",
       "        [9.99361006e-01, 6.38993757e-04],\n",
       "        [1.89299971e-02, 9.81070003e-01],\n",
       "        [2.10992343e-02, 9.78900766e-01],\n",
       "        [9.94329820e-01, 5.67018015e-03],\n",
       "        [9.99989557e-01, 1.04429485e-05],\n",
       "        [9.99969023e-01, 3.09766881e-05],\n",
       "        [9.95081589e-01, 4.91841126e-03],\n",
       "        [9.99232824e-01, 7.67176230e-04],\n",
       "        [7.47726913e-03, 9.92522731e-01],\n",
       "        [9.99993887e-01, 6.11250748e-06],\n",
       "        [9.99926188e-01, 7.38121431e-05],\n",
       "        [9.99994918e-01, 5.08215305e-06],\n",
       "        [9.99897828e-01, 1.02172329e-04],\n",
       "        [9.99868323e-01, 1.31676727e-04],\n",
       "        [9.99787540e-01, 2.12459925e-04],\n",
       "        [9.99955119e-01, 4.48812947e-05],\n",
       "        [9.90183738e-04, 9.99009816e-01],\n",
       "        [9.96468016e-01, 3.53198350e-03],\n",
       "        [3.01768249e-02, 9.69823175e-01],\n",
       "        [9.99957659e-01, 4.23408740e-05],\n",
       "        [9.99835993e-01, 1.64006879e-04],\n",
       "        [9.99966305e-01, 3.36950828e-05],\n",
       "        [6.95988204e-01, 3.04011796e-01],\n",
       "        [9.99980761e-01, 1.92390515e-05],\n",
       "        [9.99975181e-01, 2.48187014e-05],\n",
       "        [9.99954689e-01, 4.53108979e-05],\n",
       "        [9.99959777e-01, 4.02230481e-05],\n",
       "        [9.99955629e-01, 4.43707089e-05],\n",
       "        [9.99875336e-01, 1.24664376e-04],\n",
       "        [9.55002408e-01, 4.49975922e-02],\n",
       "        [9.99967380e-01, 3.26203153e-05],\n",
       "        [9.99754305e-01, 2.45694976e-04],\n",
       "        [9.99882024e-01, 1.17976106e-04],\n",
       "        [9.99852495e-01, 1.47504758e-04],\n",
       "        [1.88043985e-01, 8.11956015e-01],\n",
       "        [9.73004144e-01, 2.69958557e-02],\n",
       "        [9.99563925e-01, 4.36075428e-04],\n",
       "        [9.99623842e-01, 3.76157622e-04],\n",
       "        [9.99939244e-01, 6.07562400e-05],\n",
       "        [9.99542396e-01, 4.57603631e-04],\n",
       "        [7.19631161e-01, 2.80368839e-01],\n",
       "        [9.99957474e-01, 4.25257350e-05],\n",
       "        [9.99684055e-01, 3.15944721e-04],\n",
       "        [6.27440491e-01, 3.72559509e-01],\n",
       "        [5.94519280e-02, 9.40548072e-01],\n",
       "        [9.99654865e-01, 3.45135115e-04],\n",
       "        [9.83315346e-01, 1.66846536e-02],\n",
       "        [9.99622439e-01, 3.77561233e-04],\n",
       "        [9.98106768e-01, 1.89323205e-03],\n",
       "        [3.47997599e-02, 9.65200240e-01],\n",
       "        [9.99925766e-01, 7.42339647e-05],\n",
       "        [9.95236714e-01, 4.76328594e-03],\n",
       "        [1.06748198e-01, 8.93251802e-01],\n",
       "        [9.99897298e-01, 1.02702470e-04],\n",
       "        [6.60029280e-01, 3.39970720e-01],\n",
       "        [2.42591076e-01, 7.57408924e-01],\n",
       "        [8.15248033e-01, 1.84751967e-01],\n",
       "        [9.99615361e-01, 3.84639047e-04],\n",
       "        [9.99961339e-01, 3.86610436e-05],\n",
       "        [9.99775141e-01, 2.24859003e-04],\n",
       "        [9.99977533e-01, 2.24673324e-05],\n",
       "        [9.99933438e-01, 6.65615303e-05],\n",
       "        [9.98609221e-01, 1.39077902e-03],\n",
       "        [9.99850966e-01, 1.49033505e-04],\n",
       "        [9.99470973e-01, 5.29026593e-04],\n",
       "        [9.99912044e-01, 8.79555139e-05],\n",
       "        [9.99899694e-01, 1.00306379e-04],\n",
       "        [9.96397604e-01, 3.60239605e-03],\n",
       "        [3.54040214e-03, 9.96459598e-01],\n",
       "        [9.99154361e-01, 8.45639226e-04],\n",
       "        [9.99781799e-01, 2.18200785e-04],\n",
       "        [9.99916832e-01, 8.31680291e-05],\n",
       "        [9.99980773e-01, 1.92271794e-05],\n",
       "        [9.99896672e-01, 1.03327910e-04],\n",
       "        [9.99890360e-01, 1.09639996e-04],\n",
       "        [9.99989136e-01, 1.08644039e-05],\n",
       "        [9.99931469e-01, 6.85313237e-05],\n",
       "        [9.99799574e-01, 2.00425871e-04],\n",
       "        [4.12917091e-01, 5.87082909e-01],\n",
       "        [9.99875754e-01, 1.24246249e-04],\n",
       "        [9.99942184e-01, 5.78157758e-05],\n",
       "        [9.99937028e-01, 6.29718123e-05],\n",
       "        [8.56797126e-01, 1.43202874e-01],\n",
       "        [8.82337295e-01, 1.17662705e-01],\n",
       "        [9.94896533e-01, 5.10346711e-03],\n",
       "        [9.78461917e-01, 2.15380835e-02],\n",
       "        [9.99575358e-01, 4.24642456e-04],\n",
       "        [9.99343320e-01, 6.56680139e-04],\n",
       "        [9.99971148e-01, 2.88524098e-05],\n",
       "        [9.99977610e-01, 2.23904896e-05],\n",
       "        [4.02198702e-04, 9.99597801e-01],\n",
       "        [9.99306730e-01, 6.93269911e-04],\n",
       "        [9.99955315e-01, 4.46847246e-05],\n",
       "        [9.99968261e-01, 3.17389873e-05],\n",
       "        [9.99263288e-01, 7.36711577e-04],\n",
       "        [7.02308089e-01, 2.97691911e-01],\n",
       "        [1.66188648e-01, 8.33811352e-01],\n",
       "        [9.99963235e-01, 3.67648311e-05],\n",
       "        [9.99980025e-01, 1.99754009e-05],\n",
       "        [9.45855416e-01, 5.41445844e-02],\n",
       "        [9.84794773e-01, 1.52052271e-02],\n",
       "        [9.99985628e-01, 1.43716803e-05],\n",
       "        [9.90915927e-01, 9.08407348e-03],\n",
       "        [9.99834173e-01, 1.65826682e-04],\n",
       "        [7.08909598e-01, 2.91090402e-01],\n",
       "        [9.99959357e-01, 4.06431009e-05],\n",
       "        [6.10187102e-01, 3.89812898e-01],\n",
       "        [9.99909506e-01, 9.04941336e-05],\n",
       "        [9.83007610e-01, 1.69923899e-02],\n",
       "        [9.99523814e-01, 4.76186032e-04],\n",
       "        [9.98897950e-01, 1.10204959e-03],\n",
       "        [9.99991569e-01, 8.43143698e-06],\n",
       "        [9.99943443e-01, 5.65573224e-05],\n",
       "        [4.22142606e-05, 9.99957786e-01],\n",
       "        [9.99837299e-01, 1.62700965e-04],\n",
       "        [9.99982131e-01, 1.78685665e-05],\n",
       "        [9.99965417e-01, 3.45830464e-05],\n",
       "        [9.99644736e-01, 3.55264471e-04],\n",
       "        [9.99889733e-01, 1.10266833e-04],\n",
       "        [9.98742694e-01, 1.25730604e-03],\n",
       "        [9.99931227e-01, 6.87730257e-05],\n",
       "        [9.28844031e-01, 7.11559692e-02],\n",
       "        [9.99756001e-01, 2.43999002e-04],\n",
       "        [9.99819739e-01, 1.80261144e-04],\n",
       "        [6.02948208e-01, 3.97051792e-01],\n",
       "        [9.87969714e-01, 1.20302859e-02],\n",
       "        [9.99874697e-01, 1.25303416e-04],\n",
       "        [2.30260389e-02, 9.76973961e-01],\n",
       "        [9.99966673e-01, 3.33269803e-05],\n",
       "        [9.99942558e-01, 5.74420015e-05],\n",
       "        [9.99952047e-01, 4.79527498e-05],\n",
       "        [9.97800998e-01, 2.19900169e-03],\n",
       "        [9.99985326e-01, 1.46736222e-05],\n",
       "        [9.16986548e-01, 8.30134524e-02],\n",
       "        [9.92458391e-01, 7.54160878e-03],\n",
       "        [9.96805986e-01, 3.19401414e-03],\n",
       "        [3.37568277e-01, 6.62431723e-01],\n",
       "        [9.99866354e-01, 1.33646034e-04],\n",
       "        [9.99947341e-01, 5.26587108e-05],\n",
       "        [9.97193897e-01, 2.80610292e-03],\n",
       "        [8.09312916e-03, 9.91906871e-01],\n",
       "        [9.98973212e-01, 1.02678770e-03],\n",
       "        [9.99992612e-01, 7.38813718e-06],\n",
       "        [2.50527349e-01, 7.49472651e-01],\n",
       "        [9.99968251e-01, 3.17492471e-05],\n",
       "        [9.99991378e-01, 8.62231267e-06],\n",
       "        [9.97007361e-01, 2.99263916e-03],\n",
       "        [9.11281637e-01, 8.87183635e-02],\n",
       "        [9.99971268e-01, 2.87322042e-05],\n",
       "        [1.56649742e-01, 8.43350258e-01],\n",
       "        [9.99162264e-01, 8.37736425e-04],\n",
       "        [9.99925616e-01, 7.43843684e-05],\n",
       "        [9.91307704e-01, 8.69229567e-03],\n",
       "        [9.99942315e-01, 5.76845400e-05],\n",
       "        [9.99975518e-01, 2.44822636e-05],\n",
       "        [9.99683490e-01, 3.16509708e-04],\n",
       "        [9.99976045e-01, 2.39545401e-05],\n",
       "        [9.99953603e-01, 4.63971612e-05],\n",
       "        [9.99936231e-01, 6.37688955e-05],\n",
       "        [9.99925299e-01, 7.47014987e-05],\n",
       "        [9.99753429e-01, 2.46571152e-04],\n",
       "        [9.99936457e-01, 6.35433360e-05],\n",
       "        [9.99257851e-01, 7.42149023e-04],\n",
       "        [9.99986935e-01, 1.30648432e-05],\n",
       "        [9.99818433e-01, 1.81566599e-04],\n",
       "        [9.99989339e-01, 1.06614744e-05],\n",
       "        [3.69633438e-04, 9.99630367e-01],\n",
       "        [9.99857635e-01, 1.42365316e-04],\n",
       "        [9.98383663e-01, 1.61633700e-03],\n",
       "        [1.19990468e-01, 8.80009532e-01],\n",
       "        [9.97198049e-01, 2.80195089e-03],\n",
       "        [9.99969909e-01, 3.00907598e-05],\n",
       "        [9.99878891e-01, 1.21108782e-04],\n",
       "        [9.99925501e-01, 7.44988575e-05],\n",
       "        [9.39467325e-01, 6.05326749e-02],\n",
       "        [9.99969791e-01, 3.02088718e-05],\n",
       "        [9.99976315e-01, 2.36854480e-05],\n",
       "        [6.66212003e-03, 9.93337880e-01],\n",
       "        [9.99919825e-01, 8.01745784e-05],\n",
       "        [7.72548648e-01, 2.27451352e-01],\n",
       "        [9.98720404e-01, 1.27959574e-03],\n",
       "        [9.99849156e-01, 1.50844307e-04],\n",
       "        [9.99935808e-01, 6.41923184e-05],\n",
       "        [9.99955430e-01, 4.45695189e-05],\n",
       "        [9.93490717e-01, 6.50928310e-03],\n",
       "        [2.70138897e-01, 7.29861103e-01],\n",
       "        [9.99249633e-01, 7.50366781e-04],\n",
       "        [9.99974705e-01, 2.52949873e-05],\n",
       "        [9.99970889e-01, 2.91111838e-05],\n",
       "        [9.99864314e-01, 1.35686321e-04],\n",
       "        [9.99913462e-01, 8.65380436e-05],\n",
       "        [9.99486978e-01, 5.13021829e-04],\n",
       "        [9.99965222e-01, 3.47778778e-05],\n",
       "        [9.99734880e-01, 2.65119874e-04],\n",
       "        [9.99730042e-01, 2.69958290e-04],\n",
       "        [9.99110574e-01, 8.89425582e-04],\n",
       "        [9.99893476e-01, 1.06524109e-04],\n",
       "        [9.99980255e-01, 1.97449968e-05],\n",
       "        [7.59315236e-04, 9.99240685e-01],\n",
       "        [9.97385142e-01, 2.61485832e-03],\n",
       "        [7.42323859e-01, 2.57676141e-01],\n",
       "        [9.99768032e-01, 2.31968308e-04],\n",
       "        [9.93629536e-01, 6.37046406e-03],\n",
       "        [9.99584026e-01, 4.15974287e-04],\n",
       "        [9.96395760e-01, 3.60423959e-03],\n",
       "        [9.92455619e-01, 7.54438122e-03],\n",
       "        [9.99990252e-01, 9.74801867e-06],\n",
       "        [9.99978666e-01, 2.13338165e-05],\n",
       "        [9.99953957e-01, 4.60431401e-05],\n",
       "        [9.99961640e-01, 3.83598399e-05],\n",
       "        [9.99981905e-01, 1.80954930e-05],\n",
       "        [9.98127867e-01, 1.87213342e-03],\n",
       "        [2.41308435e-02, 9.75869156e-01],\n",
       "        [9.99907659e-01, 9.23412859e-05],\n",
       "        [6.59076012e-03, 9.93409240e-01],\n",
       "        [3.11077385e-03, 9.96889226e-01],\n",
       "        [9.98798324e-01, 1.20167623e-03],\n",
       "        [9.97306992e-01, 2.69300765e-03],\n",
       "        [9.97950523e-01, 2.04947709e-03],\n",
       "        [9.74074393e-01, 2.59256068e-02],\n",
       "        [9.97287181e-01, 2.71281917e-03],\n",
       "        [9.99220372e-01, 7.79628088e-04],\n",
       "        [9.99966438e-01, 3.35617362e-05],\n",
       "        [9.99969625e-01, 3.03752655e-05],\n",
       "        [9.99992648e-01, 7.35166922e-06],\n",
       "        [9.99349428e-01, 6.50571612e-04],\n",
       "        [9.23876552e-01, 7.61234477e-02],\n",
       "        [9.99938691e-01, 6.13094726e-05],\n",
       "        [9.98281885e-01, 1.71811471e-03],\n",
       "        [6.74461850e-04, 9.99325538e-01],\n",
       "        [9.97534542e-01, 2.46545821e-03],\n",
       "        [9.20846691e-01, 7.91533090e-02],\n",
       "        [9.99558427e-01, 4.41573221e-04],\n",
       "        [9.99946007e-01, 5.39930708e-05],\n",
       "        [9.19094964e-01, 8.09050356e-02],\n",
       "        [9.90461223e-01, 9.53877676e-03],\n",
       "        [9.99867908e-01, 1.32091847e-04],\n",
       "        [2.15452093e-03, 9.97845479e-01],\n",
       "        [6.92691225e-01, 3.07308775e-01],\n",
       "        [9.98591768e-01, 1.40823192e-03],\n",
       "        [9.90905190e-01, 9.09480959e-03],\n",
       "        [9.99955362e-01, 4.46379061e-05],\n",
       "        [9.99970144e-01, 2.98558825e-05],\n",
       "        [4.18613753e-03, 9.95813862e-01],\n",
       "        [9.99496066e-01, 5.03934172e-04],\n",
       "        [9.99954445e-01, 4.55550456e-05],\n",
       "        [2.39360481e-02, 9.76063952e-01],\n",
       "        [9.99896688e-01, 1.03311758e-04],\n",
       "        [7.28570399e-04, 9.99271430e-01],\n",
       "        [9.99953517e-01, 4.64833937e-05],\n",
       "        [9.99633997e-01, 3.66002652e-04],\n",
       "        [9.99973795e-01, 2.62054805e-05],\n",
       "        [1.64804331e-04, 9.99835196e-01],\n",
       "        [1.69687864e-04, 9.99830312e-01],\n",
       "        [9.93773336e-01, 6.22666375e-03],\n",
       "        [9.99965033e-01, 3.49668526e-05],\n",
       "        [9.99931653e-01, 6.83470714e-05],\n",
       "        [9.96647477e-01, 3.35252295e-03],\n",
       "        [9.99815234e-01, 1.84765666e-04],\n",
       "        [9.99862622e-01, 1.37377538e-04],\n",
       "        [9.99983877e-01, 1.61230939e-05],\n",
       "        [9.99924921e-01, 7.50792232e-05],\n",
       "        [9.99934667e-01, 6.53333506e-05],\n",
       "        [9.99953674e-01, 4.63257707e-05],\n",
       "        [9.99243905e-01, 7.56095126e-04],\n",
       "        [9.99886123e-01, 1.13877416e-04],\n",
       "        [9.99749296e-01, 2.50703525e-04],\n",
       "        [9.99869738e-01, 1.30262356e-04],\n",
       "        [9.97388255e-01, 2.61174458e-03],\n",
       "        [9.99928003e-01, 7.19965342e-05],\n",
       "        [9.60615671e-01, 3.93843294e-02],\n",
       "        [9.96802892e-01, 3.19710848e-03],\n",
       "        [9.97980489e-01, 2.01951134e-03],\n",
       "        [1.56411351e-01, 8.43588649e-01],\n",
       "        [9.99662640e-01, 3.37360173e-04],\n",
       "        [9.96610832e-01, 3.38916767e-03],\n",
       "        [2.76515731e-02, 9.72348427e-01],\n",
       "        [9.99934532e-01, 6.54680971e-05],\n",
       "        [9.99908577e-01, 9.14232503e-05],\n",
       "        [9.99669151e-01, 3.30848726e-04],\n",
       "        [9.97169292e-01, 2.83070781e-03],\n",
       "        [9.99757634e-01, 2.42366230e-04],\n",
       "        [9.58465651e-01, 4.15343486e-02],\n",
       "        [9.99991006e-01, 8.99427543e-06],\n",
       "        [9.98847088e-01, 1.15291220e-03],\n",
       "        [9.90278600e-01, 9.72139999e-03]]),\n",
       " 'best_y_hat': array(['purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'purr', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'purr', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps'], dtype=object),\n",
       " 'all_scores': {'mean_fit_time': array([0.9721972 , 2.39777446, 4.21372948, 1.50881429, 2.63563037,\n",
       "         3.08382554, 2.20372839, 2.98182511, 2.74577107, 2.89457893,\n",
       "         3.69320459, 3.83059497, 1.8261024 , 2.5331708 , 2.68488817,\n",
       "         3.06502552, 3.93379035, 4.39495044]),\n",
       "  'std_fit_time': array([0.00895391, 0.62877823, 0.38573496, 0.25877046, 0.37837669,\n",
       "         0.09993964, 0.27903155, 0.19582848, 0.10094673, 0.12037822,\n",
       "         0.07777942, 0.06389727, 0.04238958, 0.07358516, 0.08601297,\n",
       "         0.05596909, 0.07167834, 0.44373182]),\n",
       "  'mean_score_time': array([0.00811372, 0.01021132, 0.02104669, 0.01168203, 0.00897541,\n",
       "         0.01093941, 0.00871143, 0.01267753, 0.00895429, 0.0079865 ,\n",
       "         0.01063776, 0.0099009 , 0.00791464, 0.00864191, 0.00896559,\n",
       "         0.0098124 , 0.01010771, 0.01279898]),\n",
       "  'std_score_time': array([0.00075455, 0.00147766, 0.01690018, 0.00309939, 0.00085989,\n",
       "         0.00186521, 0.0011743 , 0.00596665, 0.00042468, 0.00021673,\n",
       "         0.00233899, 0.00065338, 0.00031296, 0.00044468, 0.00030006,\n",
       "         0.00136017, 0.00078092, 0.00594805]),\n",
       "  'param_model__max_depth': masked_array(data=[5, 5, 5, 5, 5, 5, 50, 50, 50, 50, 50, 50, None, None,\n",
       "                     None, None, None, None],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__max_features': masked_array(data=[25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "                     25, 25, 25, 25],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__min_samples_split': masked_array(data=[2, 2, 2, 10, 10, 10, 2, 2, 2, 10, 10, 10, 2, 2, 2, 10,\n",
       "                     10, 10],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__n_estimators': masked_array(data=[50, 100, 300, 50, 100, 300, 50, 100, 300, 50, 100, 300,\n",
       "                     50, 100, 300, 50, 100, 300],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': 50,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__n_estimators': 300},\n",
       "   {'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 50},\n",
       "   {'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 100},\n",
       "   {'model__max_depth': None,\n",
       "    'model__max_features': 25,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__n_estimators': 300}],\n",
       "  'split0_test_score': array([0.89583333, 0.89583333, 0.89583333, 0.90625   , 0.91319444,\n",
       "         0.91319444, 0.875     , 0.88194444, 0.88194444, 0.86458333,\n",
       "         0.875     , 0.875     , 0.875     , 0.88194444, 0.88194444,\n",
       "         0.86458333, 0.875     , 0.875     ]),\n",
       "  'split1_test_score': array([0.94076655, 0.93379791, 0.93379791, 0.93379791, 0.92682927,\n",
       "         0.93379791, 0.90940767, 0.90940767, 0.90940767, 0.90940767,\n",
       "         0.90940767, 0.90940767, 0.90940767, 0.90940767, 0.90940767,\n",
       "         0.90940767, 0.90940767, 0.90940767]),\n",
       "  'split2_test_score': array([0.92334495, 0.91637631, 0.92682927, 0.91637631, 0.91289199,\n",
       "         0.91637631, 0.90592334, 0.90592334, 0.90592334, 0.89198606,\n",
       "         0.8989547 , 0.8989547 , 0.90592334, 0.90592334, 0.90592334,\n",
       "         0.89198606, 0.8989547 , 0.8989547 ]),\n",
       "  'split3_test_score': array([0.8989547 , 0.91289199, 0.90592334, 0.8989547 , 0.90243902,\n",
       "         0.91289199, 0.90243902, 0.90940767, 0.90940767, 0.91289199,\n",
       "         0.91637631, 0.91637631, 0.90243902, 0.90940767, 0.90940767,\n",
       "         0.91289199, 0.91637631, 0.91637631]),\n",
       "  'split4_test_score': array([0.94773519, 0.94425087, 0.95470383, 0.95121951, 0.94425087,\n",
       "         0.94425087, 0.91637631, 0.92682927, 0.92682927, 0.91637631,\n",
       "         0.91986063, 0.91986063, 0.91637631, 0.92682927, 0.92682927,\n",
       "         0.91637631, 0.91986063, 0.91986063]),\n",
       "  'mean_test_score': array([0.92130919, 0.92061281, 0.92339833, 0.92130919, 0.91991643,\n",
       "         0.92409471, 0.90181058, 0.90668524, 0.90668524, 0.89902507,\n",
       "         0.90389972, 0.90389972, 0.90181058, 0.90668524, 0.90668524,\n",
       "         0.89902507, 0.90389972, 0.90389972]),\n",
       "  'std_test_score': array([0.02112116, 0.01688391, 0.02081489, 0.01897876, 0.01441786,\n",
       "         0.01268201, 0.01419715, 0.01438544, 0.01438544, 0.01918222,\n",
       "         0.01613941, 0.01613941, 0.01419715, 0.01438544, 0.01438544,\n",
       "         0.01918222, 0.01613941, 0.01613941]),\n",
       "  'rank_test_score': array([ 3,  5,  2,  3,  6,  1, 15,  7,  7, 17, 11, 11, 15,  7,  7, 17, 11,\n",
       "         11], dtype=int32)}}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBM_2_cls_scores_fewer_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T00:07:18.304982Z",
     "start_time": "2019-10-22T00:07:18.048965Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train and fit Dummy classifier\n",
    "\n",
    "# Function arguments:\n",
    "model = DummyClassifier(random_state=3, strategy='stratified')\n",
    "transformer = RandomOverSampler(random_state=3, sampling_strategy='minority')\n",
    "CV = 5\n",
    "\n",
    "# Function arguments: classifier params\n",
    "\n",
    "param_grid = dict()\n",
    "\n",
    "# Call parameter selection function\n",
    "Dummy_2_cls_scores_params, Dummy_2_cls_model = model_sel_grid.train_fit_time(model,\n",
    "                                                                        param_grid,\n",
    "                                                                        transformer,\n",
    "                                                                        X_train,\n",
    "                                                                        X_test,\n",
    "                                                                        y_train,\n",
    "                                                                        y_test,\n",
    "                                                                        CV)\n",
    "\n",
    "# Pickle results\n",
    "with open('/Users/greenapple/project3/models/Dummy_2_cls_scores_params.pkl', 'wb') as f:\n",
    "    pickle.dump(Dummy_2_cls_scores_params, f)\n",
    "    \n",
    "# Pickle model\n",
    "with open('/Users/greenapple/project3/models/Dummy_2_cls_model.pkl', 'wb') as f:\n",
    "    pickle.dump(Dummy_2_cls_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T00:07:29.791703Z",
     "start_time": "2019-10-22T00:07:29.707075Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_train_score': 0.4742339832869081,\n",
       " 'best_test_score': 0.4888888888888889,\n",
       " 'time_sec': 0.146509,\n",
       " 'time_best_fit_sec': 0.008307600000000002,\n",
       " 'best_params': {},\n",
       " 'best_estimator': Pipeline(memory=None,\n",
       "          steps=[('transformer',\n",
       "                  RandomOverSampler(random_state=3, ratio=None,\n",
       "                                    return_indices=False,\n",
       "                                    sampling_strategy='minority')),\n",
       "                 ('model',\n",
       "                  DummyClassifier(constant=None, random_state=3,\n",
       "                                  strategy='stratified'))],\n",
       "          verbose=False),\n",
       " 'best_test_proba': array([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]]),\n",
       " 'best_y_hat': array(['footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'purr', 'purr', 'purr', 'purr', 'purr',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'purr', 'purr', 'purr', 'footsteps', 'purr', 'purr', 'footsteps',\n",
       "        'footsteps', 'purr', 'purr', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'purr', 'footsteps',\n",
       "        'footsteps', 'purr', 'purr', 'purr', 'purr', 'purr', 'purr',\n",
       "        'purr', 'footsteps', 'footsteps', 'purr', 'purr', 'purr', 'purr',\n",
       "        'purr', 'footsteps', 'purr', 'purr', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps', 'purr',\n",
       "        'footsteps', 'purr', 'purr', 'purr', 'purr', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps', 'purr',\n",
       "        'purr', 'purr', 'purr', 'purr', 'purr', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'purr', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'purr', 'footsteps', 'footsteps',\n",
       "        'purr', 'purr', 'purr', 'purr', 'purr', 'footsteps', 'footsteps',\n",
       "        'purr', 'purr', 'purr', 'purr', 'footsteps', 'footsteps', 'purr',\n",
       "        'purr', 'footsteps', 'footsteps', 'purr', 'purr', 'purr', 'purr',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'purr', 'footsteps',\n",
       "        'footsteps', 'purr', 'purr', 'footsteps', 'purr', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'purr', 'purr', 'purr', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'purr', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'purr', 'footsteps', 'footsteps',\n",
       "        'purr', 'purr', 'footsteps', 'footsteps', 'purr', 'purr', 'purr',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'purr', 'purr', 'footsteps', 'purr', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'purr', 'purr',\n",
       "        'purr', 'footsteps', 'purr', 'purr', 'purr', 'footsteps', 'purr',\n",
       "        'purr', 'purr', 'purr', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'purr', 'purr', 'footsteps', 'purr', 'purr', 'purr',\n",
       "        'purr', 'purr', 'purr', 'purr', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'purr', 'purr', 'purr',\n",
       "        'footsteps', 'purr', 'purr', 'footsteps', 'purr', 'purr',\n",
       "        'footsteps', 'purr', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'purr', 'purr', 'purr', 'footsteps', 'purr', 'purr',\n",
       "        'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'purr', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'purr', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'purr', 'purr', 'footsteps', 'purr',\n",
       "        'purr', 'footsteps', 'purr', 'footsteps', 'purr', 'footsteps',\n",
       "        'purr', 'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'footsteps', 'purr', 'footsteps', 'purr', 'purr', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'purr', 'purr', 'purr', 'purr',\n",
       "        'purr', 'purr', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'purr', 'footsteps', 'footsteps', 'footsteps',\n",
       "        'purr', 'footsteps', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'purr', 'purr', 'footsteps', 'purr', 'footsteps', 'footsteps',\n",
       "        'footsteps', 'footsteps', 'footsteps', 'purr', 'footsteps', 'purr',\n",
       "        'footsteps', 'purr', 'footsteps', 'footsteps', 'purr', 'purr',\n",
       "        'purr', 'purr', 'footsteps', 'footsteps', 'footsteps', 'purr',\n",
       "        'purr', 'purr', 'footsteps'], dtype=object),\n",
       " 'all_scores': {'mean_fit_time': array([0.01746607]),\n",
       "  'std_fit_time': array([0.00457026]),\n",
       "  'mean_score_time': array([0.0049778]),\n",
       "  'std_score_time': array([0.00133333]),\n",
       "  'params': [{}],\n",
       "  'split0_test_score': array([0.48958333]),\n",
       "  'split1_test_score': array([0.48083624]),\n",
       "  'split2_test_score': array([0.48083624]),\n",
       "  'split3_test_score': array([0.45296167]),\n",
       "  'split4_test_score': array([0.46689895]),\n",
       "  'mean_test_score': array([0.47423398]),\n",
       "  'std_test_score': array([0.01287897]),\n",
       "  'rank_test_score': array([1], dtype=int32)}}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dummy_2_cls_scores_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T00:07:45.861782Z",
     "start_time": "2019-10-22T00:07:45.782856Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dummy classifier\n",
    "dummy = DummyClassifier()\n",
    "dummy.fit(X_train, y_train)\n",
    "f1_dummy = f1_score(y_test, dummy.predict(X_test), average='micro')\n",
    "accuracy_dummy = accuracy_score(y_test, dummy.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T00:07:46.368892Z",
     "start_time": "2019-10-22T00:07:46.285594Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy classifier F1 score:  0.6888888888888889\n",
      "Dummy classifier accuracy score:  0.7194444444444444\n"
     ]
    }
   ],
   "source": [
    "print('Dummy classifier F1 score: ', f1_dummy)\n",
    "print('Dummy classifier accuracy score: ', accuracy_dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T00:08:32.095083Z",
     "start_time": "2019-10-22T00:08:32.017383Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "footsteps    291\n",
       "purr          69\n",
       "Name: y_name, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T00:08:32.523590Z",
     "start_time": "2019-10-22T00:08:32.381869Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null accuracy:  footsteps    0.808333\n",
      "Name: y_name, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "null_accuracy = y_test.value_counts().head(1) / len(y_test)\n",
    "print('Null accuracy: ', null_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T00:21:38.099861Z",
     "start_time": "2019-10-22T00:21:38.018427Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>F1_score_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Models, F1_score_train]\n",
       "Index: []"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_score_table = pd.DataFrame(columns=['Models', 'F1_score_train'])\n",
    "model_score_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T00:21:40.108964Z",
     "start_time": "2019-10-22T00:21:40.037780Z"
    }
   },
   "outputs": [],
   "source": [
    "model_score_table['Models'] = ['Logistis_Regression',\n",
    "                              'KNN',\n",
    "                              'Multinomial_NB',\n",
    "                              'SVC_poly',\n",
    "                              'Random_Forest',\n",
    "                               'GBM',\n",
    "                               'Dummy'\n",
    "                              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T00:23:29.707450Z",
     "start_time": "2019-10-22T00:23:29.642848Z"
    }
   },
   "outputs": [],
   "source": [
    "model_score_table['F1_score_train'] = trainin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T00:23:33.700648Z",
     "start_time": "2019-10-22T00:23:33.629584Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>F1_score_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Logistis_Regression</td>\n",
       "      <td>0.914345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>KNN</td>\n",
       "      <td>0.903900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Multinomial_NB</td>\n",
       "      <td>0.870474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>SVC_poly</td>\n",
       "      <td>0.926184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>0.916435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>GBM</td>\n",
       "      <td>0.924095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>0.474234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Models  F1_score_train\n",
       "0  Logistis_Regression        0.914345\n",
       "1                  KNN        0.903900\n",
       "2       Multinomial_NB        0.870474\n",
       "3             SVC_poly        0.926184\n",
       "4        Random_Forest        0.916435\n",
       "5                  GBM        0.924095\n",
       "6                Dummy        0.474234"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_score_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T00:31:20.145737Z",
     "start_time": "2019-10-22T00:31:20.084893Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pickle results\n",
    "with open('/Users/greenapple/project3/reports/figures/model_score_table_MVP.pkl', 'wb') as f:\n",
    "    pickle.dump(model_score_table, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for printing confusion matrices (see: https://gist.github.com/shaypal5/94c53d765083101efc0240d776a23823)\n",
    "\n",
    "# prints confusion matrix as a heatmap which is nicer to visaulize\n",
    "\n",
    "def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=18):\n",
    "    \"\"\"Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a heatmap.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    confusion_matrix: numpy.ndarray\n",
    "        The numpy.ndarray object returned from a call to sklearn.metrics.confusion_matrix. \n",
    "        Similarly constructed ndarrays can also be used.\n",
    "    class_names: list\n",
    "        An ordered list of class names, in the order they index the given confusion matrix.\n",
    "    figsize: tuple\n",
    "        A 2-long tuple, the first value determining the horizontal size of the ouputted figure,\n",
    "        the second determining the vertical size. Defaults to (10,7).\n",
    "    fontsize: int\n",
    "        Font size for axes labels. Defaults to 14.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.figure.Figure\n",
    "        The resulting confusion matrix figure\n",
    "    \"\"\"\n",
    "    df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names, )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "cm = print_confusion_matrix(conf_mat, ['Class 0', 'Class 1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model for later\n",
    "filename = /Users/greenapple/project3/models/logreg.sav'\n",
    "joblib.dump(logreg, filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metis",
   "language": "python",
   "name": "metis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "287.986px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
